{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il6NhhW5UMeT",
        "outputId": "35efb6b5-bb78-4c93-a4c1-7c290bc91b1f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.9.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from gymnasium import Env, spaces, register, make"
      ],
      "metadata": {
        "id": "FupryweRUQQq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J_HaZNr1S5G4"
      },
      "outputs": [],
      "source": [
        "#Random-Maze Environment Implementation\n",
        "\n",
        "class RMEnv(Env):\n",
        "    metadata = {\"render_modes\": [\"human\", \"rgb_array\"], \"render_fps\": 4}\n",
        "\n",
        "    def __init__(self, render_mode=None):\n",
        "\n",
        "        self.P = {\n",
        "            0: {\n",
        "                0: [(0.9, 0, -0.04, False),(0.1, 1, -0.04, False)],\n",
        "                1: [(0.8, 1, -0.04, False),(0.1, 4, -0.04, False),(0.1, 0, -0.04, False)],\n",
        "                2: [(0.8, 4, -0.04, False),(0.1, 1, -0.04, False),(0.1, 0, -0.04, False)],\n",
        "                3: [(0.9, 0, -0.04, False),(0.1, 4, -0.04, False)]\n",
        "\n",
        "            },\n",
        "            1: {\n",
        "                0: [(0.8, 1, -0.04, False),(0.1, 0, -0.04, False),(0.1, 2, -0.04, False)],\n",
        "                1: [(0.8, 2, -0.04, False),(0.2, 1, -0.04, False)],\n",
        "                2: [(0.8, 1, -0.04, False),(0.1, 0, -0.04, False),(0.1, 2, -0.04, False)],\n",
        "                3: [(0.8, 0, -0.04, False),(0.2, 1, -0.04, False)]\n",
        "\n",
        "            },\n",
        "            2: {\n",
        "                0: [(0.8, 2, -0.04, False),(0.1, 3, 1, True),(0.1, 1, -0.04, False)],\n",
        "                1: [(0.8, 3, 1, True),(0.1, 2, -0.04, False),(0.1, 6, -0.04, False)],\n",
        "                2: [(0.8, 6, -0.04, False),(0.1, 1, -0.04, False),(0.1, 3, 1, True)],\n",
        "                3: [(0.8, 1, -0.04, False),(0.1, 2, -0.04, False),(0.1, 6, -0.04, False)]\n",
        "\n",
        "            },\n",
        "            3: {\n",
        "                0: [(1.0, 3, 0, True)],\n",
        "                1: [(1.0, 3, 0, True)],\n",
        "                2: [(1.0, 3, 0, True)],\n",
        "                3: [(1.0, 3, 0, True)]\n",
        "\n",
        "            },\n",
        "            4: {\n",
        "                0: [(0.8, 0, -0.04, False),(0.2, 4, -0.04, False)],\n",
        "                1: [(0.8, 4, -0.04, False),(0.1, 0, -0.04, False),(0.1, 8, -0.04, False)],\n",
        "                2: [(0.8, 8, -0.04, False),(0.2, 4, -0.04, False)],\n",
        "                3: [(0.8, 4, -0.04, False),(0.1, 0, -0.04, False),(0.1, 8, -0.04, False)]\n",
        "\n",
        "            },\n",
        "            5: {\n",
        "                0: [(0.0, 5, 0, False)],\n",
        "                1: [(0.0, 5, 0, False)],\n",
        "                2: [(0.0, 5, 0, False)],\n",
        "                3: [(0.0, 5, 0, False)]\n",
        "\n",
        "            },\n",
        "\n",
        "            6: {\n",
        "                0: [(0.8, 2, -0.04, False),(0.1, 7, -1, True),(0.1, 6, -0.04, False)],\n",
        "                1: [(0.8, 7, -1, True),(0.1, 2, -0.04, False),(0.1, 10, -0.04, False)],\n",
        "                2: [(0.8, 10, -0.04, False),(0.1, 7, -1, True),(0.1, 6, -0.04, False)],\n",
        "                3: [(0.8, 6, -0.04, False),(0.1, 2, -0.04, False),(0.1, 10, -0.04, False)]\n",
        "\n",
        "            },\n",
        "            7: {\n",
        "                0: [(1.0, 7, 0, True)],\n",
        "                1: [(1.0, 7, 0, True)],\n",
        "                2: [(1.0, 7, 0, True)],\n",
        "                3: [(1.0, 7, 0, True)]\n",
        "\n",
        "            },\n",
        "            8: {\n",
        "                0: [(0.8, 4, -0.04, False),(0.1, 9, -0.04, False),(0.1, 8, -0.04, False)],\n",
        "                1: [(0.8, 9, -0.04, False),(0.1, 4, -0.04, False),(0.1, 8, -0.04, False)],\n",
        "                2: [(0.9, 8, -0.04, False),(0.1, 9, -0.04, False)],\n",
        "                3: [(0.9, 8, -0.04, False),(0.1, 4, -0.04, False)]\n",
        "\n",
        "            },\n",
        "            9: {\n",
        "              0: [(0.8, 9, -0.04, False),(0.1, 8, -0.04, False),(0.1, 10, -0.04, False)],\n",
        "              1: [(0.8, 10, -0.04, False),(0.2, 9, -0.04, False)],\n",
        "              2: [(0.8, 9, -0.04, False),(0.1, 10, -0.04, False),(0.1, 8, -0.04, False)],\n",
        "              3: [(0.8, 8, -0.04, False),(0.2, 9, -0.04, False)]\n",
        "\n",
        "            },\n",
        "            10: {\n",
        "              0: [(0.8, 6, -0.04, False),(0.1, 11, -0.04, False),(0.1, 9, -0.04, False)],\n",
        "              1: [(0.8, 11, -0.04, False),(0.1, 6, -0.04, False),(0.1, 10, -0.04, False)],\n",
        "              2: [(0.8, 10, -0.04, False),(0.1, 11, -0.04, False),(0.1, 9, -0.04, False)],\n",
        "              3: [(0.8, 9, -0.04, False),(0.1, 10, -0.04, False),(0.1, 6, -0.04, False)]\n",
        "\n",
        "            },\n",
        "            11: {\n",
        "                0: [(0.8, 7, -1, True),(0.1, 11, -0.04, False),(0.1, 10, -0.04, False)],\n",
        "                1: [(0.9, 11, -0.04, False),(0.1, 7, -1, True)],\n",
        "                2: [(0.9, 11, -0.04, False),(0.1, 10, -0.04, False)],\n",
        "                3: [(0.8, 10, -0.04, False),(0.1, 11, -0.04, False),(0.1, 7, -1, True)]\n",
        "\n",
        "            },\n",
        "        }\n",
        "        self.size = 12 # The size of the 1D grid\n",
        "\n",
        "       #We have 3 observations, corresponding to each position in the 1-D grid\n",
        "        self.observation_space = spaces.Discrete(self.size)\n",
        "\n",
        "        #We have 2 actions, corresponding to \"left\" & \"right\"\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "        assert render_mode is None or render_mode in self.metadata[\"render_modes\"]\n",
        "        self.render_mode = render_mode\n",
        "\n",
        "        self.window = None\n",
        "        self.clock = None\n",
        "\n",
        "    def _get_obs(self):\n",
        "\n",
        "        return self._agent_location\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self._agent_location = 8\n",
        "        self._target_location = 3\n",
        "        self._dead_state = 7\n",
        "\n",
        "\n",
        "        observation = self._get_obs()\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self._render_frame()\n",
        "\n",
        "        return observation\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        prev_location = self._agent_location\n",
        "        transitions = self.P[prev_location][action]\n",
        "        probabilities, next_states, rewards, termination = zip(*transitions)\n",
        "\n",
        "        # Randomly select a transition based on the probabilities\n",
        "        index = random.choices(range(len(probabilities)), weights=probabilities, k=1)[0]\n",
        "        prob,self._agent_location, reward, terminated = probabilities[index],next_states[index], rewards[index], termination[index]\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        truncated = False\n",
        "\n",
        "        # \"current_state\": prev_location,\"action\":action,\"next_state\": self._agent_location,\"reward\":reward,\"done\":terminated\n",
        "        tansition_info={\"current_state\": prev_location,\n",
        "                       \"action\":action,\n",
        "                        \"next_state\": self._agent_location,\n",
        "                        \"reward\":reward,\n",
        "                        \"done\":terminated}\n",
        "\n",
        "        if self.render_mode == \"human\":\n",
        "            self._render_frame()\n",
        "\n",
        "        # Return the required 5-tuple\n",
        "        return observation, reward, terminated,truncated,tansition_info\n",
        "\n",
        "register(id='RMEnv', entry_point=RMEnv)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing enviroment\n",
        "env1 = make('RMEnv', render_mode=\"rgb_array\")\n",
        "observation= env1.reset(seed=32)\n",
        "for i in range(10):\n",
        "  action = env1.action_space.sample()\n",
        "  observation, reward, terminated,truncated,info = env1.step(action)\n",
        "\n",
        "  print(info,\"\\n\")\n",
        "\n",
        "  if terminated or truncated:\n",
        "      observation= env1.reset(seed=32)\n",
        "      if reward==1:\n",
        "        print(\"Goal\")\n",
        "      else:\n",
        "        print(\"Hole\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_hxNBguC9W_",
        "outputId": "bc4e9488-0d25-41b9-b595-263d054b94d0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'current_state': 8, 'action': 1, 'next_state': 9, 'reward': -0.04, 'done': False} \n",
            "\n",
            "{'current_state': 9, 'action': 0, 'next_state': 9, 'reward': -0.04, 'done': False} \n",
            "\n",
            "{'current_state': 9, 'action': 2, 'next_state': 10, 'reward': -0.04, 'done': False} \n",
            "\n",
            "{'current_state': 10, 'action': 2, 'next_state': 10, 'reward': -0.04, 'done': False} \n",
            "\n",
            "{'current_state': 10, 'action': 0, 'next_state': 6, 'reward': -0.04, 'done': False} \n",
            "\n",
            "{'current_state': 6, 'action': 0, 'next_state': 2, 'reward': -0.04, 'done': False} \n",
            "\n",
            "{'current_state': 2, 'action': 2, 'next_state': 6, 'reward': -0.04, 'done': False} \n",
            "\n",
            "{'current_state': 6, 'action': 1, 'next_state': 7, 'reward': -1, 'done': True} \n",
            "\n",
            "Hole\n",
            "{'current_state': 8, 'action': 2, 'next_state': 8, 'reward': -0.04, 'done': False} \n",
            "\n",
            "{'current_state': 8, 'action': 1, 'next_state': 9, 'reward': -0.04, 'done': False} \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "question 2\n"
      ],
      "metadata": {
        "id": "9lUkSNl4QkDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamma=0.99\n",
        "#Policy\n",
        "#towards goal\n",
        "p_g=[[0.0,1.0,0.0,0.0],[0.0,1.0,0.0,0.0],[0.0,1.0,0.0,0.0],[0.25,0.25,0.25,0.25],[0.0,1.0,0.0,0.0],[0.25,0.25,0.25,0.25],[1.0,0.0,0.0,0.0],[0.25,0.25,0.25,0.25],[1.0,0.0,0.0,0.0],[0.0,1.0,0.0,0.0],[1.0,0.0,0.0,0.0],[1.0,0.0,0.0,0.0]]\n",
        "#away from hole\n",
        "p_h=[[0.0,0.0,0.0,1.0],[0.0,0.0,0.0,1.0],[0.0,0.0,0.0,1.0],[0.25,0.25,0.25,0.25],[0.0,0.0,0.0,1.0],[0.25,0.25,0.25,0.25],[0.0,0.0,0.0,1.0],[0.25,0.25,0.25,0.25],[0.0,0.0,0.0,1.0],[0.0,0.0,1.0,0.0],[0.0,0.0,1.0,0.0],[0.0,0.0,1.0,0.0]]\n",
        "#random\n",
        "p_r=[[0.1,0.1,0.7,0.1],[0.1,0.7,0.1,0.1],[0.7,0.1,0.1,0.1],[0.25,0.25,0.25,0.25],[0.1,0.7,0.1,0.1],[0.25,0.25,0.25,0.25],[0.1,0.1,0.1,0.7],[0.25,0.25,0.25,0.25],[0.1,0.1,0.7,0.1],[0.1,0.1,0.1,0.7],[0.7,0.1,0.1,0.1],[0.1,0.7,0.1,0.1]]\n"
      ],
      "metadata": {
        "id": "3VZr_pL38OtP"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "#policy evaluation\n",
        "def policy_evaluation(env,pi,gamma,theta):\n",
        "  v_old=np.zeros(env.observation_space.n)\n",
        "  i=0\n",
        "  while 1:\n",
        "    v_new=np.zeros(env.observation_space.n)\n",
        "    for s in range(env.observation_space.n):\n",
        "      for a in range(env.action_space.n):\n",
        "        temp=0\n",
        "        for t_prob,n_s,r,_ in env.P[s][a]:\n",
        "          temp=temp+t_prob*(r+gamma*v_old[n_s])\n",
        "\n",
        "        v_new[s]+=pi[s][a]*temp\n",
        "    diff=np.abs(v_new-v_old)\n",
        "    i=i+1\n",
        "    if np.max(diff)<theta:\n",
        "      break\n",
        "    v_old=v_new\n",
        "\n",
        "\n",
        "  return v_new,i\n",
        "\n",
        "#policy improvement\n",
        "def policy_improvement(env,v,gamma):\n",
        "  Q=np.zeros((env.observation_space.n,env.action_space.n))\n",
        "  pi=np.zeros(env.observation_space.n)\n",
        "  for s in range(env.observation_space.n):\n",
        "    for a in range(env.action_space.n):\n",
        "      for t_prob,n_s,r,_ in env.P[s][a]:\n",
        "        Q[s][a]+=t_prob*(r+gamma*v[n_s])\n",
        "\n",
        "  for s in range(env.observation_space.n):\n",
        "    pi[s]=np.argmax(Q[s])\n",
        "\n",
        "  return pi\n",
        "\n",
        "#policy iteration\n",
        "def poilcy_iteration(env,gamma,theta,pi):\n",
        "  pie=np.zeros(env.observation_space.n)\n",
        "  for s in range(env.observation_space.n):\n",
        "    pie[s]=random.choices(range(env.action_space.n), weights=pi[s], k=1)[0]\n",
        "  i=0\n",
        "  while 1:\n",
        "    pi_old=pie\n",
        "    v,_=policy_evaluation(env,pi,gamma,theta)\n",
        "    pie=policy_improvement(env,v,gamma)\n",
        "    i=i+1\n",
        "    if np.array_equal(pi_old, pie):\n",
        "      break\n",
        "  return v,pie,i\n"
      ],
      "metadata": {
        "id": "Numvj1LbQluf"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing policy iteration\n",
        "theta=1e-10\n",
        "#towards goal\n",
        "V_g,Pi_g,n_g=poilcy_iteration(env1,gamma,theta,p_g)\n",
        "\n",
        "#away from hole\n",
        "V_h,P_h,n_h=poilcy_iteration(env1,gamma,theta,p_h)\n",
        "\n",
        "#random\n",
        "V_r,P_r,n_r=poilcy_iteration(env1,gamma,theta,p_r)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-btVZ--QQo6y",
        "outputId": "ce9f80d0-0904-4a93-ad0b-0fb0a2b1f0d6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.P to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.P` for environment variables or `env.get_wrapper_attr('P')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"policy:towards the goal\")\n",
        "print(\"value function\",V_g,\"\\n\")\n",
        "print(\"optimum policy\",Pi_g,\"\\n\")\n",
        "print(\"num of iterations\",n_g,\"\\n\\n\")\n",
        "\n",
        "print(\"policy:away from Hole\")\n",
        "print(\"value function\",V_h,\"\\n\")\n",
        "print(\"optimum policy\",P_h,\"\\n\")\n",
        "print(\"num of iterations\",n_h,\"\\n\\n\")\n",
        "\n",
        "print(\"policy:Random\")\n",
        "print(\"value function\",V_r,\"\\n\")\n",
        "print(\"optimum policy\",P_r,\"\\n\")\n",
        "print(\"num of iterations\",n_r,\"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGrNu3-udhRk",
        "outputId": "5fc9b880-0686-426e-89ec-f872ee5dac18"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy:towards the goal\n",
            "value function [ 0.7737106   0.89286374  0.95464233  0.          0.30267844  0.\n",
            "  0.68820946  0.          0.26626026  0.40585022  0.46147965 -0.84607493] \n",
            "\n",
            "optimum policy [1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 3.] \n",
            "\n",
            "num of iterations 2 \n",
            "\n",
            "\n",
            "policy:away from Hole\n",
            "value function [-3.99999999 -3.99999999 -3.99999999  0.         -3.99999999  0.\n",
            " -3.99999999  0.         -3.99999999 -3.99999999 -3.99999999 -3.99999999] \n",
            "\n",
            "optimum policy [0. 1. 1. 0. 0. 0. 1. 0. 2. 1. 0. 0.] \n",
            "\n",
            "num of iterations 2 \n",
            "\n",
            "\n",
            "policy:Random\n",
            "value function [-1.3039768  -0.1752878   0.08592316  0.         -1.5683866   0.\n",
            " -0.62675083  0.         -1.67928545 -1.60208747 -0.91212583 -1.06170702] \n",
            "\n",
            "optimum policy [1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 3.] \n",
            "\n",
            "num of iterations 2 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#value iteration\n",
        "def value_iteration(env,gamma,theta):\n",
        "  v=np.zeros(env.observation_space.n)\n",
        "  pi=np.zeros(env.observation_space.n)\n",
        "  v_new=np.zeros(env.observation_space.n)\n",
        "  i=0\n",
        "  while 1:\n",
        "    Q=np.zeros((env.observation_space.n,env.action_space.n))\n",
        "    for s in range(env.observation_space.n):\n",
        "      for a in range(env.action_space.n):\n",
        "        for t_prob,n_s,r,_ in env.P[s][a]:\n",
        "          Q[s][a]+=t_prob*(r+gamma*v[n_s])\n",
        "    v_new=np.max(Q, axis=1)\n",
        "    diff=np.abs(v-v_new)\n",
        "    i=i+1\n",
        "    if np.max(diff)<theta:\n",
        "      break\n",
        "    v=v_new\n",
        "\n",
        "  for s in range(env.observation_space.n):\n",
        "    pi[s]=np.argmax(Q[s])\n",
        "\n",
        "  return v,pi,i"
      ],
      "metadata": {
        "id": "3OjGYsEDex5M"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V,Pi,n=value_iteration(env1,gamma,theta)\n",
        "print(\"Value Iteration\")\n",
        "print(\"value function\",V,\"\\n\")\n",
        "print(\"optimum policy\",Pi,\"\\n\")\n",
        "print(\"num of iterations\",n,\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt5xNazGNTu4",
        "outputId": "c12d7a08-ad8a-44f5-b017-04318947dc90"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value Iteration\n",
            "value function [0.82442985 0.89286374 0.95464233 0.         0.76427487 0.\n",
            " 0.68820946 0.         0.69763948 0.63906542 0.60613373 0.38186228] \n",
            "\n",
            "optimum policy [1. 1. 1. 0. 0. 0. 0. 0. 0. 3. 0. 3.] \n",
            "\n",
            "num of iterations 38 \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}