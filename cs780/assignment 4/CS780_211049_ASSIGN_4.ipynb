{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjN4DR4lTqkw"
      },
      "source": [
        "# ASSIGNMENT 4\n",
        "# Submission Deadline: April 16, 6PM\n",
        "# Submission Link: https://forms.gle/G4B6FiAsyoPLCkZu9  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-yx9x7BTqkx"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "1. [Provide Information](#Provide-Information)\n",
        "2. [Instructions](#Instructions)\n",
        "3. [Environment](#Environment)\n",
        "4. [Hyperparameters](#Hyperparameters)\n",
        "5. [Helper Functions](#helper)\n",
        "6. [DDPG](#ddpg)\n",
        "7. [TD3](#td3)\n",
        "8. [PPO](#ppo)\n",
        "9. [Experiments to Run](#experiments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW9kbTiSTqky"
      },
      "source": [
        "# Provide Information\n",
        "<a id=\"Provide-Information\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2Hb_2MpTqky"
      },
      "source": [
        "Name: **Somya Gupta**\n",
        "\n",
        "Roll No.: **211049**\n",
        "\n",
        "IITK EMail: **somyavg21@iitk.ac.in**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqw93n4uTqky"
      },
      "source": [
        "# Instructions\n",
        "<a id=\"Instructions\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "272erps8Tqky"
      },
      "source": [
        "**Read all the instructions below carefully before you start working on the assignment.**\n",
        "- The purpose of this course is that you learn RL and the best way to do that is by implementation and experimentation.\n",
        "- The assignment requires your to implement some algorithms and you are required report your findings after experimenting with those algorithms.\n",
        "- **You are required to submit ZIP file containing a Jupyter notebook (.ipynb), and an image folder. The notebook would include the code, graphs/plots of the experiments you run and your findings/observations. Image folder is the folder having plots, images, etc.**\n",
        "- In case you use any maths in your explanations, render it using latex in the Jupyter notebook.\n",
        "- You are expected to implement algorithms on your own and not copy it from other sources/class mates. Of course, you can refer to lecture slides.\n",
        "- If you use any reference or material (including code), please cite the source, else it will be considered plagiarism. But referring to other sources that directly solve the problems given in the assignment is not allowed. There is a limit to which you can refer to outside material.\n",
        "- This is an individual assignment.\n",
        "- In case your solution is found to have an overlap with solution by someone else (including external sources), all the parties involved will get zero in this and all future assignments plus further more penalties in the overall grade. We will check not just for lexical but also semantic overlap. Same applies for the code as well. Even an iota of cheating would NOT be tolerated. If you cheat one line or cheat one page the penalty would be same.\n",
        "- Be a smart agent, think long term, if you cheat we will discover it somehow, the price you would be paying is not worth it.\n",
        "- In case you are struggling with the assignment, seek help from TAs. Cheating is not an option! I respect honesty and would be lenient if you are not able to solve some questions due to difficulty in understanding. Remember we are there to help you out, seek help if something is difficult to understand.\n",
        "- The deadline for the submission is given above. Submit at least 30 minutes before the deadline, lot can happen at the last moment, your internet can fail, there can be a power failure, you can be abducted by aliens, etc.\n",
        "- You have to submit your assignment via the Google Form (link above)\n",
        "- The form would close after the deadline and we will not accept any solution. No reason what-so-ever would be accepted for not being able to submit before the deadline.\n",
        "- Since the assignment involves experimentation, reporting your results and observations, there is a lot of scope for creativity and innovation and presenting new perspectives. Such efforts would be highly appreciated and accordingly well rewarded. Be an exploratory agent!\n",
        "- Your code should be very well documented, there are marks for that.\n",
        "- In your plots, have a clear legend and clear lines, etc. Of course you would generating the plots in your code but you must also put these plots in your notebook. Generate high resolution pdf/svg version of the plots so that it doesn't pixilate on zooming.\n",
        "- For all experiments, report about the seed used in the code documentation, write about the seed used.\n",
        "- In your notebook write about all things that are not obvious from the code e.g., if you have made any assumptions, references/sources, running time, etc.\n",
        "-  **DO NOT Forget to write name, roll no and email details above**\n",
        "- **In addition to checking your code, we will be conducting one-on-one viva for the evaluation. So please make sure that you do not cheat!**\n",
        "- **Use of LLMs based tools or AI-based code tools is strictly prohibited! Use of ChatGPT, VS Code, Gemini, CO-Pilot, etc. is not allowed. NOTE VS code is also not allowed. Even in Colab disable the AI assistant. If you use it, we will know it very easily. Use of any of the tools would be counted as cheating and would be given a ZERO, with no questions asked.**\n",
        "- For each of the sub-part in the question create a new cell below the question and put your answer in there. This includes the plots as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdjFbSvqTqky"
      },
      "source": [
        "# OpenAI Gym Environments\n",
        "<a id=\"Environment\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q4bmiREZvcR",
        "outputId": "c428fce1-1e6e-4f13-b07f-99dd07d0ad8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y0ZZtw39Tqkz"
      },
      "outputs": [],
      "source": [
        "# all imports go in here\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import time\n",
        "import random\n",
        "from itertools import count, cycle\n",
        "from collections import deque, namedtuple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y4zS9ztTqkz"
      },
      "source": [
        "In this assignment we will be exploring Deep RL algorithms and for this we will be using environmentd provided by OpenAI Gym. In particular we will be exploring \"Pendulum-v1\" , \"Hopper-v4\", and \"Half-Cheetah\" environments (https://gymnasium.farama.org/environments/classic_control/ ). The code to instantiate the environments are given in the cells below. Run these cells and play with the environments to learn more details about the environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v6dk126Tqkz",
        "outputId": "2d5ea1c7-2d29-4575-bdbb-8018d38ca4d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation Space = \n",
            "Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)\n",
            "Action Space = \n",
            "Box(-2.0, 2.0, (1,), float32)\n",
            "In episode 0\n",
            "(array([-0.9996797 , -0.0253075 ,  0.74435383], dtype=float32), {})\n",
            "[-0.9974179  -0.07181562  0.9313459 ]\n",
            "[-0.99266046 -0.12093452  0.98707515]\n",
            "[-0.98503816 -0.17233652  1.0393987 ]\n",
            "[-0.9737827 -0.2274801  1.1257594]\n",
            "[-0.9649726 -0.2623506  0.7193628]\n",
            "[-0.96104944 -0.27637652  0.29128805]\n",
            "[-0.9620454  -0.27288955 -0.07252774]\n",
            "[-0.96177995 -0.2738236   0.01942021]\n",
            "[-0.96485525 -0.26278192 -0.22924025]\n",
            "[-0.972509   -0.23286515 -0.6176302 ]\n",
            "[-0.98142534 -0.19184458 -0.8396301 ]\n",
            "[-0.9909423  -0.13428824 -1.1669227 ]\n",
            "[-0.99700916 -0.07728345 -1.1466914 ]\n",
            "[-0.99996597 -0.00825376 -1.3821348 ]\n",
            "[-0.9987471   0.05004163 -1.1663278 ]\n",
            "[-0.9928466   0.11939676 -1.3923947 ]\n",
            "[-0.98061013  0.19596875 -1.5512595 ]\n",
            "[-0.965439    0.26062897 -1.3285677 ]\n",
            "[-0.9474494   0.31990576 -1.2391275 ]\n",
            "[-0.9285639   0.37117267 -1.0928314 ]\n",
            "[-0.9105587   0.41337985 -0.91782427]\n",
            "[-0.89254344  0.4509614  -0.8335883 ]\n",
            "[-0.87718195  0.48015812 -0.65985477]\n",
            "[-0.8711711   0.49097955 -0.24757701]\n",
            "[-0.87137586  0.49061605  0.00834371]\n",
            "[-0.88132066  0.47251862  0.4130046 ]\n",
            "[-0.8983728   0.43923366  0.7480182 ]\n",
            "[-0.9232309  0.3842456  1.2070982]\n",
            "[-0.9445492  0.32837    1.196264 ]\n",
            "[-0.96745706  0.25303525  1.5752207 ]\n",
            "[-0.9853151   0.17074588  1.6845943 ]\n",
            "[-0.99592036  0.09023672  1.6245397 ]\n",
            "[-0.9998201   0.01896741  1.4278218 ]\n",
            "[-0.9979632  -0.06379285  1.6560948 ]\n",
            "[-0.9891791  -0.14671323  1.6681707 ]\n",
            "[-0.97576094 -0.21883921  1.4675994 ]\n",
            "[-0.95526725 -0.295744    1.5921911 ]\n",
            "[-0.9374434  -0.34813783  1.1069933 ]\n",
            "[-0.9188108  -0.39469835  1.0031123 ]\n",
            "[-0.9005654  -0.4347206   0.87976927]\n",
            "[-0.89286304 -0.4503283   0.34810004]\n",
            "[-0.8945955  -0.44687682 -0.07723717]\n",
            "[-0.8976706  -0.440667   -0.13859145]\n",
            "[-0.90504235 -0.42532146 -0.34049028]\n",
            "[-0.91603744 -0.4010927  -0.532153  ]\n",
            "[-0.93479395 -0.35519052 -0.991831  ]\n",
            "[-0.9515223 -0.3075798 -1.009388 ]\n",
            "[-0.9720325  -0.23484641 -1.5117579 ]\n",
            "[-0.9878148  -0.15563414 -1.6158236 ]\n",
            "[-0.99773234 -0.06730692 -1.7782308 ]\n",
            "[-0.9996386   0.02688192 -1.88486   ]\n",
            "[-0.99328184  0.11572039 -1.7819015 ]\n",
            "[-0.9786884  0.2053508 -1.816838 ]\n",
            "[-0.9616736   0.27419677 -1.4186448 ]\n",
            "[-0.9390888  0.3436745 -1.461452 ]\n",
            "[-0.9175059   0.39772215 -1.1641177 ]\n",
            "[-0.89801776  0.4399592  -0.9304079 ]\n",
            "[-0.89079434  0.4544067  -0.32305694]\n",
            "[-0.8863107   0.46309105 -0.19546953]\n",
            "[-0.8927281   0.45059577  0.28093967]\n",
            "[-0.9085596   0.41775516  0.7291887 ]\n",
            "[-0.9285725  0.3711512  1.0144938]\n",
            "[-0.9509967  0.309201   1.317914 ]\n",
            "[-0.97446203  0.22455232  1.7573831 ]\n",
            "[-0.99241763  0.1229115   2.0652103 ]\n",
            "[-0.9999768   0.00680828  2.3282952 ]\n",
            "[-0.9946654  -0.10315393  2.2029216 ]\n",
            "[-0.9807495  -0.19527021  1.8639042 ]\n",
            "[-0.9612768  -0.27558458  1.6532965 ]\n",
            "[-0.9377526 -0.347304   1.5099363]\n",
            "[-0.9185565  -0.39528972  1.0337726 ]\n",
            "[-0.90642613 -0.4223644   0.59338   ]\n",
            "[-0.9022975  -0.43111393  0.19349478]\n",
            "[-0.898838   -0.43828103  0.15916762]\n",
            "[-0.8982003  -0.43958643  0.02905665]\n",
            "[-0.9073108  -0.42046067 -0.4237041 ]\n",
            "[-0.91683185 -0.3992735  -0.46457285]\n",
            "[-0.9269059  -0.37529382 -0.52021176]\n",
            "[-0.93744326 -0.3481381  -0.5825907 ]\n",
            "[-0.9490934  -0.31499475 -0.70266193]\n",
            "[-0.9609565  -0.27669936 -0.801869  ]\n",
            "[-0.97334516 -0.22934505 -0.97905844]\n",
            "[-0.98660773 -0.16311091 -1.3512353 ]\n",
            "[-0.99656534 -0.08280991 -1.6187627 ]\n",
            "[-0.9999504  -0.00995935 -1.4589067 ]\n",
            "[-0.997472    0.07106058 -1.6216009 ]\n",
            "[-0.9890944   0.14728309 -1.5340062 ]\n",
            "[-0.9741033  0.2261036 -1.6050998]\n",
            "[-0.95745414  0.28858545 -1.2934654 ]\n",
            "[-0.9373486  0.3483928 -1.2621368]\n",
            "[-0.92444146  0.38132405 -0.70744437]\n",
            "[-0.9117265   0.4107978  -0.64201564]\n",
            "[-0.91006047  0.41447556 -0.0807503 ]\n",
            "[-0.913178    0.40756088  0.15169987]\n",
            "[-0.9274946   0.37383667  0.7327858 ]\n",
            "[-0.94366527  0.33090162  0.9176664 ]\n",
            "[-0.9597359   0.28090397  1.0504597 ]\n",
            "[-0.9722783   0.23382673  0.9744839 ]\n",
            "[-0.98624015  0.1653191   1.3986021 ]\n",
            "In episode 1\n",
            "[-0.99680704  0.07984781  1.7229731 ]\n",
            "[-0.9999764  -0.00687155  1.7360902 ]\n",
            "[-0.994148   -0.10802632  2.0273187 ]\n",
            "[-0.9802107  -0.19795696  1.8207132 ]\n",
            "[-0.9602093  -0.27928144  1.6754501 ]\n",
            "[-0.93532455 -0.3537909   1.5715067 ]\n",
            "[-0.9080902 -0.4187747  1.4094905]\n",
            "[-0.88826233 -0.45933652  0.90305114]\n",
            "[-0.87021893 -0.49266517  0.75803286]\n",
            "[-0.8613702 -0.5079777  0.3537129]\n",
            "[-0.8572262 -0.51494    0.1620452]\n",
            "[-0.86312085 -0.5049974  -0.23117492]\n",
            "[-0.88303834 -0.46930087 -0.81760067]\n",
            "[-0.91321695 -0.40747365 -1.3762591 ]\n",
            "[-0.94097185 -0.33848482 -1.4875946 ]\n",
            "[-0.96925104 -0.24607393 -1.9335735 ]\n",
            "[-0.9893822  -0.14533716 -2.0554757 ]\n",
            "[-0.9996272  -0.02730456 -2.370916  ]\n",
            "[-0.995205    0.09781106 -2.505513  ]\n",
            "[-0.9742618  0.2254193 -2.588114 ]\n",
            "[-0.93965703  0.34211794 -2.4359307 ]\n",
            "[-0.8906516   0.45468637 -2.4570026 ]\n",
            "[-0.84315294  0.53767383 -1.9131144 ]\n",
            "[-0.79908586  0.6012169  -1.5469465 ]\n",
            "[-0.7659991   0.64284164 -1.0635833 ]\n",
            "[-0.7395249  0.6731292 -0.8045957]\n",
            "[-0.73896396  0.673745   -0.01665967]\n",
            "[-0.75689733  0.6535338   0.5404233 ]\n",
            "[-0.7846938   0.6198836   0.87299114]\n",
            "[-0.82581913  0.5639351   1.3890232 ]\n",
            "[-0.874549    0.48493722  1.8570355 ]\n",
            "[-0.92358345  0.38339746  2.2563865 ]\n",
            "[-0.9676057  0.2524663  2.7648757]\n",
            "[-0.99497074  0.10016591  3.097882  ]\n",
            "[-0.9990379  -0.04385433  2.884051  ]\n",
            "[-0.980142   -0.19829698  3.1150339 ]\n",
            "[-0.9430065 -0.3327742  2.792477 ]\n",
            "[-0.8983654  -0.43924895  2.3103712 ]\n",
            "[-0.84318197 -0.5376283   2.2571864 ]\n",
            "[-0.7943293  -0.60748744  1.7054363 ]\n",
            "[-0.7490106 -0.662558   1.4267035]\n",
            "[-0.7150417  -0.69908184  0.9976761 ]\n",
            "[-0.7020587  -0.7121191   0.36798862]\n",
            "[-0.71046925 -0.70372826 -0.23760927]\n",
            "[-0.7327925  -0.68045217 -0.64504164]\n",
            "[-0.7762994  -0.63036436 -1.3271399 ]\n",
            "[-0.8377634 -0.5460334 -2.0880067]\n",
            "[-0.90114796 -0.43351164 -2.584723  ]\n",
            "[-0.95876324 -0.284206   -3.2041564 ]\n",
            "[-0.99406534 -0.10878452 -3.583559  ]\n",
            "[-0.9973626   0.07257968 -3.6328757 ]\n",
            "[-0.967267    0.25376102 -3.6784601 ]\n",
            "[-0.9118968   0.41041955 -3.3269508 ]\n",
            "[-0.83194274  0.55486155 -3.3056483 ]\n",
            "[-0.73706895  0.67581755 -3.077536  ]\n",
            "[-0.6386837  0.7694694 -2.7187328]\n",
            "[-0.55306256  0.8331397  -2.1350129 ]\n",
            "[-0.48819217  0.87273616 -1.5203722 ]\n",
            "[-0.4469187   0.8945746  -0.93398345]\n",
            "[-0.43649432  0.899707   -0.23238839]\n",
            "[-0.46950492  0.88292986  0.7406289 ]\n",
            "[-0.5398926   0.84173393  1.6315911 ]\n",
            "[-0.6226859  0.7824719  2.0372226]\n",
            "[-0.7160022   0.69809794  2.517762  ]\n",
            "[-0.81916606  0.5735564   3.2379358 ]\n",
            "[-0.9111068  0.4121703  3.7201195]\n",
            "[-0.9759039   0.21820067  4.09729   ]\n",
            "[-0.99983424  0.01820663  4.035254  ]\n",
            "[-0.9806467  -0.19578546  4.3053193 ]\n",
            "[-0.9153307  -0.40270293  4.348191  ]\n",
            "[-0.8139257  -0.58096904  4.1090164 ]\n",
            "[-0.68571544 -0.72786975  3.905829  ]\n",
            "[-0.56066847 -0.82804036  3.2078652 ]\n",
            "[-0.45956555 -0.88814384  2.3537385 ]\n",
            "[-0.38619986 -0.92241514  1.6199545 ]\n",
            "[-0.34671363 -0.93797106  0.84886265]\n",
            "[-0.3313743  -0.9434994   0.32610634]\n",
            "[-0.35607946 -0.9344557  -0.52618384]\n",
            "[-0.40465012 -0.91447157 -1.050544  ]\n",
            "[-0.48613042 -0.8738863  -1.8212011 ]\n",
            "[-0.5833299 -0.8122353 -2.3033233]\n",
            "[-0.68461925 -0.72890085 -2.6251757 ]\n",
            "[-0.7869499 -0.6170169 -3.0353754]\n",
            "[-0.87659246 -0.4812335  -3.2577004 ]\n",
            "[-0.95024085 -0.3115162  -3.7054625 ]\n",
            "[-0.99211097 -0.12536263 -3.8218975 ]\n",
            "[-0.9967755   0.08024105 -4.120415  ]\n",
            "[-0.9629995  0.2695031 -3.8509912]\n",
            "[-0.8983711   0.43923727 -3.63745   ]\n",
            "[-0.82011056  0.57220507 -3.088853  ]\n",
            "[-0.7290576   0.68445235 -2.893203  ]\n",
            "[-0.64697564  0.76251066 -2.2666528 ]\n",
            "[-0.57639456  0.8171715  -1.7860343 ]\n",
            "[-0.52926445  0.8484569  -1.1315264 ]\n",
            "[-0.5142491   0.8576409  -0.35203102]\n",
            "[-0.5326297   0.84634835  0.4314578 ]\n",
            "[-0.5745753  0.8184517  1.0076087]\n",
            "[-0.642749   0.7660768  1.7199233]\n",
            "[-0.7226809  0.6911818  2.191839 ]\n",
            "[-0.80302215  0.5959492   2.4935184 ]\n",
            "In episode 2\n",
            "[-0.88280004  0.46974897  2.9888146 ]\n",
            "[-0.95163643  0.30722654  3.5345836 ]\n",
            "[-0.9914539  0.1304578  3.6289303]\n",
            "[-0.9985839  -0.05319903  3.6810975 ]\n",
            "[-0.97349256 -0.22871873  3.5507433 ]\n",
            "[-0.91532576 -0.4027142   3.6743774 ]\n",
            "[-0.83047575 -0.55705476  3.5270987 ]\n",
            "[-0.7414174 -0.6710441  2.8956206]\n",
            "[-0.65190536 -0.75830036  2.5017161 ]\n",
            "[-0.56455594 -0.8253948   2.2039847 ]\n",
            "[-0.49870458 -0.86677206  1.555831  ]\n",
            "[-0.4522484 -0.891892   1.0563786]\n",
            "[-0.4409263  -0.8975433   0.25308362]\n",
            "[-0.46430618 -0.8856748  -0.5244115 ]\n",
            "[-0.5168954 -0.8560486 -1.2073852]\n",
            "[-0.59516364 -0.80360454 -1.8849785 ]\n",
            "[-0.6890843 -0.7246812 -2.4551084]\n",
            "[-0.78496    -0.61954653 -2.8481364 ]\n",
            "[-0.881547   -0.47209635 -3.5299504 ]\n",
            "[-0.9548553  -0.29707122 -3.800868  ]\n",
            "[-0.9962208  -0.08685645 -4.293158  ]\n",
            "[-0.99185014  0.1274101  -4.294468  ]\n",
            "[-0.9432331  0.3321316 -4.216104 ]\n",
            "[-0.86110747  0.5084229  -3.8957958 ]\n",
            "[-0.75771165  0.6525895  -3.5528922 ]\n",
            "[-0.6566855  0.7541646 -2.867681 ]\n",
            "[-0.57346916  0.81922716 -2.1136208 ]\n",
            "[-0.4999598   0.86604863 -1.7436384 ]\n",
            "[-0.44292575  0.8965583  -1.2938597 ]\n",
            "[-0.42422953  0.9055547  -0.41496918]\n",
            "[-0.42453954  0.9054094   0.00684678]\n",
            "[-0.45653164  0.8897072   0.7127943 ]\n",
            "[-0.5217566  0.8530944  1.4963161]\n",
            "[-0.6160814  0.7876825  2.2969873]\n",
            "[-0.7151837  0.6989366  2.6625748]\n",
            "[-0.8243275  0.5661132  3.442529 ]\n",
            "[-0.916384   0.4003004  3.7987673]\n",
            "[-0.9794012   0.20192412  4.170451  ]\n",
            "[-0.9999757  -0.00697074  4.205858  ]\n",
            "[-0.9791341  -0.20321536  3.953398  ]\n",
            "[-0.9287582  -0.37068608  3.5021389 ]\n",
            "[-0.8602377  -0.50989324  3.1062605 ]\n",
            "[-0.78282696 -0.6222395   2.7307913 ]\n",
            "[-0.7104037 -0.7037944  2.182489 ]\n",
            "[-0.6585081 -0.7525736  1.4247395]\n",
            "[-0.6223112  -0.78277     0.94285744]\n",
            "[-0.61318296 -0.7899409   0.23216179]\n",
            "[-0.6186383  -0.78567594 -0.13849235]\n",
            "[-0.64548    -0.7637772  -0.69286436]\n",
            "[-0.7003989 -0.7137516 -1.4860942]\n",
            "[-0.76747024 -0.6410846  -1.9785886 ]\n",
            "[-0.8348997 -0.5504021 -2.2612972]\n",
            "[-0.90028137 -0.43530843 -2.649299  ]\n",
            "[-0.95497537 -0.29668507 -2.9832253 ]\n",
            "[-0.9889612  -0.14817454 -3.0499477 ]\n",
            "[-0.9998559   0.01697666 -3.313993  ]\n",
            "[-0.98282963  0.18451537 -3.3720253 ]\n",
            "[-0.93530226  0.35384986 -3.522107  ]\n",
            "[-0.8703665   0.49240446 -3.063322  ]\n",
            "[-0.79372865  0.608272   -2.7806308 ]\n",
            "[-0.7115018  0.7026843 -2.5056295]\n",
            "[-0.6360809   0.77162236 -2.0444915 ]\n",
            "[-0.5671746   0.82359755 -1.7267454 ]\n",
            "[-0.5094728   0.86048675 -1.3699853 ]\n",
            "[-0.4874512  0.8731502 -0.5080743]\n",
            "[-0.49061403  0.871377    0.07252031]\n",
            "[-0.51910233  0.8547121   0.66012126]\n",
            "[-0.57472515  0.8183465   1.3293576 ]\n",
            "[-0.64561284  0.7636649   1.7911452 ]\n",
            "[-0.73419434  0.67893934  2.4530761 ]\n",
            "[-0.82704014  0.56214285  2.98685   ]\n",
            "[-0.9084261  0.4180455  3.3136363]\n",
            "[-0.9663618  0.2571864  3.4236634]\n",
            "[-0.9967227   0.08089424  3.5825365 ]\n",
            "[-0.9942313 -0.1072574  3.7689369]\n",
            "[-0.9557255 -0.2942597  3.8243344]\n",
            "[-0.88255644 -0.4702065   3.816878  ]\n",
            "[-0.7910104  -0.61180276  3.3762581 ]\n",
            "[-0.68306273 -0.73035973  3.2102156 ]\n",
            "[-0.588246  -0.808682   2.4611952]\n",
            "[-0.51384443 -0.8578834   1.7845608 ]\n",
            "[-0.4582449 -0.888826   1.2728115]\n",
            "[-0.42518562 -0.9051062   0.7370516 ]\n",
            "[-0.42383552 -0.9057392   0.02982239]\n",
            "[-0.44723752 -0.8944152  -0.5199706 ]\n",
            "[-0.50187975 -0.86493737 -1.241927  ]\n",
            "[-0.5868384  -0.80970407 -2.0275588 ]\n",
            "[-0.69772494 -0.71636575 -2.901362  ]\n",
            "[-0.81431043 -0.5804296  -3.5864685 ]\n",
            "[-0.90790504 -0.41917595 -3.734373  ]\n",
            "[-0.97570574 -0.21908516 -4.233215  ]\n",
            "[-9.9999720e-01 -2.3674485e-03 -4.3701859e+00]\n",
            "[-0.9746369   0.22379206 -4.5614185 ]\n",
            "[-0.9068551  0.4214425 -4.1866384]\n",
            "[-0.80734307  0.59008235 -3.922508  ]\n",
            "[-0.6863132  0.7273061 -3.6645555]\n",
            "[-0.57262516  0.8198173  -2.9340665 ]\n",
            "[-0.47778735  0.87847555 -2.2314036 ]\n",
            "[-0.4147687  0.9099269 -1.4089129]\n",
            "[-0.39375967  0.9192134  -0.45940912]\n",
            "In episode 3\n",
            "[-0.40542156  0.91412985  0.25443614]\n",
            "[-0.43736586  0.89928365  0.7045502 ]\n",
            "[-0.5013261   0.86525846  1.4492644 ]\n",
            "[-0.5936388   0.80473167  2.208848  ]\n",
            "[-0.7039827  0.7102171  2.9083343]\n",
            "[-0.8152018   0.57917696  3.4417565 ]\n",
            "[-0.9146381   0.40427363  4.0306845 ]\n",
            "[-0.9782573   0.20739484  4.1454678 ]\n",
            "[-9.9999571e-01 -2.9294945e-03  4.2368126e+00]\n",
            "[-0.98012793 -0.19836646  3.9352295 ]\n",
            "[-0.92328036 -0.38412675  3.8914173 ]\n",
            "[-0.84107625 -0.54091656  3.5452924 ]\n",
            "[-0.7453386 -0.6666861  3.1645455]\n",
            "[-0.6580228 -0.752998   2.4570522]\n",
            "[-0.58611465 -0.8102281   1.8386976 ]\n",
            "[-0.5456494  -0.8380135   0.98182505]\n",
            "[-0.5423954  -0.84012336  0.07756168]\n",
            "[-0.57381    -0.81898844 -0.7572922 ]\n",
            "[-0.6211369 -0.7837021 -1.1808429]\n",
            "[-0.6895568 -0.7242316 -1.8136871]\n",
            "[-0.77935356 -0.6265845  -2.6551306 ]\n",
            "[-0.86221164 -0.5065482  -2.9197245 ]\n",
            "[-0.929333   -0.36924285 -3.0596504 ]\n",
            "[-0.9749423  -0.22245766 -3.0771918 ]\n",
            "[-0.99815804 -0.06066703 -3.2726054 ]\n",
            "[-0.995796    0.09159866 -3.0486307 ]\n",
            "[-0.9682954   0.24980797 -3.215094  ]\n",
            "[-0.91571474  0.40182894 -3.220626  ]\n",
            "[-0.84648514  0.53241235 -2.958692  ]\n",
            "[-0.7786111   0.62750673 -2.3379798 ]\n",
            "[-0.7236984   0.69011647 -1.6660618 ]\n",
            "[-0.6732999  0.7393695 -1.4096706]\n",
            "[-0.63653004  0.7712519  -0.97344315]\n",
            "[-0.6274079   0.7786908  -0.23541592]\n",
            "[-0.63548607  0.77211237  0.20835912]\n",
            "[-0.669419    0.74288505  0.89577025]\n",
            "[-0.7114885   0.70269775  1.1637567 ]\n",
            "[-0.77483743  0.63216054  1.8968736 ]\n",
            "[-0.8441682  0.5360784  2.3710742]\n",
            "[-0.91186345  0.41049373  2.8557856 ]\n",
            "[-0.9674138   0.25320074  3.3401613 ]\n",
            "[-0.9960878   0.08836918  3.3500555 ]\n",
            "[-0.99772286 -0.06744715  3.1196597 ]\n",
            "[-0.9744254  -0.22471125  3.1829662 ]\n",
            "[-0.93330884 -0.3590746   2.8125892 ]\n",
            "[-0.8803166 -0.4743866  2.539819 ]\n",
            "[-0.82642096 -0.5630528   2.0761602 ]\n",
            "[-0.7695829 -0.6385468  1.8906685]\n",
            "[-0.7211083  -0.69282234  1.4557406 ]\n",
            "[-0.6879821  -0.7257277   0.93391764]\n",
            "[-0.67899656 -0.73414147  0.24619842]\n",
            "[-0.68912655 -0.724641   -0.2777618 ]\n",
            "[-0.7154491  -0.6986649  -0.73967266]\n",
            "[-0.75667876 -0.6537869  -1.2190275 ]\n",
            "[-0.80688363 -0.5907104  -1.6127857 ]\n",
            "[-0.87024057 -0.492627   -2.3366625 ]\n",
            "[-0.9340046  -0.35726103 -2.9954426 ]\n",
            "[-0.9782337  -0.20750622 -3.126175  ]\n",
            "[-0.9983481  -0.05745485 -3.0307698 ]\n",
            "[-0.9963641   0.08519717 -2.855742  ]\n",
            "[-0.97160864  0.23659386 -3.0711617 ]\n",
            "[-0.9318632   0.36280987 -2.6484556 ]\n",
            "[-0.8882689  0.4593238 -2.1190464]\n",
            "[-0.83621514  0.54840153 -2.0643544 ]\n",
            "[-0.7929192  0.6093268 -1.4951956]\n",
            "[-0.75893867  0.6511621  -1.0780675 ]\n",
            "[-0.74829334  0.663368   -0.32392168]\n",
            "[-0.7472558   0.6645365  -0.03125192]\n",
            "[-0.75426817  0.65656644  0.21231651]\n",
            "[-0.783271    0.62168044  0.90742457]\n",
            "[-0.82160926  0.5700511   1.286365  ]\n",
            "[-0.87318575  0.48738754  1.9494534 ]\n",
            "[-0.91918117  0.393835    2.0859056 ]\n",
            "[-0.962428    0.27153715  2.5962052 ]\n",
            "[-0.99274004  0.12027982  3.0883617 ]\n",
            "[-0.9992873  -0.03774748  3.166564  ]\n",
            "[-0.9832486  -0.18226947  2.910753  ]\n",
            "[-0.94391483 -0.33018905  3.0641954 ]\n",
            "[-0.8863976  -0.46292472  2.895761  ]\n",
            "[-0.82243365 -0.56886107  2.4765687 ]\n",
            "[-0.7691545 -0.6390629  1.7631786]\n",
            "[-0.73262846 -0.6806288   1.1068252 ]\n",
            "[-0.7122485  -0.70192736  0.5895884 ]\n",
            "[-0.71148217 -0.70270413  0.02182283]\n",
            "[-0.7336599  -0.6795168  -0.64174587]\n",
            "[-0.7647641  -0.6443105  -0.93965036]\n",
            "[-0.81269926 -0.5826833  -1.5618945 ]\n",
            "[-0.86062145 -0.5092453  -1.7543792 ]\n",
            "[-0.9130812  -0.40777776 -2.2857733 ]\n",
            "[-0.95958847 -0.28140718 -2.6951745 ]\n",
            "[-0.98893744 -0.14833315 -2.7275534 ]\n",
            "[-0.99980533 -0.01973208 -2.582984  ]\n",
            "[-0.9929742  0.1183309 -2.766843 ]\n",
            "[-0.96491414  0.2625657  -2.9414287 ]\n",
            "[-0.91946214  0.39317855 -2.7681155 ]\n",
            "[-0.86653715  0.49911258 -2.369767  ]\n",
            "[-0.8157472   0.57840866 -1.8840433 ]\n",
            "[-0.7769098   0.62961185 -1.2855399 ]\n",
            "[-0.7576529   0.65265775 -0.60066974]\n",
            "[-0.7621555   0.647394    0.13853608]\n",
            "In episode 4\n",
            "[-0.7838909   0.62089854  0.68543476]\n",
            "[-0.81629     0.57764226  1.0810215 ]\n",
            "[-0.858048   0.5135694  1.5299566]\n",
            "[-0.9018357   0.43207923  1.8508503 ]\n",
            "[-0.94668907  0.3221487   2.3759742 ]\n",
            "[-0.9805367   0.19633585  2.607574  ]\n",
            "[-0.99842685  0.05606955  2.8304133 ]\n",
            "[-0.99699914 -0.0774126   2.671782  ]\n",
            "[-0.9782119  -0.20760901  2.6327991 ]\n",
            "[-0.9474597  -0.31987515  2.3293526 ]\n",
            "[-0.9044069  -0.42667097  2.3042188 ]\n",
            "[-0.85124546 -0.5247677   2.2326708 ]\n",
            "[-0.80234706 -0.5968577   1.7427365 ]\n",
            "[-0.767507   -0.64104056  1.1254853 ]\n",
            "[-0.7497092 -0.6617675  0.5464109]\n",
            "[-0.7403037 -0.6722726  0.2820105]\n",
            "[-0.74656713 -0.66531014 -0.18730451]\n",
            "[-0.7629841  -0.64641726 -0.5005963 ]\n",
            "[-0.7956498 -0.6057569 -1.0432506]\n",
            "[-0.84218293 -0.53919184 -1.6247911 ]\n",
            "[-0.88708943 -0.46159762 -1.7936381 ]\n",
            "[-0.9322925 -0.3617052 -2.1939807]\n",
            "[-0.9663736  -0.25714213 -2.2006516 ]\n",
            "[-0.9888006  -0.14924273 -2.2052264 ]\n",
            "[-0.9993394  -0.03634154 -2.2690568 ]\n",
            "[-0.9974022   0.07203367 -2.1689131 ]\n",
            "[-0.9838554   0.17896514 -2.1567678 ]\n",
            "[-0.96240216  0.27162862 -1.9030077 ]\n",
            "[-0.93114746  0.3646428  -1.9632856 ]\n",
            "[-0.8931232   0.44981214 -1.8661166 ]\n",
            "[-0.85097575  0.52520496 -1.7280189 ]\n",
            "[-0.8156509  0.5785444 -1.2797403]\n",
            "[-0.7885206   0.61500835 -0.9090721 ]\n",
            "[-0.77105975  0.63676286 -0.55792093]\n",
            "[-0.76122624  0.64848644 -0.3060357 ]\n",
            "[-0.7750025   0.6319582   0.43034124]\n",
            "[-0.80376196  0.59495103  0.93745255]\n",
            "[-0.8439239   0.53646284  1.4192908 ]\n",
            "[-0.8862709   0.46316725  1.6934922 ]\n",
            "[-0.9233386  0.3839868  1.7491062]\n",
            "[-0.95708793  0.2897977   2.0018957 ]\n",
            "[-0.98115623  0.19321616  1.9915289 ]\n",
            "[-0.99515486  0.09832015  1.9191954 ]\n",
            "[-0.9999908   0.00428078  1.8839692 ]\n",
            "[-0.99609864 -0.08824658  1.8528461 ]\n",
            "[-0.9835479 -0.1806473  1.8656605]\n",
            "[-0.96127284 -0.27559844  1.9513531 ]\n",
            "[-0.932219   -0.36189458  1.8217447 ]\n",
            "[-0.90758437 -0.4198698   1.2600485 ]\n",
            "[-0.8804677  -0.47410607  1.2129322 ]\n",
            "[-0.8569401 -0.515416   0.9508912]\n",
            "[-0.84060925 -0.541642    0.6179249 ]\n",
            "[-0.8390172  -0.5441049   0.05865184]\n",
            "[-0.8447516  -0.5351586  -0.21252833]\n",
            "[-0.8675071  -0.4974248  -0.88135433]\n",
            "[-0.895213   -0.44563854 -1.174806  ]\n",
            "[-0.9293361  -0.36923495 -1.6740355 ]\n",
            "[-0.95983756 -0.28055635 -1.876239  ]\n",
            "[-0.98453975 -0.17516121 -2.1660838 ]\n",
            "[-0.9985288  -0.05422455 -2.4363673 ]\n",
            "[-0.9966364   0.08195087 -2.7258806 ]\n",
            "[-0.97540224  0.22043249 -2.8042994 ]\n",
            "[-0.9413642  0.3373921 -2.4377465]\n",
            "[-0.89940625  0.4371137  -2.1648378 ]\n",
            "[-0.8563668   0.51636803 -1.8043458 ]\n",
            "[-0.81482834  0.5797023  -1.5151796 ]\n",
            "[-0.7888239   0.6146193  -0.87079895]\n",
            "[-0.771365    0.636393   -0.55819654]\n",
            "[-0.7663477   0.642426   -0.15693311]\n",
            "[-0.77964514  0.62622154  0.41924834]\n",
            "[-0.8105209   0.58570975  1.0188372 ]\n",
            "[-0.84552854  0.53393024  1.2502686 ]\n",
            "[-0.8861832  0.463335   1.6297437]\n",
            "[-0.92353946  0.38350347  1.7633604 ]\n",
            "[-0.9570115   0.29004997  1.986156  ]\n",
            "[-0.98360574  0.1803323   2.2590952 ]\n",
            "[-0.99736434  0.07255614  2.1740866 ]\n",
            "[-0.9991756  -0.04059622  2.2645466 ]\n",
            "[-0.99033123 -0.138723    1.971289  ]\n",
            "[-0.9701981  -0.24231319  2.111551  ]\n",
            "[-0.9459103 -0.3244283  1.7131577]\n",
            "[-0.9146243  -0.40430486  1.7162285 ]\n",
            "[-0.89004886 -0.45586511  1.1425052 ]\n",
            "[-0.8655104 -0.5008909  1.0256778]\n",
            "[-0.8446135  -0.53537655  0.806514  ]\n",
            "[-0.8403481  -0.5420471   0.15835296]\n",
            "[-0.8451909  -0.53446454 -0.17994246]\n",
            "[-0.86785805 -0.49681222 -0.87904626]\n",
            "[-0.9033236 -0.4289598 -1.5316169]\n",
            "[-0.9350572  -0.35449684 -1.6193    ]\n",
            "[-0.96318144 -0.26885223 -1.8034941 ]\n",
            "[-0.98535985 -0.17048742 -2.0175376 ]\n",
            "[-0.9981561  -0.06069977 -2.211744  ]\n",
            "[-0.99881625  0.04864231 -2.1879725 ]\n",
            "[-0.9888002   0.14924517 -2.0228667 ]\n",
            "[-0.97063816  0.2405442  -1.8624325 ]\n",
            "[-0.94580775  0.32472703 -1.7559326 ]\n",
            "[-0.9210116   0.38953507 -1.3880728 ]\n",
            "[-0.90222114  0.43127373 -0.9155465 ]\n",
            "[-0.8899551  0.4560482 -0.552912 ]\n",
            "In episode 5\n",
            "[-0.87945765  0.47597718 -0.45050326]\n",
            "[-0.8754581   0.48329392 -0.16677031]\n",
            "[-0.8809903   0.47313434  0.23136444]\n",
            "[-0.89755684  0.4408988   0.7249061 ]\n",
            "[-0.92417943  0.38195863  1.2937027 ]\n",
            "[-0.9555804   0.29473057  1.8548225 ]\n",
            "[-0.9822237   0.18771431  2.20678   ]\n",
            "[-0.99784577  0.06560343  2.4636798 ]\n",
            "[-0.99733716 -0.07292903  2.7728882 ]\n",
            "[-0.9780369  -0.20843202  2.7395532 ]\n",
            "[-0.945794  -0.3247673  2.4158833]\n",
            "[-0.9074093 -0.420248   2.0590587]\n",
            "[-0.86238337 -0.5062558   1.9423791 ]\n",
            "[-0.81756103 -0.57584196  1.6559218 ]\n",
            "[-0.7796786  -0.62617993  1.2602063 ]\n",
            "[-0.75337416 -0.65759206  0.8194827 ]\n",
            "[-0.7373953  -0.6754614   0.47944367]\n",
            "[-0.7384691  -0.6742873  -0.03182173]\n",
            "[-0.7586207  -0.6515326  -0.60792583]\n",
            "[-0.7971629  -0.60376424 -1.2277623 ]\n",
            "[-0.84463084 -0.53534913 -1.6658744 ]\n",
            "[-0.89578384 -0.44449    -2.0863252 ]\n",
            "[-0.944961   -0.32718292 -2.5456789 ]\n",
            "[-0.9805628  -0.19620553 -2.716683  ]\n",
            "[-0.99779207 -0.06641491 -2.620458  ]\n",
            "[-0.9974412   0.07149235 -2.7603445 ]\n",
            "[-0.9770886   0.21283303 -2.8584023 ]\n",
            "[-0.9349976   0.35465392 -2.961408  ]\n",
            "[-0.87877446  0.47723734 -2.6992872 ]\n",
            "[-0.81901544  0.5737715  -2.2719018 ]\n",
            "[-0.7623453  0.6471705 -1.8552728]\n",
            "[-0.7239532  0.6898491 -1.1482718]\n",
            "[-0.69558597  0.71844286 -0.80561054]\n",
            "[-0.69406     0.7199171  -0.04243544]\n",
            "[-0.7170652  0.6970061  0.6493821]\n",
            "[-0.7623568  0.6471569  1.3472921]\n",
            "[-0.81942296  0.5731893   1.8691285 ]\n",
            "[-0.8788159   0.47716096  2.259428  ]\n",
            "[-0.9328187   0.36034596  2.5756521 ]\n",
            "[-0.9751247   0.22165696  2.9025073 ]\n",
            "[-0.99805766  0.06229717  3.223517  ]\n",
            "[-0.9936257  -0.11272937  3.506141  ]\n",
            "[-0.9570307  -0.28998664  3.6248672 ]\n",
            "[-0.8903177  -0.45533997  3.570823  ]\n",
            "[-0.7966518  -0.60443854  3.5261383 ]\n",
            "[-0.70271116 -0.71147525  2.8506885 ]\n",
            "[-0.6192795 -0.7851706  2.2275245]\n",
            "[-0.5483582 -0.8362435  1.7485011]\n",
            "[-0.49891356 -0.8666518   1.1611    ]\n",
            "[-0.4786612  -0.87799966  0.4643086 ]\n",
            "[-0.47807688 -0.878318    0.01330839]\n",
            "[-0.5104988  -0.8598785  -0.74601847]\n",
            "[-0.5742129 -0.818706  -1.5175539]\n",
            "[-0.64787346 -0.761748   -1.8629394 ]\n",
            "[-0.73582715 -0.67716944 -2.4419577 ]\n",
            "[-0.8344395  -0.55109954 -3.204553  ]\n",
            "[-0.9245197  -0.38113427 -3.8531704 ]\n",
            "[-0.9846796  -0.17437358 -4.315066  ]\n",
            "[-0.9994829   0.03215452 -4.1485925 ]\n",
            "[-0.97515243  0.22153494 -3.8245637 ]\n",
            "[-0.9162504   0.40060607 -3.7757993 ]\n",
            "[-0.8300501   0.55768883 -3.5884118 ]\n",
            "[-0.729827    0.68363184 -3.2225728 ]\n",
            "[-0.63912374  0.76910394 -2.4942095 ]\n",
            "[-0.5543199  0.8323037 -2.1162548]\n",
            "[-0.4849087   0.87456477 -1.6257379 ]\n",
            "[-0.43041286  0.9026321  -1.2261727 ]\n",
            "[-0.4092368   0.9124282  -0.46665335]\n",
            "[-0.40747216  0.9132176  -0.038663  ]\n",
            "[-0.44399142  0.896031    0.80728066]\n",
            "[-0.5158786  0.8566617  1.6396918]\n",
            "[-0.618494    0.78578955  2.495835  ]\n",
            "[-0.73714346  0.6757363   3.2401707 ]\n",
            "[-0.8522409  0.5231495  3.8284154]\n",
            "[-0.9439091   0.33020544  4.2804227 ]\n",
            "[-0.9925681   0.12169085  4.29056   ]\n",
            "[-0.99492264 -0.10064258  4.4561296 ]\n",
            "[-0.94777364 -0.31894383  4.476033  ]\n",
            "[-0.8563589  -0.51638114  4.360095  ]\n",
            "[-0.7381864 -0.6745967  3.9559722]\n",
            "[-0.5995446  -0.80034137  3.7489216 ]\n",
            "[-0.47063518 -0.8823279   3.0584285 ]\n",
            "[-0.3704288  -0.92886084  2.2107983 ]\n",
            "[-0.28574   -0.9583072  1.793842 ]\n",
            "[-0.23288395 -0.97250456  1.094728  ]\n",
            "[-0.22541596 -0.9742626   0.15344289]\n",
            "[-0.25265762 -0.96755576 -0.56112075]\n",
            "[-0.31512636 -0.9490497  -1.3032758 ]\n",
            "[-0.3963727 -0.9180897 -1.7394547]\n",
            "[-0.5082346  -0.86121863 -2.511423  ]\n",
            "[-0.64339113 -0.7655376  -3.3157225 ]\n",
            "[-0.78636205 -0.6177659  -4.1195617 ]\n",
            "[-0.9099435  -0.41473225 -4.764998  ]\n",
            "[-0.9844545  -0.17563981 -5.0218577 ]\n",
            "[-0.99698704  0.077568   -5.084033  ]\n",
            "[-0.9499592  0.3123739 -4.800899 ]\n",
            "[-0.8555616  0.517701  -4.529414 ]\n",
            "[-0.73955095  0.6731006  -3.8846335 ]\n",
            "[-0.6206156   0.78411496 -3.2575085 ]\n",
            "[-0.49875233  0.8667446  -2.9473774 ]\n",
            "In episode 6\n",
            "[-0.38252884  0.9239436  -2.5925388 ]\n",
            "[-0.27994412  0.9600163  -2.1759167 ]\n",
            "[-0.20739697  0.9782569  -1.4964517 ]\n",
            "[-0.17866611  0.9839098  -0.58565474]\n",
            "[-0.1745773   0.98464346 -0.08308252]\n",
            "[-0.21103878  0.97747767  0.74322206]\n",
            "[-0.28278622  0.959183    1.481202  ]\n",
            "[-0.38389498  0.92337674  2.1462626 ]\n",
            "[-0.5197085   0.85434365  3.0499787 ]\n",
            "[-0.6685553  0.7436624  3.715094 ]\n",
            "[-0.8114125  0.5844739  4.286008 ]\n",
            "[-0.9208926  0.3898164  4.4759855]\n",
            "[-0.98741794  0.15813212  4.8326707 ]\n",
            "[-0.9953189  -0.09664518  5.111899  ]\n",
            "[-0.93772227 -0.34738588  5.1597137 ]\n",
            "[-0.8280691 -0.5606261  4.807195 ]\n",
            "[-0.6856672  -0.72791517  4.402694  ]\n",
            "[-0.54233193 -0.8401643   3.6461945 ]\n",
            "[-0.41662657 -0.9090777   2.8695774 ]\n",
            "[-0.3021337  -0.95326555  2.456023  ]\n",
            "[-0.2317661 -0.9727715  1.4607468]\n",
            "[-0.19473396 -0.9808561   0.7581324 ]\n",
            "[-0.18236701 -0.98323053  0.25185814]\n",
            "[-0.21338753 -0.97696763 -0.632955  ]\n",
            "[-0.26699477 -0.96369797 -1.104644  ]\n",
            "[-0.34549072 -0.93842214 -1.6497678 ]\n",
            "[-0.46067578 -0.8875685  -2.5198958 ]\n",
            "[-0.590948   -0.80670965 -3.0695407 ]\n",
            "[-0.7251802 -0.6885591 -3.5812526]\n",
            "[-0.8445629  -0.53545636 -3.8890443 ]\n",
            "[-0.93745095 -0.34811738 -4.1897173 ]\n",
            "[-0.99206597 -0.12571836 -4.5902047 ]\n",
            "[-0.9953071   0.09676681 -4.4594073 ]\n",
            "[-0.9461027  0.3238668 -4.6579056]\n",
            "[-0.85174716  0.523953   -4.433433  ]\n",
            "[-0.72283745  0.6910181  -4.2282233 ]\n",
            "[-0.5737226  0.8190497 -3.9371219]\n",
            "[-0.43083307  0.90243167 -3.312559  ]\n",
            "[-0.30547953  0.9521986  -2.6994746 ]\n",
            "[-0.2171004   0.97614926 -1.831979  ]\n",
            "[-0.1538365  0.9880963 -1.2878642]\n",
            "[-0.11209305  0.9936977  -0.8424141 ]\n",
            "[-0.10879724  0.994064   -0.06632207]\n",
            "[-0.14536616  0.9893779   0.73740053]\n",
            "[-0.2149254   0.97663045  1.4146477 ]\n",
            "[-0.32593012  0.94539386  2.3075995 ]\n",
            "[-0.47128937  0.88197863  3.1751342 ]\n",
            "[-0.6389615  0.7692387  4.047907 ]\n",
            "[-0.79589385  0.6054362   4.546701  ]\n",
            "[-0.922334   0.3863935  5.0719132]\n",
            "[-0.9934098   0.11461658  5.6369824 ]\n",
            "[-0.98691934 -0.16121496  5.5358124 ]\n",
            "[-0.9105985  -0.41329202  5.2828946 ]\n",
            "[-0.7780177 -0.6282423  5.0645127]\n",
            "[-0.6164205 -0.7874171  4.5463123]\n",
            "[-0.4526678 -0.8916792  3.8886752]\n",
            "[-0.31003666 -0.9507246   3.0904677 ]\n",
            "[-0.20904146 -0.97790676  2.0927384 ]\n",
            "[-0.1538049  -0.98810124  1.1235366 ]\n",
            "[-0.12187686 -0.99254525  0.64474446]\n",
            "[-0.13043617 -0.9914567  -0.17256545]\n",
            "[-0.16813585 -0.98576385 -0.7625879 ]\n",
            "[-0.24202137 -0.97027093 -1.5102065 ]\n",
            "[-0.34038386 -0.9402866  -2.05753   ]\n",
            "[-0.46804318 -0.8837056  -2.7950006 ]\n",
            "[-0.6043891 -0.7966893 -3.2384741]\n",
            "[-0.75327975 -0.65770024 -4.0807157 ]\n",
            "[-0.87925315 -0.4763548  -4.4251494 ]\n",
            "[-0.96381485 -0.26657254 -4.5333824 ]\n",
            "[-0.9991076  -0.04223761 -4.551699  ]\n",
            "[-0.98324543  0.18228655 -4.511233  ]\n",
            "[-0.9230957   0.38457033 -4.228617  ]\n",
            "[-0.8248717   0.56531996 -4.1215754 ]\n",
            "[-0.7064895  0.7077235 -3.7089932]\n",
            "[-0.58739597  0.80929965 -3.1337621 ]\n",
            "[-0.47112593  0.88206595 -2.7454128 ]\n",
            "[-0.3717384  0.9283375 -2.193718 ]\n",
            "[-0.31052652  0.95056474 -1.3026807 ]\n",
            "[-0.2777415   0.96065587 -0.68609136]\n",
            "[-0.28390276  0.95885307  0.12839204]\n",
            "[-0.32622585  0.9452919   0.88892645]\n",
            "[-0.39601684  0.9182432   1.4973345 ]\n",
            "[-0.5021521  0.8647793  2.3782127]\n",
            "[-0.61509186  0.7884554   2.728338  ]\n",
            "[-0.7370632  0.6758238  3.32424  ]\n",
            "[-0.8457448  0.5335876  3.5849   ]\n",
            "[-0.93744206  0.3481413   4.1449842 ]\n",
            "[-0.98926604  0.1461256   4.178739  ]\n",
            "[-0.99756694 -0.06971557  4.328457  ]\n",
            "[-0.9638385  -0.26648688  3.999482  ]\n",
            "[-0.89128035 -0.45345265  4.0177817 ]\n",
            "[-0.7942834  -0.60754746  3.6466763 ]\n",
            "[-0.6938557  -0.72011405  3.0199506 ]\n",
            "[-0.5906324 -0.8069408  2.6997473]\n",
            "[-0.5142168  -0.85766023  1.8349619 ]\n",
            "[-0.46616727 -0.8846966   1.1028122 ]\n",
            "[-0.45257103 -0.89172834  0.30614245]\n",
            "[-0.46182954 -0.8869687  -0.20820694]\n",
            "[-0.4933097  -0.86985373 -0.71667576]\n",
            "[-0.56099164 -0.8278215  -1.5938525 ]\n",
            "In episode 7\n",
            "[-0.6597765  -0.75146186 -2.4987626 ]\n",
            "[-0.76192313 -0.64766747 -2.9151187 ]\n",
            "[-0.8533998  -0.52125686 -3.1239195 ]\n",
            "[-0.9291418 -0.3697235 -3.3922336]\n",
            "[-0.9784143  -0.20665292 -3.4111722 ]\n",
            "[-0.9994467  -0.03326118 -3.4977098 ]\n",
            "[-0.98832244  0.15237702 -3.724805  ]\n",
            "[-0.9495161   0.31371826 -3.3226705 ]\n",
            "[-0.8942838  0.4475003 -2.8972342]\n",
            "[-0.82604456  0.56360483 -2.6955023 ]\n",
            "[-0.74742216  0.6643494  -2.557595  ]\n",
            "[-0.6659712   0.74597746 -2.307566  ]\n",
            "[-0.59820634  0.8013421  -1.7506819 ]\n",
            "[-0.5579462   0.82987714 -0.98703945]\n",
            "[-0.5316941   0.84693646 -0.62618643]\n",
            "[-0.52813447  0.8491608  -0.08394976]\n",
            "[-0.5398883   0.8417367   0.27804652]\n",
            "[-0.5816608   0.81343144  1.0092899 ]\n",
            "[-0.6392602  0.7689905  1.4553366]\n",
            "[-0.72105837  0.6928743   2.2358568 ]\n",
            "[-0.8127863  0.582562   2.8718088]\n",
            "[-0.89548945  0.44508272  3.2122128 ]\n",
            "[-0.95820224  0.28609177  3.4224198 ]\n",
            "[-0.9929589   0.11845926  3.4281514 ]\n",
            "[-0.9989078  -0.04672429  3.3095877 ]\n",
            "[-0.9808206  -0.19491266  2.9885418 ]\n",
            "[-0.9453718 -0.3259941  2.7178936]\n",
            "[-0.89684355 -0.44234794  2.5230381 ]\n",
            "[-0.85026765 -0.5263506   1.9217563 ]\n",
            "[-0.81103456 -0.58499825  1.4115027 ]\n",
            "[-0.7835232  -0.62136257  0.9120515 ]\n",
            "[-0.7724654  -0.6350568   0.35203132]\n",
            "[-0.77156955 -0.63614494  0.02818927]\n",
            "[-0.78181964 -0.6235047  -0.32548153]\n",
            "[-0.81103355 -0.5849996  -0.9667567 ]\n",
            "[-0.84479743 -0.5350863  -1.2053946 ]\n",
            "[-0.8876737 -0.4604731 -1.7216362]\n",
            "[-0.9265422  -0.37619072 -1.8569301 ]\n",
            "[-0.96044403 -0.27847314 -2.0695517 ]\n",
            "[-0.98470736 -0.17421663 -2.1418767 ]\n",
            "[-0.9974227  -0.07174964 -2.0659764 ]\n",
            "[-0.9989358   0.04612144 -2.358983  ]\n",
            "[-0.9863436   0.16470052 -2.3863313 ]\n",
            "[-0.9641832   0.26523715 -2.0599098 ]\n",
            "[-0.93506235  0.3544833  -1.8782313 ]\n",
            "[-0.90927136  0.4162038  -1.3380978 ]\n",
            "[-0.88743997  0.46092328 -0.9953794 ]\n",
            "[-0.8709237  0.4914182 -0.6936424]\n",
            "[-0.86654335  0.49910182 -0.17689084]\n",
            "[-0.8664068   0.49933878 -0.00546963]\n",
            "[-0.87740135  0.47975713  0.44915086]\n",
            "[-0.89987755  0.43614268  0.9814037 ]\n",
            "[-0.92133105  0.38877892  1.0400363 ]\n",
            "[-0.94301     0.33276445  1.2014463 ]\n",
            "[-0.96581286  0.2592402   1.5399631 ]\n",
            "[-0.9869551   0.16099568  2.0107203 ]\n",
            "[-0.99874175  0.05014941  2.230579  ]\n",
            "[-0.9972552 -0.0740412  2.4855897]\n",
            "[-0.9785802  -0.20586616  2.6647944 ]\n",
            "[-0.9471855 -0.3206861  2.3821003]\n",
            "[-0.9014122  -0.43296194  2.4264467 ]\n",
            "[-0.8514421  -0.52444863  2.0858264 ]\n",
            "[-0.8072703 -0.5901819  1.5843341]\n",
            "[-0.77521735 -0.63169456  1.0490617 ]\n",
            "[-0.74747634 -0.6642884   0.8560844 ]\n",
            "[-0.72778934 -0.68580073  0.58323854]\n",
            "[-0.7245156  -0.6892584   0.09523183]\n",
            "[-0.74446195 -0.6676649  -0.5879453 ]\n",
            "[-0.7753041  -0.63158816 -0.9493549 ]\n",
            "[-0.8162764 -0.5776616 -1.3547785]\n",
            "[-0.86167043 -0.50746834 -1.6723374 ]\n",
            "[-0.91029555 -0.4139589  -2.1089063 ]\n",
            "[-0.9545824 -0.297947  -2.4851518]\n",
            "[-0.9881629  -0.15340848 -2.9704912 ]\n",
            "[-0.99990803 -0.01356344 -2.8090563 ]\n",
            "[-0.99210536  0.12540722 -2.7860427 ]\n",
            "[-0.96630573  0.25739712 -2.6917863 ]\n",
            "[-0.93189037  0.36274007 -2.2175791 ]\n",
            "[-0.89598995  0.44407436 -1.7786871 ]\n",
            "[-0.85680515  0.5156403  -1.6322788 ]\n",
            "[-0.82536983  0.5645924  -1.1636907 ]\n",
            "[-0.804616    0.5937956  -0.71657073]\n",
            "[-0.7984976   0.601998   -0.20466027]\n",
            "[-0.8138307   0.58110213  0.51837325]\n",
            "[-0.84626013  0.53276986  1.1642394 ]\n",
            "[-0.88857144  0.4587383   1.7059108 ]\n",
            "[-0.9327958   0.36040533  2.1574473 ]\n",
            "[-0.9726968   0.23207957  2.6897464 ]\n",
            "[-0.9946967   0.10285183  2.6236207 ]\n",
            "[-0.9993766  -0.03530467  2.7669208 ]\n",
            "[-0.98359054 -0.18041517  2.9219306 ]\n",
            "[-0.95239985 -0.30485156  2.567481  ]\n",
            "[-0.9050445 -0.4253169  2.5905883]\n",
            "[-0.85327905 -0.5214546   2.1848555 ]\n",
            "[-0.8113428 -0.5845707  1.5159217]\n",
            "[-0.78376776 -0.62105405  0.9147195 ]\n",
            "[-0.775933   -0.63081527  0.25033322]\n",
            "[-0.7790617  -0.6269473  -0.09949859]\n",
            "[-0.79060316 -0.6123289  -0.37251216]\n",
            "[-0.81463146 -0.57997894 -0.8060019 ]\n",
            "In episode 8\n",
            "[-0.8538002 -0.5206009 -1.4229653]\n",
            "[-0.89539975 -0.4452632  -1.7217278 ]\n",
            "[-0.931617   -0.36344144 -1.7901782 ]\n",
            "[-0.96198785 -0.27309233 -1.9070638 ]\n",
            "[-0.9864545  -0.16403526 -2.236523  ]\n",
            "[-0.9990157  -0.04435783 -2.4081511 ]\n",
            "[-0.9972095   0.07465416 -2.3819215 ]\n",
            "[-0.98023874  0.19781807 -2.4881563 ]\n",
            "[-0.9504169  0.3109785 -2.3418179]\n",
            "[-0.90765077  0.4197262  -2.338425  ]\n",
            "[-0.8633142  0.5046668 -1.9170462]\n",
            "[-0.8290309  0.5592028 -1.2885585]\n",
            "[-0.7970514   0.60391146 -1.0995117 ]\n",
            "[-0.78380686  0.62100464 -0.43248662]\n",
            "[-0.7832375   0.6217226  -0.01832611]\n",
            "[-0.80132705  0.59822655  0.5930793 ]\n",
            "[-0.8264815   0.56296384  0.8663718 ]\n",
            "[-0.8598653  0.510521   1.2435395]\n",
            "[-0.8992294   0.43747735  1.6599832 ]\n",
            "[-0.93628836  0.3512322   1.8780917 ]\n",
            "[-0.9707165  0.2402281  2.32572  ]\n",
            "[-0.99382037  0.11100037  2.6274247 ]\n",
            "[-0.9998146  -0.01925409  2.6096973 ]\n",
            "[-0.9907072  -0.13601191  2.34359   ]\n",
            "[-0.9671325  -0.25427294  2.4132214 ]\n",
            "[-0.93109393 -0.3647795   2.3260026 ]\n",
            "[-0.89244664 -0.45115295  1.8932165 ]\n",
            "[-0.85719645 -0.5149895   1.4587721 ]\n",
            "[-0.81990206 -0.57250386  1.3712206 ]\n",
            "[-0.8006696  -0.5991062   0.65655696]\n",
            "[-0.80253977 -0.5965986  -0.06256312]\n",
            "[-0.81153005 -0.58431065 -0.30451494]\n",
            "[-0.8398741 -0.5427813 -1.0057054]\n",
            "[-0.88087165 -0.47335523 -1.6129849 ]\n",
            "[-0.92557377 -0.37856737 -2.096958  ]\n",
            "[-0.9640445 -0.2657409 -2.385512 ]\n",
            "[-0.9910303 -0.1336374 -2.6986794]\n",
            "[-0.99997354 -0.00727286 -2.5353096 ]\n",
            "[-0.9944552   0.10516074 -2.2525692 ]\n",
            "[-0.977873    0.20919937 -2.1080122 ]\n",
            "[-0.9535614   0.30119857 -1.9038638 ]\n",
            "[-0.92722034  0.37451625 -1.5585135 ]\n",
            "[-0.8973416   0.44133663 -1.4642533 ]\n",
            "[-0.87715983  0.4801985  -0.87586683]\n",
            "[-0.859679   0.5108347 -0.7054888]\n",
            "[-0.85372895  0.5207177  -0.2307181 ]\n",
            "[-0.8583033   0.5131427   0.17698048]\n",
            "[-0.87292     0.48786342  0.5840379 ]\n",
            "[-0.89810616  0.4397787   1.0857638 ]\n",
            "[-0.9214891   0.38840416  1.1290622 ]\n",
            "[-0.9441103   0.32962984  1.2597531 ]\n",
            "[-0.96577466  0.25938267  1.470571  ]\n",
            "[-0.98452455  0.17524685  1.7245289 ]\n",
            "[-0.9973678   0.07250833  2.0716896 ]\n",
            "[-0.99938697 -0.03500946  2.1517725 ]\n",
            "[-0.9901154  -0.14025499  2.1140466 ]\n",
            "[-0.9712876  -0.23790844  1.989859  ]\n",
            "[-0.94171107 -0.33642277  2.0580752 ]\n",
            "[-0.90532494 -0.4247196   1.91073   ]\n",
            "[-0.8720181  -0.48947367  1.4566787 ]\n",
            "[-0.84087235 -0.5412335   1.2083447 ]\n",
            "[-0.8255774  -0.564289    0.55336833]\n",
            "[-0.8276993  -0.5611718  -0.07541689]\n",
            "[-0.8490222  -0.5283572  -0.78272897]\n",
            "[-0.8832672  -0.46886992 -1.3730705 ]\n",
            "[-0.91524154 -0.40290558 -1.4664326 ]\n",
            "[-0.95097774 -0.3092594  -2.0055027 ]\n",
            "[-0.9768271  -0.21402994 -1.9743103 ]\n",
            "[-0.99385905 -0.11065346 -2.0963624 ]\n",
            "[-0.9999184   0.01277493 -2.473116  ]\n",
            "[-0.99065894  0.1363631  -2.4802802 ]\n",
            "[-0.9702667   0.24203834 -2.1535363 ]\n",
            "[-0.94063157  0.33942938 -2.0368817 ]\n",
            "[-0.9058119  0.42368   -1.8238788]\n",
            "[-0.86473286  0.5022321  -1.7734795 ]\n",
            "[-0.8264711  0.5629792 -1.4361601]\n",
            "[-0.7991477   0.6011347  -0.93868285]\n",
            "[-0.7788509  0.6272091 -0.6608887]\n",
            "[-0.77274334  0.63471866 -0.19359359]\n",
            "[-0.78975874  0.61341757  0.5452727 ]\n",
            "[-0.8277683  0.56107    1.2940565]\n",
            "[-0.8776561  0.4792909  1.9166261]\n",
            "[-0.9252686   0.37931263  2.2158656 ]\n",
            "[-0.9684363   0.24926107  2.7427232 ]\n",
            "[-0.99313104  0.11700755  2.692819  ]\n",
            "[-0.9999281  -0.01199049  2.5853395 ]\n",
            "[-0.99133384 -0.13136667  2.3951337 ]\n",
            "[-0.9699061  -0.24347925  2.2840798 ]\n",
            "[-0.941973  -0.3356887  1.9276966]\n",
            "[-0.90964925 -0.41537723  1.7204233 ]\n",
            "[-0.8828133  -0.46972412  1.2124157 ]\n",
            "[-0.8617687  -0.50730133  0.8614418 ]\n",
            "[-0.8521385  -0.5233163   0.37375554]\n",
            "[-0.84920156 -0.52806884  0.1117349 ]\n",
            "[-0.85304135 -0.5218433  -0.14628913]\n",
            "[-0.86594504 -0.5001392  -0.5050182 ]\n",
            "[-0.8896762 -0.456592  -0.9919739]\n",
            "[-0.91591495 -0.4013724  -1.2229207 ]\n",
            "[-0.9477124  -0.31912565 -1.7641602 ]\n",
            "[-0.9734895  -0.22873156 -1.880645  ]\n",
            "In episode 9\n",
            "[-0.99259657 -0.12145819 -2.1803136 ]\n",
            "[-0.99981415 -0.01927958 -2.0495608 ]\n",
            "[-0.99628085  0.08616517 -2.1110585 ]\n",
            "[-0.9833964   0.18147042 -1.924187  ]\n",
            "[-0.9659145   0.25886124 -1.5872316 ]\n",
            "[-0.94438434  0.3288437  -1.4647167 ]\n",
            "[-0.9180218   0.39652994 -1.4530982 ]\n",
            "[-0.89715534  0.4417152  -0.9955156 ]\n",
            "[-0.8752378   0.48369282 -0.9471888 ]\n",
            "[-0.8579486   0.51373553 -0.69328254]\n",
            "[-0.842668    0.53843355 -0.5808778 ]\n",
            "[-0.84026384  0.54217774 -0.08899272]\n",
            "[-0.8556842  0.5174983  0.5820384]\n",
            "[-0.8777286   0.4791582   0.88458747]\n",
            "[-0.9008363   0.43415892  1.0118202 ]\n",
            "[-0.93199354  0.36247483  1.5636487 ]\n",
            "[-0.9651089   0.26184887  2.1196907 ]\n",
            "[-0.98964626  0.14352812  2.4182377 ]\n",
            "[-0.99956226  0.02958415  2.2887414 ]\n",
            "[-0.9949954  -0.09992038  2.5935173 ]\n",
            "[-0.9760704  -0.21745463  2.3823707 ]\n",
            "[-0.94557196 -0.3254131   2.2448528 ]\n",
            "[-0.90973437 -0.4151908   1.9340787 ]\n",
            "[-0.87247133 -0.48866525  1.6481351 ]\n",
            "[-0.83445215 -0.55108035  1.4619825 ]\n",
            "[-0.8059567 -0.5919745  0.9969621]\n",
            "[-0.7976834  -0.6030764   0.27691394]\n",
            "[-0.810869   -0.5852277  -0.44382668]\n",
            "[-0.8340907  -0.5516273  -0.81693816]\n",
            "[-0.8616853  -0.50744313 -1.0419812 ]\n",
            "[-0.8976071  -0.44079643 -1.5145823 ]\n",
            "[-0.93673706 -0.35003388 -1.97757   ]\n",
            "[-0.9730523  -0.23058434 -2.498582  ]\n",
            "[-0.9955558  -0.09417339 -2.7673006 ]\n",
            "[-0.9982908   0.05844292 -3.0557876 ]\n",
            "[-0.9788363   0.20464493 -2.9524941 ]\n",
            "[-0.9397382   0.34189492 -2.856633  ]\n",
            "[-0.88685936  0.46203944 -2.6272168 ]\n",
            "[-0.8266484   0.56271875 -2.3475513 ]\n",
            "[-0.77283835  0.63460296 -1.7964728 ]\n",
            "[-0.7299346   0.68351704 -1.3015087 ]\n",
            "[-0.69527286  0.7187459  -0.98853505]\n",
            "[-0.6743227   0.73843676 -0.5750465 ]\n",
            "[-0.6722934   0.7402848  -0.05489401]\n",
            "[-0.686315   0.7273044  0.3821548]\n",
            "[-0.7170566   0.697015    0.86319965]\n",
            "[-0.76876885  0.6395267   1.5468733 ]\n",
            "[-0.8313552   0.55574137  2.0925603 ]\n",
            "[-0.8950293  0.4460073  2.5391011]\n",
            "[-0.9540863   0.29953182  3.1619499 ]\n",
            "[-0.9910499   0.13349225  3.4061997 ]\n",
            "[-0.99915814 -0.04102382  3.4985454 ]\n",
            "[-0.9750263  -0.22208941  3.6584308 ]\n",
            "[-0.9222569  -0.38657764  3.4592192 ]\n",
            "[-0.84600043 -0.5331822   3.308795  ]\n",
            "[-0.75362617 -0.6573033   3.097544  ]\n",
            "[-0.6539349  -0.75655085  2.8157523 ]\n",
            "[-0.56252664 -0.8267791   2.3067052 ]\n",
            "[-0.485074  -0.8744731  1.8198173]\n",
            "[-0.4452812  -0.89539075  0.89918995]\n",
            "[-0.4380002  -0.8989749   0.16230777]\n",
            "[-0.44783223 -0.8941176  -0.21932909]\n",
            "[-0.48449278 -0.87479526 -0.8288779 ]\n",
            "[-0.5561626 -0.8310735 -1.6795588]\n",
            "[-0.6428329  -0.76600647 -2.1685922 ]\n",
            "[-0.73471105 -0.6783802  -2.5409966 ]\n",
            "[-0.82522595 -0.56480277 -2.9072294 ]\n",
            "[-0.9050083  -0.42539388 -3.2159429 ]\n",
            "[-0.963824  -0.2665395 -3.391924 ]\n",
            "[-0.99535495 -0.09627344 -3.4675617 ]\n",
            "[-0.99748266  0.07091079 -3.347863  ]\n",
            "[-0.96968585  0.24435507 -3.5176837 ]\n",
            "[-0.9098791   0.41487357 -3.6189864 ]\n",
            "[-0.8245015  0.5658598 -3.473436 ]\n",
            "[-0.73832357  0.67444664 -2.7747867 ]\n",
            "[-0.66558313  0.7463237  -2.046128  ]\n",
            "[-0.611705    0.79108596 -1.4012171 ]\n",
            "[-0.5750874   0.818092   -0.91006184]\n",
            "[-0.5723253   0.8200267  -0.06744556]\n",
            "[-0.58953965  0.80773944  0.42300197]\n",
            "[-0.63404393  0.773297    1.125655  ]\n",
            "[-0.70301574  0.71117425  1.8571527 ]\n",
            "[-0.78816783  0.6154604   2.5639439 ]\n",
            "[-0.8737393   0.48639455  3.1002283 ]\n",
            "[-0.9426408  0.3338089  3.352343 ]\n",
            "[-0.9874027   0.15822767  3.6289186 ]\n",
            "[-0.99964446 -0.02666309  3.711234  ]\n",
            "[-0.978022   -0.20850176  3.6675308 ]\n",
            "[-0.9294677  -0.36890358  3.3557262 ]\n",
            "[-0.8659238 -0.5001759  2.9194555]\n",
            "[-0.78700036 -0.61695254  2.8212528 ]\n",
            "[-0.7142418 -0.699899   2.2078319]\n",
            "[-0.64526725 -0.7639569   1.8833426 ]\n",
            "[-0.58300346 -0.81246966  1.5790519 ]\n",
            "[-0.5485446 -0.8361213  0.835958 ]\n",
            "[-0.5505979  -0.8347706  -0.04915416]\n",
            "[-0.5698451  -0.82175213 -0.46474072]\n",
            "[-0.6131442 -0.789971  -1.0743461]\n",
            "[-0.67410976 -0.7386312  -1.5944834 ]\n",
            "[-0.75857913 -0.65158087 -2.4274187 ]\n",
            "In episode 10\n",
            "[-0.84589267 -0.5333532  -2.9421377 ]\n",
            "[-0.9203728  -0.39104214 -3.2159219 ]\n",
            "[-0.97476745 -0.22322291 -3.5328813 ]\n",
            "[-0.9996728  -0.02557998 -3.9907358 ]\n",
            "[-0.98377365  0.179414   -4.1194706 ]\n",
            "[-0.9261002  0.3772777 -4.129285 ]\n",
            "[-0.84143186  0.54036325 -3.680275  ]\n",
            "[-0.7379752  0.6748279 -3.3972528]\n",
            "[-0.6404873  0.7679687 -2.698645 ]\n",
            "[-0.5443918   0.83883107 -2.3893754 ]\n",
            "[-0.481047   0.8766948 -1.4763058]\n",
            "[-0.45173416  0.8921526  -0.66280854]\n",
            "[-0.44450828  0.8957747  -0.16165821]\n",
            "[-0.46451268  0.8855665   0.4491794 ]\n",
            "[-0.51628053  0.85641956  1.1883585 ]\n",
            "[-0.5882228  0.8086989  1.727147 ]\n",
            "[-0.68239903  0.73097986  2.4436007 ]\n",
            "[-0.77686137  0.62967163  2.7725263 ]\n",
            "[-0.87280774  0.4880642   3.4251997 ]\n",
            "[-0.95131403  0.30822334  3.9309123 ]\n",
            "[-0.99562186  0.0934726   4.3943124 ]\n",
            "[-0.99056864 -0.13701726  4.621178  ]\n",
            "[-0.936607   -0.35038173  4.4105797 ]\n",
            "[-0.8468103  -0.53189504  4.057164  ]\n",
            "[-0.72769356 -0.68590236  3.9001231 ]\n",
            "[-0.5993066 -0.8005196  3.4463744]\n",
            "[-0.47316134 -0.8809758   2.9951768 ]\n",
            "[-0.35389325 -0.9352858   2.6229062 ]\n",
            "[-0.25837263 -0.9660453   2.0078642 ]\n",
            "[-0.19841881 -0.9801173   1.2318571 ]\n",
            "[-0.16688582 -0.9859762   0.64148104]\n",
            "[-0.17134035 -0.9852119  -0.09039252]\n",
            "[-0.20840648 -0.9780423  -0.75510836]\n",
            "[-0.28334978 -0.9590166  -1.5467974 ]\n",
            "[-0.388357  -0.921509  -2.2312546]\n",
            "[-0.52312887 -0.85225356 -3.0334032 ]\n",
            "[-0.67502505 -0.7377948  -3.8096101 ]\n",
            "[-0.810758   -0.58538145 -4.0889444 ]\n",
            "[-0.9202226  -0.39139545 -4.464059  ]\n",
            "[-0.98621017 -0.1654978  -4.7176957 ]\n",
            "[-0.9968061   0.07986012 -4.92416   ]\n",
            "[-0.9504513  0.3108734 -4.723331 ]\n",
            "[-0.8569098   0.51546633 -4.5087996 ]\n",
            "[-0.7232058  0.6906326 -4.4162316]\n",
            "[-0.5844101   0.81145847 -3.6856015 ]\n",
            "[-0.45025957  0.8928977  -3.1419373 ]\n",
            "[-0.3323397   0.94315976 -2.5654562 ]\n",
            "[-0.23729308  0.9714381  -1.9840964 ]\n",
            "[-0.17343861  0.9848447  -1.3051654 ]\n",
            "[-0.14415547  0.98955506 -0.5932128 ]\n",
            "[-0.14114757  0.98998857 -0.06077992]\n",
            "[-0.18937112  0.9819056   0.97802305]\n",
            "[-0.2869567   0.95794356  2.0105352 ]\n",
            "[-0.41068023  0.9117794   2.643032  ]\n",
            "[-0.56103015  0.8277954   3.448594  ]\n",
            "[-0.71703184  0.69704044  4.0780993 ]\n",
            "[-0.8639962  0.5034983  4.8723726]\n",
            "[-0.9640773   0.26562178  5.1758842 ]\n",
            "[-9.9999589e-01  2.8690819e-03  5.3195944e+00]\n",
            "[-0.9642014  -0.26517096  5.425006  ]\n",
            "[-0.86185485 -0.507155    5.269987  ]\n",
            "[-0.719805  -0.6941763  4.7078876]\n",
            "[-0.55511236 -0.83177537  4.3004665 ]\n",
            "[-0.40310267 -0.91515476  3.471868  ]\n",
            "[-0.2624206 -0.9649536  2.9874952]\n",
            "[-0.14058465 -0.9900687   2.4895592 ]\n",
            "[-0.06389651 -0.9979565   1.5422367 ]\n",
            "[-0.01930211 -0.9998137   0.8927352 ]\n",
            "[-0.01878369 -0.9998236   0.01037043]\n",
            "[-0.0632067  -0.99800044 -0.8892814 ]\n",
            "[-0.15041569 -0.98862284 -1.7547973 ]\n",
            "[-0.2727614  -0.96208173 -2.5054674 ]\n",
            "[-0.41980928 -0.9076123  -3.1394613 ]\n",
            "[-0.5916825 -0.8061711 -3.9981818]\n",
            "[-0.7552756 -0.6554073 -4.458606 ]\n",
            "[-0.8881092  -0.45963252 -4.742808  ]\n",
            "[-0.9721104  -0.23452386 -4.817053  ]\n",
            "[-0.999988   0.0048994 -4.832563 ]\n",
            "[-0.97318286  0.23003277 -4.544239  ]\n",
            "[-0.90318686  0.4292476  -4.2309637 ]\n",
            "[-0.80884683  0.5880194  -3.6989677 ]\n",
            "[-0.6999008  0.7142401 -3.3385956]\n",
            "[-0.6005397   0.79959494 -2.6216547 ]\n",
            "[-0.5178039  0.8554993 -1.9978797]\n",
            "[-0.44548723  0.8952883  -1.6512697 ]\n",
            "[-0.38810953  0.9216133  -1.262779  ]\n",
            "[-0.35682687  0.93417054 -0.6742101 ]\n",
            "[-0.34974462  0.93684506 -0.15140922]\n",
            "[-0.3673785   0.93007153  0.37780744]\n",
            "[-0.41456023  0.9100219   1.0254126 ]\n",
            "[-0.49566782  0.8685122   1.822882  ]\n",
            "[-0.6020138  0.7984857  2.5483432]\n",
            "[-0.7110596  0.7031318  2.8996642]\n",
            "[-0.81259423  0.58282983  3.1517107 ]\n",
            "[-0.906574   0.4220468  3.7300992]\n",
            "[-0.9718061  0.2357814  3.9535866]\n",
            "[-0.999046    0.04366983  3.8867764 ]\n",
            "[-0.9862587  -0.16520822  4.193057  ]\n",
            "[-0.92706203 -0.37490803  4.3665686 ]\n",
            "[-0.8266545 -0.5627098  4.2672534]\n",
            "In episode 11\n",
            "[-0.710279   -0.70392025  3.6648319 ]\n",
            "[-0.58147013 -0.81356776  3.3871984 ]\n",
            "[-0.46877182 -0.8833193   2.6526947 ]\n",
            "[-0.3793541 -0.9252516  1.976035 ]\n",
            "[-0.3197144  -0.94751394  1.273401  ]\n",
            "[-0.27885583 -0.960333    0.85651135]\n",
            "[-0.26802152 -0.96341294  0.22527267]\n",
            "[-0.2930112 -0.956109  -0.5207179]\n",
            "[-0.34674945 -0.93795776 -1.1345717 ]\n",
            "[-0.43676862 -0.89957386 -1.9580016 ]\n",
            "[-0.558661  -0.8293961 -2.815341 ]\n",
            "[-0.701106   -0.71305704 -3.6835394 ]\n",
            "[-0.83342904 -0.55262655 -4.1667295 ]\n",
            "[-0.93824744 -0.34596494 -4.644908  ]\n",
            "[-0.99402934 -0.10911282 -4.878731  ]\n",
            "[-0.99202377  0.12605084 -4.714351  ]\n",
            "[-0.93877846  0.34452134 -4.5068364 ]\n",
            "[-0.8519272  0.5236602 -3.988256 ]\n",
            "[-0.7541596   0.65669113 -3.3056233 ]\n",
            "[-0.66234475  0.7491992  -2.608588  ]\n",
            "[-0.584885   0.8111162 -1.9841167]\n",
            "[-0.5203736  0.8539387 -1.5489979]\n",
            "[-0.47199577  0.8816008  -1.1147032 ]\n",
            "[-0.44306153  0.89649117 -0.6508474 ]\n",
            "[-0.4505501   0.89275116  0.16741185]\n",
            "[-0.48246565  0.8759149   0.72172093]\n",
            "[-0.540292   0.8414776  1.3463323]\n",
            "[-0.6168134  0.7871094  1.8780739]\n",
            "[-0.70737994  0.70683354  2.421935  ]\n",
            "[-0.8025195   0.59662586  2.9144337 ]\n",
            "[-0.8879062  0.4600245  3.225346 ]\n",
            "[-0.95251775  0.304483    3.3725443 ]\n",
            "[-0.99112177  0.13295709  3.5208726 ]\n",
            "[-0.9985737  -0.05339068  3.7353606 ]\n",
            "[-0.9700224  -0.24301553  3.8411458 ]\n",
            "[-0.90657604 -0.42204255  3.8044765 ]\n",
            "[-0.8180125 -0.5752005  3.5430403]\n",
            "[-0.7255837  -0.68813396  2.9212978 ]\n",
            "[-0.6317023 -0.7752111  2.562702 ]\n",
            "[-0.54396945 -0.839105    2.1717339 ]\n",
            "[-0.48451543 -0.8747827   1.3870258 ]\n",
            "[-0.45217624 -0.8919286   0.7321076 ]\n",
            "[-0.43737474 -0.89927936  0.3305293 ]\n",
            "[-0.46402395 -0.88582265 -0.5971022 ]\n",
            "[-0.531496  -0.8470608 -1.5566657]\n",
            "[-0.6164196 -0.7874179 -2.0764368]\n",
            "[-0.7189079 -0.6951053 -2.7608473]\n",
            "[-0.82421553 -0.5662762  -3.3317118 ]\n",
            "[-0.9159596  -0.40127057 -3.7815456 ]\n",
            "[-0.9780117 -0.2085498 -4.056233 ]\n",
            "[-9.9999595e-01 -2.8437339e-03 -4.1449633e+00]\n",
            "[-0.97719455  0.21234612 -4.336379  ]\n",
            "[-0.90895194  0.41690084 -4.321157  ]\n",
            "[-0.8135876   0.58144236 -3.8093472 ]\n",
            "[-0.69783115  0.71626234 -3.5586185 ]\n",
            "[-0.57650197  0.81709576 -3.1584764 ]\n",
            "[-0.45978826  0.88802856 -2.733688  ]\n",
            "[-0.36181012  0.9322518  -2.1509588 ]\n",
            "[-0.2848318  0.9585775 -1.627557 ]\n",
            "[-0.24977994  0.9683026  -0.7275594 ]\n",
            "[-0.2640073   0.9645207   0.29443124]\n",
            "[-0.3184875   0.94792706  1.1391784 ]\n",
            "[-0.41158417  0.91137177  2.001163  ]\n",
            "[-0.5268521  0.849957   2.6140208]\n",
            "[-0.65674716  0.7541109   3.2320895 ]\n",
            "[-0.78446823  0.620169    3.7068217 ]\n",
            "[-0.8965509   0.44294068  4.2016416 ]\n",
            "[-0.97244835  0.23311849  4.471854  ]\n",
            "[-0.9999843   0.00559537  4.593758  ]\n",
            "[-0.974249  -0.2254749  4.6605167]\n",
            "[-0.89995897 -0.4359746   4.4738097 ]\n",
            "[-0.7984667 -0.602039   3.898627 ]\n",
            "[-0.67823744 -0.73484284  3.587653  ]\n",
            "[-0.547186   -0.83701104  3.3272564 ]\n",
            "[-0.42742032 -0.90405303  2.7472239 ]\n",
            "[-0.3186028 -0.9478883  2.3476455]\n",
            "[-0.24993563 -0.96826243  1.4328266 ]\n",
            "[-0.22087303 -0.9753026   0.598085  ]\n",
            "[-0.24085528 -0.970561   -0.41074932]\n",
            "[-0.30056903 -0.9537601  -1.2408444 ]\n",
            "[-0.393546  -0.9193049 -1.9839293]\n",
            "[-0.5174037  -0.85574144 -2.786571  ]\n",
            "[-0.66068554 -0.7506628  -3.5583482 ]\n",
            "[-0.7947616  -0.60692173 -3.9376612 ]\n",
            "[-0.9078117  -0.41937798 -4.388432  ]\n",
            "[-0.9781386  -0.20795383 -4.465549  ]\n",
            "[-0.99974555  0.02255737 -4.6408377 ]\n",
            "[-0.9694973   0.24510194 -4.5013113 ]\n",
            "[-0.89255893  0.4509307  -4.40366   ]\n",
            "[-0.7768244   0.62971723 -4.2676272 ]\n",
            "[-0.6449093  0.7642591 -3.77405  ]\n",
            "[-0.52216214  0.85284626 -3.0304093 ]\n",
            "[-0.41464263  0.90998435 -2.4366827 ]\n",
            "[-0.3300563   0.94396126 -1.8237361 ]\n",
            "[-0.27257785  0.9621337  -1.2058383 ]\n",
            "[-0.245896   0.9692962 -0.5525474]\n",
            "[-0.24316718  0.9699844  -0.05628496]\n",
            "[-0.28331068  0.9590282   0.83229524]\n",
            "[-0.3523663  0.9358622  1.4570783]\n",
            "[-0.44445735  0.8958      2.0094004 ]\n",
            "In episode 12\n",
            "[-0.5577435  0.8300134  2.6219256]\n",
            "[-0.6891811   0.72458917  3.3738716 ]\n",
            "[-0.81020606  0.5861451   3.682907  ]\n",
            "[-0.9132773  0.4073383  4.1351004]\n",
            "[-0.97754455  0.21072899  4.144341  ]\n",
            "[-9.9999946e-01  1.0077554e-03  4.2262578e+00]\n",
            "[-0.9802014  -0.19800283  4.006555  ]\n",
            "[-0.92919064 -0.36960074  3.5851862 ]\n",
            "[-0.851676  -0.5240687  3.4608386]\n",
            "[-0.7662142 -0.6425853  2.924927 ]\n",
            "[-0.6921142 -0.721788   2.1702936]\n",
            "[-0.6226243 -0.7825209  1.8464435]\n",
            "[-0.57298744 -0.8195641   1.2389096 ]\n",
            "[-0.54858005 -0.836098    0.58962804]\n",
            "[-0.54585654 -0.83787864  0.06507885]\n",
            "[-0.57788914 -0.81611526 -0.7745757 ]\n",
            "[-0.638156  -0.7699071 -1.519218 ]\n",
            "[-0.72114617 -0.69278294 -2.2670913 ]\n",
            "[-0.8039863  -0.59464777 -2.5702703 ]\n",
            "[-0.88820744 -0.45944262 -3.1891987 ]\n",
            "[-0.95854276 -0.28494874 -3.7682924 ]\n",
            "[-0.9965977  -0.08241949 -4.128797  ]\n",
            "[-0.99158937  0.12942377 -4.246019  ]\n",
            "[-0.9433747   0.33172908 -4.1669607 ]\n",
            "[-0.86025476  0.50986445 -3.9378266 ]\n",
            "[-0.7536738  0.6572487 -3.6427028]\n",
            "[-0.6383178   0.76977295 -3.2264597 ]\n",
            "[-0.5392775  0.8421281 -2.4546413]\n",
            "[-0.46014822  0.8878421  -1.8283362 ]\n",
            "[-0.40026185  0.91640085 -1.3271915 ]\n",
            "[-0.37241378  0.9280668  -0.60388035]\n",
            "[-0.3782212   0.92571527  0.12530987]\n",
            "[-0.42207447  0.90656114  0.9571674 ]\n",
            "[-0.4834852   0.87535256  1.3779889 ]\n",
            "[-0.575119    0.81806976  2.1623561 ]\n",
            "[-0.6809209   0.73235697  2.7253945 ]\n",
            "[-0.79449314  0.6072731   3.3830626 ]\n",
            "[-0.8956743  0.4447107  3.8354516]\n",
            "[-0.97139794  0.23745757  4.42207   ]\n",
            "[-0.99993515  0.01139094  4.567131  ]\n",
            "[-0.978826   -0.20469421  4.3508496 ]\n",
            "[-0.9157704  -0.40170214  4.1444697 ]\n",
            "[-0.8236264 -0.5671328  3.7929127]\n",
            "[-0.7246094 -0.6891598  3.1461694]\n",
            "[-0.63297755 -0.77417016  2.5014832 ]\n",
            "[-0.5483474 -0.8362506  2.1001296]\n",
            "[-0.4836324  -0.87527126  1.5117364 ]\n",
            "[-0.44622853 -0.89491904  0.84506804]\n",
            "[-0.43649453 -0.8997069   0.21695694]\n",
            "[-0.4579845  -0.8889602  -0.48055804]\n",
            "[-0.5180615  -0.85534334 -1.3771286 ]\n",
            "[-0.6086706 -0.793423  -2.1960187]\n",
            "[-0.7196158 -0.6943724 -2.977298 ]\n",
            "[-0.83396745 -0.5518136  -3.6602013 ]\n",
            "[-0.932588   -0.36094272 -4.3051763 ]\n",
            "[-0.99112743 -0.13291506 -4.71938   ]\n",
            "[-0.99285823  0.11929998 -5.0578876 ]\n",
            "[-0.93204653  0.36233866 -5.0238204 ]\n",
            "[-0.81867313  0.5742598  -4.818478  ]\n",
            "[-0.67058045  0.74183685 -4.4821134 ]\n",
            "[-0.5031238  0.8642143 -4.155626 ]\n",
            "[-0.3496971  0.9368628 -3.3992372]\n",
            "[-0.21667275  0.9762443  -2.7768567 ]\n",
            "[-0.1274573   0.99184406 -1.8119999 ]\n",
            "[-0.07980449  0.99681056 -0.9583101 ]\n",
            "[-0.075445    0.99714994 -0.08745377]\n",
            "[-0.12113902  0.99263555  0.91841024]\n",
            "[-0.20751545  0.9782317   1.7519432 ]\n",
            "[-0.32563514  0.9454955   2.4529796 ]\n",
            "[-0.47871155  0.87797225  3.350063  ]\n",
            "[-0.645066    0.76412684  4.0384617 ]\n",
            "[-0.7947049   0.60699594  4.348233  ]\n",
            "[-0.91434467  0.40493688  4.707304  ]\n",
            "[-0.9860927  0.1661962  4.998777 ]\n",
            "[-0.9952765  -0.09708051  5.284092  ]\n",
            "[-0.93133825 -0.36415532  5.509841  ]\n",
            "[-0.80653787 -0.5911825   5.1959686 ]\n",
            "[-0.63454366 -0.772887    5.0170846 ]\n",
            "[-0.44325498 -0.89639556  4.563827  ]\n",
            "[-0.27408984 -0.9617041   3.6316686 ]\n",
            "[-0.12067162 -0.9926925   3.1335354 ]\n",
            "[-0.00367986 -0.9999932   2.345731  ]\n",
            "[ 0.06262941 -0.99803686  1.3270057 ]\n",
            "[ 0.09494014 -0.995483    0.64825845]\n",
            "[ 0.07536534 -0.99715596 -0.39292952]\n",
            "[ 0.0181507  -0.99983525 -1.1457034 ]\n",
            "[-0.07890591 -0.9968821  -1.9427944 ]\n",
            "[-0.20893754 -0.977929   -2.6300075 ]\n",
            "[-0.3731654  -0.92776483 -3.438603  ]\n",
            "[-0.55844384 -0.82954234 -4.2018027 ]\n",
            "[-0.7338027  -0.67936265 -4.6278777 ]\n",
            "[-0.87781674 -0.4789966  -4.947649  ]\n",
            "[-0.97168493 -0.23628037 -5.2195053 ]\n",
            "[-0.9998318  0.0183398 -5.137537 ]\n",
            "[-0.96494627  0.26244742 -4.9443364 ]\n",
            "[-0.8702114   0.49267852 -4.992149  ]\n",
            "[-0.7356352   0.67737794 -4.5805464 ]\n",
            "[-0.5896063  0.8076908 -3.920652 ]\n",
            "[-0.44395828  0.8960475  -3.4111996 ]\n",
            "[-0.31788442  0.9481295  -2.7302804 ]\n",
            "In episode 13\n",
            "[-0.22982289  0.97323245 -1.8320326 ]\n",
            "[-0.18661477  0.98243314 -0.8836089 ]\n",
            "[-0.187566    0.982252    0.01936662]\n",
            "[-0.23421651  0.9721845   0.9545802 ]\n",
            "[-0.3109643  0.9504216  1.5958974]\n",
            "[-0.4055844  0.9140576  2.028212 ]\n",
            "[-0.5340519  0.8454517  2.915357 ]\n",
            "[-0.677299   0.7357078  3.613985 ]\n",
            "[-0.8189852  0.5738146  4.3111033]\n",
            "[-0.92760354  0.3735662   4.5661077 ]\n",
            "[-0.9890384   0.14765862  4.6930017 ]\n",
            "[-0.99538493 -0.09596279  4.8862243 ]\n",
            "[-0.9387936 -0.3444802  5.1114864]\n",
            "[-0.8289032 -0.5593921  4.8393435]\n",
            "[-0.6957748 -0.71826    4.1529217]\n",
            "[-0.5522888  -0.83365285  3.6878161 ]\n",
            "[-0.40559325 -0.9140537   3.3495893 ]\n",
            "[-0.29100028 -0.956723    2.4471118 ]\n",
            "[-0.20223992 -0.979336    1.8325527 ]\n",
            "[-0.13378401 -0.9910105   1.3891644 ]\n",
            "[-0.09584738 -0.995396    0.7638319 ]\n",
            "[-0.08658754 -0.99624425  0.18597274]\n",
            "[-0.12124004 -0.9926232  -0.69685876]\n",
            "[-0.17917684 -0.98381686 -1.1722127 ]\n",
            "[-0.26944613 -0.96301544 -1.8533634 ]\n",
            "[-0.38472146 -0.9230327  -2.4417636 ]\n",
            "[-0.5200347  -0.85414517 -3.0397105 ]\n",
            "[-0.6710537 -0.7414087 -3.7747514]\n",
            "[-0.81115174 -0.5848357  -4.209794  ]\n",
            "[-0.9294696 -0.3688988 -4.9370704]\n",
            "[-0.99143857 -0.13057415 -4.937518  ]\n",
            "[-0.9931796   0.11659454 -4.956168  ]\n",
            "[-0.9322912   0.36170864 -5.064793  ]\n",
            "[-0.81942713  0.5731834  -4.8057103 ]\n",
            "[-0.68583465  0.7277574  -4.093217  ]\n",
            "[-0.5498594   0.83525723 -3.471081  ]\n",
            "[-0.4124123   0.91099733 -3.1419096 ]\n",
            "[-0.30728862  0.95161635 -2.2551594 ]\n",
            "[-0.2297626  0.9732467 -1.6101745]\n",
            "[-0.19248831  0.9812993  -0.7627299 ]\n",
            "[-0.19439317  0.9809237   0.03883068]\n",
            "[-0.227051    0.97388285  0.66819483]\n",
            "[-0.29656038  0.9550141   1.4408091 ]\n",
            "[-0.40015036  0.9164495   2.2118385 ]\n",
            "[-0.52132076  0.85336083  2.7343402 ]\n",
            "[-0.6615774  0.7498769  3.4904482]\n",
            "[-0.7962293   0.60499495  3.96233   ]\n",
            "[-0.9052723   0.42483178  4.219669  ]\n",
            "[-0.97944504  0.20171124  4.7134256 ]\n",
            "[-0.99956566 -0.02946955  4.6515718 ]\n",
            "[-0.96912646 -0.24656409  4.393189  ]\n",
            "[-0.88966894 -0.45660618  4.5008693 ]\n",
            "[-0.7761434  -0.63055646  4.1618643 ]\n",
            "[-0.6419837  -0.76671827  3.8288724 ]\n",
            "[-0.5214834 -0.8532614  2.9698837]\n",
            "[-0.42184478 -0.90666807  2.2621903 ]\n",
            "[-0.35838127 -0.93357533  1.3789129 ]\n",
            "[-0.33303317 -0.9429151   0.5402967 ]\n",
            "[-0.3391359  -0.9407374  -0.12959222]\n",
            "[-0.38121107 -0.924488   -0.9021551 ]\n",
            "[-0.44598013 -0.8950429  -1.4232616 ]\n",
            "[-0.5255745 -0.8507476 -1.8224256]\n",
            "[-0.61669034 -0.7872058  -2.222823  ]\n",
            "[-0.7241589 -0.6896332 -2.9056501]\n",
            "[-0.8368665  -0.54740703 -3.6343946 ]\n",
            "[-0.926     -0.3775235 -3.842844 ]\n",
            "[-0.98282176 -0.18455721 -4.0299826 ]\n",
            "[-0.9996357  0.0269909 -4.25231  ]\n",
            "[-0.96811885  0.25049123 -4.523869  ]\n",
            "[-0.8875438  0.4607233 -4.5124464]\n",
            "[-0.7817905   0.62354124 -3.8890846 ]\n",
            "[-0.6561841  0.7546009 -3.6356294]\n",
            "[-0.54088014  0.8410997  -2.88535   ]\n",
            "[-0.45485908  0.8905634  -1.9853842 ]\n",
            "[-0.3911166   0.92034113 -1.4073887 ]\n",
            "[-0.35607573  0.9344571  -0.7555902 ]\n",
            "[-0.3542095   0.9351661  -0.03992745]\n",
            "[-0.3869078  0.9221184  0.7041443]\n",
            "[-0.45149985  0.89227116  1.4233944 ]\n",
            "[-0.5451628  0.8383302  2.162754 ]\n",
            "[-0.6635099  0.7481675  2.978342 ]\n",
            "[-0.78984016  0.6133127   3.70096   ]\n",
            "[-0.90398294  0.42756853  4.3689322 ]\n",
            "[-0.9814461   0.19173846  4.977363  ]\n",
            "[-0.9982044  -0.05989951  5.0573707 ]\n",
            "[-0.9480488  -0.31812504  5.276315  ]\n",
            "[-0.84560275 -0.5338127   4.787039  ]\n",
            "[-0.7135072 -0.7006479  4.2640424]\n",
            "[-0.56774765 -0.82320267  3.8144796 ]\n",
            "[-0.4333247 -0.9012379  3.1117728]\n",
            "[-0.3201368 -0.9473713  2.4460936]\n",
            "[-0.23305604 -0.9724633   1.8130957 ]\n",
            "[-0.18148103 -0.98339444  1.0545361 ]\n",
            "[-0.16043395 -0.9870466   0.42723987]\n",
            "[-0.19023663 -0.98173827 -0.6054577 ]\n",
            "[-0.25673524 -0.9664818  -1.3647901 ]\n",
            "[-0.36190662 -0.9322144  -2.2133934 ]\n",
            "[-0.4964433 -0.8680692 -2.9836874]\n",
            "[-0.64850473 -0.7612106  -3.7224357 ]\n",
            "[-0.8041248  -0.59446055 -4.571664  ]\n",
            "In episode 14\n",
            "[-0.93134713 -0.36413255 -5.277868  ]\n",
            "[-0.99401766 -0.1092193  -5.2652726 ]\n",
            "[-0.9873159  0.1587683 -5.377612 ]\n",
            "[-0.9164931   0.40005037 -5.0425763 ]\n",
            "[-0.7934847   0.60859025 -4.8542175 ]\n",
            "[-0.6367236  0.7710922 -4.525439 ]\n",
            "[-0.4822043  0.8760588 -3.7414513]\n",
            "[-0.33392814  0.9425985  -3.2540252 ]\n",
            "[-0.20890988  0.9779349  -2.6001546 ]\n",
            "[-0.11290707  0.99360555 -1.9462353 ]\n",
            "[-0.06100433  0.9981375  -1.0421224 ]\n",
            "[-0.03452648  0.9994038  -0.53017783]\n",
            "[-0.05750986  0.99834496  0.46016526]\n",
            "[-0.1251169  0.992142   1.3580809]\n",
            "[-0.23085733  0.9729876   2.1502614 ]\n",
            "[-0.36604404  0.93059754  2.8359149 ]\n",
            "[-0.5317722   0.84688747  3.718746  ]\n",
            "[-0.70908797  0.70512     4.550243  ]\n",
            "[-0.8634295  0.5044696  5.0764976]\n",
            "[-0.9664776   0.25675097  5.3821707 ]\n",
            "[-0.99942195 -0.03399596  5.87323   ]\n",
            "[-0.9467988  -0.32182613  5.8731017 ]\n",
            "[-0.8118375  -0.58388346  5.9169297 ]\n",
            "[-0.62135464 -0.78352946  5.536437  ]\n",
            "[-0.3998673  -0.91657305  5.181967  ]\n",
            "[-0.19473438 -0.980856    4.3077087 ]\n",
            "[-0.02578202 -0.9996676   3.404035  ]\n",
            "[ 0.11081413 -0.9938412   2.7365413 ]\n",
            "[ 0.20625325 -0.97849864  1.9340425 ]\n",
            "[ 0.25801003 -0.96614224  1.0643522 ]\n",
            "[ 0.2791411  -0.9602501   0.43875203]\n",
            "[ 0.26855403 -0.96326464 -0.2201585 ]\n",
            "[ 0.22898902 -0.973429   -0.8170524 ]\n",
            "[ 0.1424939 -0.9897957 -1.7611681]\n",
            "[ 0.02307138 -0.9997338  -2.398143  ]\n",
            "[-0.13001712 -0.99151176 -3.0691934 ]\n",
            "[-0.3126037  -0.94988364 -3.750933  ]\n",
            "[-0.51616573 -0.85648876 -4.4887047 ]\n",
            "[-0.7163262 -0.6977656 -5.123095 ]\n",
            "[-0.8848293  -0.46591535 -5.7520924 ]\n",
            "[-0.98443806 -0.1757319  -6.1603928 ]\n",
            "[-0.98889583  0.14861037 -6.5162416 ]\n",
            "[-0.89843136  0.43911397 -6.1089873 ]\n",
            "[-0.7313866  0.6819631 -5.916622 ]\n",
            "[-0.52114594  0.8534676  -5.4431973 ]\n",
            "[-0.2994194  0.9541216 -4.88218  ]\n",
            "[-0.10680194  0.99428034 -3.941561  ]\n",
            "[ 0.04386896  0.99903727 -3.0177815 ]\n",
            "[ 0.14713147  0.98911697 -2.0756903 ]\n",
            "[ 0.20501387  0.97875905 -1.1762066 ]\n",
            "[ 0.22579347  0.9741752  -0.4255916 ]\n",
            "[0.19654885 0.980494   0.5984121 ]\n",
            "[0.11777527 0.99304026 1.595752  ]\n",
            "[0.00383855 0.9999926  2.284214  ]\n",
            "[-0.1433743   0.98966855  2.9541733 ]\n",
            "[-0.32655966  0.9451766   3.7758255 ]\n",
            "[-0.5385785  0.8425753  4.7217546]\n",
            "[-0.73798114  0.6748214   5.2264924 ]\n",
            "[-0.90203387  0.43166527  5.88769   ]\n",
            "[-0.9886717  0.1500939  5.9134965]\n",
            "[-0.9885325 -0.1510083  6.0450287]\n",
            "[-0.8973499  -0.44131982  6.1096153 ]\n",
            "[-0.7358828  -0.67710894  5.7351565 ]\n",
            "[-0.52705365 -0.84983206  5.4367948 ]\n",
            "[-0.29722086 -0.9548088   5.066983  ]\n",
            "[-0.09051589 -0.995895    4.222814  ]\n",
            "[ 0.07727008 -0.9970102   3.3597424 ]\n",
            "[ 0.21254387 -0.9771515   2.7366083 ]\n",
            "[ 0.297184  -0.9548202  1.7512889]\n",
            "[ 0.34170008 -0.939809    0.9396648 ]\n",
            "[ 0.3626356 -0.931931   0.4473837]\n",
            "[ 0.33866557 -0.9409068  -0.5119232 ]\n",
            "[ 0.29188395 -0.95645374 -0.9860466 ]\n",
            "[ 0.19804604 -0.9801927  -1.9366376 ]\n",
            "[ 0.07883919 -0.9968873  -2.4088597 ]\n",
            "[-0.07020613 -0.9975325  -2.9837003 ]\n",
            "[-0.24848229 -0.96863645 -3.6169832 ]\n",
            "[-0.45531136 -0.8903323  -4.432176  ]\n",
            "[-0.6558554 -0.7548865 -4.851867 ]\n",
            "[-0.8263027 -0.5632263 -5.1439195]\n",
            "[-0.947473   -0.31983584 -5.4545774 ]\n",
            "[-0.9992453  -0.03884348 -5.7340593 ]\n",
            "[-0.9658893  0.2589555 -6.0158787]\n",
            "[-0.8494115  0.5277312 -5.8797317]\n",
            "[-0.6713724   0.74112016 -5.5762005 ]\n",
            "[-0.46173579  0.8870175  -5.1221595 ]\n",
            "[-0.26585564  0.96401286 -4.2171936 ]\n",
            "[-0.09850309  0.99513674 -3.4085665 ]\n",
            "[ 0.04842703  0.99882674 -2.9421813 ]\n",
            "[ 0.15022877  0.9886513  -2.0470736 ]\n",
            "[ 0.21330978  0.9769846  -1.283236  ]\n",
            "[ 0.25293112  0.9674843  -0.81494457]\n",
            "[ 0.2596992   0.96568954 -0.14003983]\n",
            "[0.24209353 0.97025293 0.36375397]\n",
            "[0.17428586 0.9846951  1.3868502 ]\n",
            "[0.05814305 0.99830824 2.3400924 ]\n",
            "[-0.10420418  0.99455595  3.251391  ]\n",
            "[-0.31052545  0.95056504  4.2270412 ]\n",
            "[-0.5302371  0.8478494  4.8626885]\n",
            "[-0.74220806  0.67016953  5.549579  ]\n",
            "In episode 15\n",
            "[-0.9124215   0.40925166  6.256069  ]\n",
            "[-0.996071   0.0885587  6.6591773]\n",
            "[-0.96858    -0.24870215  6.8002987 ]\n",
            "[-0.83986014 -0.5428029   6.4486156 ]\n",
            "[-0.64092547 -0.7676031   6.026443  ]\n",
            "[-0.4110809  -0.91159886  5.441277  ]\n",
            "[-0.18202135 -0.9832946   4.8119545 ]\n",
            "[ 0.02662455 -0.99964553  4.193389  ]\n",
            "[ 0.18806674 -0.9821563   3.2513137 ]\n",
            "[ 0.29978344 -0.95400727  2.3054447 ]\n",
            "[ 0.36189649 -0.9322183   1.3167167 ]\n",
            "[ 0.39053372 -0.9205886   0.6181962 ]\n",
            "[ 0.38119024 -0.92449665 -0.20255767]\n",
            "[ 0.3288812 -0.9443713 -1.1192952]\n",
            "[ 0.22923537 -0.973371   -2.0765314 ]\n",
            "[ 0.09346201 -0.9956229  -2.753869  ]\n",
            "[-0.0710924 -0.9974697 -3.2950208]\n",
            "[-0.2652165 -0.9641889 -3.9455206]\n",
            "[-0.49396926 -0.86947936 -4.96441   ]\n",
            "[-0.7223758  -0.69150066 -5.81166   ]\n",
            "[-0.9028639  -0.42992643 -6.383062  ]\n",
            "[-0.99244356 -0.1227018  -6.4279895 ]\n",
            "[-0.982032   0.1887144 -6.257293 ]\n",
            "[-0.87855244  0.47764593 -6.162408  ]\n",
            "[-0.70622176  0.7079907  -5.7735143 ]\n",
            "[-0.5017652  0.8650039 -5.1701818]\n",
            "[-0.2903661  0.9569156 -4.620577 ]\n",
            "[-0.10215376  0.9947686  -3.845543  ]\n",
            "[ 0.05771465  0.9983331  -3.2015803 ]\n",
            "[ 0.17424344  0.9847026  -2.3478131 ]\n",
            "[ 0.25404713  0.9671918  -1.6344999 ]\n",
            "[ 0.29368144  0.95590335 -0.8242692 ]\n",
            "[0.28560197 0.95834833 0.16882713]\n",
            "[0.2560119 0.9666736 0.6148031]\n",
            "[0.19076765 0.9816352  1.339005  ]\n",
            "[0.09938363 0.9950492  1.8479224 ]\n",
            "[-0.03676189  0.999324    2.7263627 ]\n",
            "[-0.2044105   0.97888523  3.3818257 ]\n",
            "[-0.4080894  0.912942   4.2899766]\n",
            "[-0.6288443  0.7775312  5.194114 ]\n",
            "[-0.8271284  0.562013   5.878258 ]\n",
            "[-0.9596103   0.28133273  6.2326956 ]\n",
            "[-0.99875075 -0.04996955  6.7034607 ]\n",
            "[-0.9253181 -0.3791917  6.7786446]\n",
            "[-0.7513664 -0.6598853  6.63487  ]\n",
            "[-0.52936155 -0.84839636  5.8456483 ]\n",
            "[-0.3028255 -0.953046   5.0038366]\n",
            "[-0.08503813 -0.9963777   4.4503007 ]\n",
            "[ 0.11153103 -0.99376094  3.9380903 ]\n",
            "[ 0.26398182 -0.96452767  3.1076915 ]\n",
            "[ 0.38867268 -0.92137593  2.6408484 ]\n",
            "[ 0.48724186 -0.87326705  2.19476   ]\n",
            "[ 0.54942936 -0.8355402   1.4550513 ]\n",
            "[ 0.574837   -0.81826794  0.614476  ]\n",
            "[ 0.5676339  -0.82328105 -0.17551763]\n",
            "[ 0.547015  -0.8371228 -0.4966955]\n",
            "[ 0.49470815 -0.86905915 -1.225906  ]\n",
            "[ 0.42224768 -0.9064805  -1.6315101 ]\n",
            "[ 0.324207   -0.94598615 -2.1150024 ]\n",
            "[ 0.17398593 -0.9847481  -3.105949  ]\n",
            "[-0.01516458 -0.999885   -3.8008213 ]\n",
            "[-0.25356784 -0.9673176  -4.8240347 ]\n",
            "[-0.49805832 -0.8671435  -5.299825  ]\n",
            "[-0.7375892  -0.67524976 -6.1626983 ]\n",
            "[-0.92181873 -0.38762116 -6.8650727 ]\n",
            "[-0.9994807  -0.03222303 -7.31642   ]\n",
            "[-0.94189525  0.33590674 -7.4959273 ]\n",
            "[-0.76031196  0.6495581  -7.288707  ]\n",
            "[-0.4923351   0.87040573 -6.9804544 ]\n",
            "[-0.19343513  0.9811131  -6.4021664 ]\n",
            "[ 0.0967994  0.9953039 -5.832268 ]\n",
            "[ 0.33836985  0.9410132  -4.9646564 ]\n",
            "[ 0.5168524  0.8560745 -3.9597206]\n",
            "[ 0.647663    0.76192695 -3.2268627 ]\n",
            "[ 0.73351943  0.6796685  -2.379451  ]\n",
            "[ 0.78520566  0.61923504 -1.5908498 ]\n",
            "[ 0.8263499  0.563157  -1.391336 ]\n",
            "[ 0.8602766  0.5098277 -1.2643368]\n",
            "[ 0.8754435   0.48332042 -0.6108176 ]\n",
            "[ 0.8781104   0.47845808 -0.11091305]\n",
            "[0.876043   0.4822329  0.08607709]\n",
            "[0.86394674 0.50358325 0.4907905 ]\n",
            "[0.83794504 0.5457546  0.99096185]\n",
            "[0.7891692  0.61417586 1.6810371 ]\n",
            "[0.72700953 0.6866274  1.9099704 ]\n",
            "[0.6408244 0.7676875 2.3676987]\n",
            "[0.51501364 0.85718197 3.0909615 ]\n",
            "[0.3426833 0.939451  3.825038 ]\n",
            "[0.13045119 0.9914547  4.378952  ]\n",
            "[-0.1333832   0.99106455  5.292119  ]\n",
            "[-0.41326115  0.9106125   5.8450108 ]\n",
            "[-0.68901515  0.72474694  6.681937  ]\n",
            "[-0.90001905  0.43585056  7.193679  ]\n",
            "[-0.99653625  0.08315951  7.354549  ]\n",
            "[-0.959523  -0.2816302  7.374966 ]\n",
            "[-0.8075758  -0.58976376  6.9054723 ]\n",
            "[-0.57274336 -0.81973475  6.603629  ]\n",
            "[-0.3106327  -0.95053005  5.8798003 ]\n",
            "[-0.0721521  -0.99739367  4.8728747 ]\n",
            "[ 0.1316771  -0.99129266  4.08551   ]\n",
            "In episode 16\n",
            "[ 0.2804686 -0.9598632  3.044433 ]\n",
            "[ 0.39993683 -0.9165427   2.5433123 ]\n",
            "[ 0.48382953 -0.87516224  1.8715469 ]\n",
            "[ 0.53476703 -0.84499955  1.1841354 ]\n",
            "[ 0.55665946 -0.83074075  0.52254367]\n",
            "[ 0.54549694 -0.8381128  -0.267545  ]\n",
            "[ 0.50336003 -0.8640768  -0.98997974]\n",
            "[ 0.4211078 -0.9070106 -1.8563323]\n",
            "[ 0.2929988 -0.9561128 -2.7460914]\n",
            "[ 0.13563597 -0.9907587  -3.226129  ]\n",
            "[-0.07078581 -0.99749154 -4.138008  ]\n",
            "[-0.29639995 -0.95506394 -4.601519  ]\n",
            "[-0.52906346 -0.84858227 -5.1315103 ]\n",
            "[-0.74969155 -0.66178745 -5.8019867 ]\n",
            "[-0.9194757  -0.39314693 -6.382977  ]\n",
            "[-0.99745053 -0.07136146 -6.6525893 ]\n",
            "[-0.9672838  0.2536969 -6.558449 ]\n",
            "[-0.8406284   0.54161227 -6.3170724 ]\n",
            "[-0.63496876  0.7725378  -6.2094874 ]\n",
            "[-0.4037419   0.91487294 -5.447296  ]\n",
            "[-0.16834849  0.98572755 -4.928985  ]\n",
            "[ 0.03153674  0.9995026  -4.0139194 ]\n",
            "[ 0.19130312  0.981531   -3.218953  ]\n",
            "[ 0.31201366  0.9500776  -2.4964428 ]\n",
            "[ 0.3928669   0.91959536 -1.7287068 ]\n",
            "[ 0.43039158  0.90264225 -0.8235892 ]\n",
            "[ 0.43808073  0.8989356  -0.17071907]\n",
            "[0.42702714 0.9042388  0.24519983]\n",
            "[0.39028883 0.92069244 0.80514467]\n",
            "[0.30864173 0.9511784  1.7436115 ]\n",
            "[0.20021199 0.9797526  2.2438085 ]\n",
            "[0.04253927 0.9990948  3.1804435 ]\n",
            "[-0.14605376  0.98927665  3.7826035 ]\n",
            "[-0.3713772   0.92848206  4.678276  ]\n",
            "[-0.6031841  0.797602   5.339907 ]\n",
            "[-0.8146705   0.57992417  6.093471  ]\n",
            "[-0.95864725  0.28459692  6.6009927 ]\n",
            "[-0.9980255  -0.06280997  7.0287457 ]\n",
            "[-0.9189201  -0.39444372  6.8522215 ]\n",
            "[-0.7384039  -0.67435867  6.6926684 ]\n",
            "[-0.4858134  -0.87406254  6.4681387 ]\n",
            "[-0.22030017 -0.97543216  5.7034273 ]\n",
            "[ 0.030586   -0.99953216  5.0542593 ]\n",
            "[ 0.25526863 -0.9668702   4.5506954 ]\n",
            "[ 0.43601266 -0.89994055  3.8607535 ]\n",
            "[ 0.58438236 -0.81147844  3.4591095 ]\n",
            "[ 0.70252156 -0.7116625   3.0963159 ]\n",
            "[ 0.78451586 -0.6201088   2.4596095 ]\n",
            "[ 0.84106195 -0.5409388   1.9465693 ]\n",
            "[ 0.87813675 -0.47840968  1.4542018 ]\n",
            "[ 0.90371275 -0.42813933  1.128199  ]\n",
            "[ 0.92113626 -0.38924026  0.85252374]\n",
            "[ 0.93588066 -0.35231715  0.79521596]\n",
            "[ 0.9411022  -0.33812228  0.3024983 ]\n",
            "[ 0.94025373 -0.34047464 -0.05001356]\n",
            "[ 0.93246126 -0.36127004 -0.44415852]\n",
            "[ 0.92186123 -0.3875201  -0.5662084 ]\n",
            "[ 0.90677327 -0.42161855 -0.74579084]\n",
            "[ 0.8846779  -0.46620277 -0.9952833 ]\n",
            "[ 0.850434   -0.52608174 -1.3798575 ]\n",
            "[ 0.8019951  -0.59733063 -1.72364   ]\n",
            "[ 0.7323431  -0.68093586 -2.177424  ]\n",
            "[ 0.6366913 -0.7711188 -2.6311345]\n",
            "[ 0.50338835 -0.8640603  -3.2536814 ]\n",
            "[ 0.32868937 -0.9444381  -3.8520052 ]\n",
            "[ 0.11678091 -0.9931577  -4.3573503 ]\n",
            "[-0.12566108 -0.99207324 -4.860843  ]\n",
            "[-0.40387776 -0.914813   -5.795152  ]\n",
            "[-0.6744736  -0.73829895 -6.4899945 ]\n",
            "[-0.8855015  -0.46463653 -6.9464145 ]\n",
            "[-0.993249   -0.11600159 -7.3392153 ]\n",
            "[-0.96754766  0.25268856 -7.4344263 ]\n",
            "[-0.8107265  0.585425  -7.398925 ]\n",
            "[-0.56798744  0.8230372  -6.826671  ]\n",
            "[-0.28505704  0.9585106  -6.2998524 ]\n",
            "[-0.02288601  0.9997381  -5.3235583 ]\n",
            "[ 0.19795287  0.98021156 -4.4431405 ]\n",
            "[ 0.36789793  0.9298662  -3.5495675 ]\n",
            "[ 0.50629824  0.86235845 -3.0827868 ]\n",
            "[ 0.6039535   0.79701954 -2.3513086 ]\n",
            "[ 0.6668932  0.7451533 -1.6315892]\n",
            "[ 0.6979877   0.7161098  -0.85103786]\n",
            "[ 0.71485025  0.6992776  -0.476528  ]\n",
            "[ 0.7210575   0.69287527 -0.17834722]\n",
            "[0.7147051  0.6994259  0.18249755]\n",
            "[0.67977524 0.7334205  0.97492534]\n",
            "[0.6191442 0.7852773 1.5960748]\n",
            "[0.52673227 0.85003126 2.2580142 ]\n",
            "[0.39471352 0.9188042  2.9799128 ]\n",
            "[0.20611547 0.97852767 3.9630506 ]\n",
            "[-0.01466396  0.9998925   4.44536   ]\n",
            "[-0.26568714  0.9640593   5.0850425 ]\n",
            "[-0.53100365  0.84736955  5.817359  ]\n",
            "[-0.77989954  0.62590474  6.694414  ]\n",
            "[-0.9462712  0.3233742  6.9399586]\n",
            "[-0.99904865 -0.04360999  7.458339  ]\n",
            "[-0.92081535 -0.38999882  7.1401296 ]\n",
            "[-0.7436907  -0.66852385  6.631836  ]\n",
            "[-0.5038482  -0.86379224  6.210524  ]\n",
            "[-0.25019738 -0.96819484  5.5032783 ]\n",
            "In episode 17\n",
            "[-0.01309425 -0.9999143   4.7957897 ]\n",
            "[ 0.18529221 -0.9826835   3.989277  ]\n",
            "[ 0.3452196 -0.9385219  3.3220713]\n",
            "[ 0.47434884 -0.88033694  2.8350284 ]\n",
            "[ 0.56424445 -0.8256078   2.1058717 ]\n",
            "[ 0.6288872 -0.7774966  1.6120656]\n",
            "[ 0.6677513 -0.7443844  1.0212549]\n",
            "[ 0.6779064  -0.73514825  0.27454352]\n",
            "[ 0.6673255  -0.7447662  -0.28598127]\n",
            "[ 0.63466704 -0.7727857  -0.8606871 ]\n",
            "[ 0.5655711 -0.8246995 -1.7290398]\n",
            "[ 0.4531471  -0.89143574 -2.6166604 ]\n",
            "[ 0.3019189 -0.9533336 -3.2717545]\n",
            "[ 0.10925929 -0.9940133  -3.94454   ]\n",
            "[-0.13156731 -0.99130726 -4.828554  ]\n",
            "[-0.41038278 -0.91191334 -5.818478  ]\n",
            "[-0.6844138 -0.7290938 -6.6185117]\n",
            "[-0.90305257 -0.42953    -7.4604945 ]\n",
            "[-0.9989267  -0.04631938 -7.952726  ]\n",
            "[-0.93811     0.34633738 -8.        ]\n",
            "[-0.7356601   0.67735094 -7.8098326 ]\n",
            "[-0.44317958  0.8964329  -7.3499627 ]\n",
            "[-0.11408892  0.99347055 -6.8960924 ]\n",
            "[ 0.20199826  0.97938585 -6.354714  ]\n",
            "[ 0.45529607  0.8903401  -5.386138  ]\n",
            "[ 0.64922726  0.7605945  -4.677266  ]\n",
            "[ 0.78630334  0.61784065 -3.964696  ]\n",
            "[ 0.8792332  0.4763917 -3.3889463]\n",
            "[ 0.9364066  0.3509169 -2.7599225]\n",
            "[ 0.97311944  0.23030093 -2.5232632 ]\n",
            "[ 0.9935292   0.11357704 -2.3712854 ]\n",
            "[ 0.9999273 -0.0120619 -2.5176969]\n",
            "[ 0.98979354 -0.14250895 -2.6186717 ]\n",
            "[ 0.96251965 -0.27121192 -2.6331227 ]\n",
            "[ 0.9142441 -0.4051638 -2.8501215]\n",
            "[ 0.8342143 -0.5514403 -3.3386366]\n",
            "[ 0.7098265 -0.7043765 -3.9490914]\n",
            "[ 0.5319223 -0.8467932 -4.567658 ]\n",
            "[ 0.28771722 -0.9577154  -5.3805323 ]\n",
            "[ 1.8768519e-04 -1.0000000e+00 -5.8330946e+00]\n",
            "[-0.32784674 -0.94473094 -6.6842227 ]\n",
            "[-0.65775234 -0.75323427 -7.676148  ]\n",
            "[-0.8991533  -0.43763387 -8.        ]\n",
            "[-0.9985977  -0.05294072 -8.        ]\n",
            "[-0.94038546  0.34011063 -8.        ]\n",
            "[-0.7457183  0.6662614 -7.642991 ]\n",
            "[-0.46280968  0.8864577  -7.209002  ]\n",
            "[-0.16045767  0.9870427  -6.4001565 ]\n",
            "[ 0.11721653  0.99310637 -5.5728188 ]\n",
            "[ 0.3492392  0.9370336 -4.785449 ]\n",
            "[ 0.5277429   0.84940416 -3.9836407 ]\n",
            "[ 0.6680482  0.744118  -3.5128326]\n",
            "[ 0.7742595   0.63286823 -3.0792294 ]\n",
            "[ 0.8428807  0.5381004 -2.3414068]\n",
            "[ 0.88726515  0.46125978 -1.7753454 ]\n",
            "[ 0.91941    0.3933004 -1.5039189]\n",
            "[ 0.94461936  0.32816803 -1.3971002 ]\n",
            "[ 0.9639353  0.2661366 -1.2996143]\n",
            "[ 0.9787865   0.20488277 -1.2607781 ]\n",
            "[ 0.989668    0.14337797 -1.2494024 ]\n",
            "[ 0.99578035  0.09176854 -1.0395197 ]\n",
            "[ 0.9990087   0.04451555 -0.94735134]\n",
            "[ 0.99990857 -0.01352401 -1.1610938 ]\n",
            "[ 0.9975385 -0.0701206 -1.1330754]\n",
            "[ 0.99311113 -0.11717612 -0.9453549 ]\n",
            "[ 0.987254   -0.15915236 -0.84772146]\n",
            "[ 0.9765193 -0.21543   -1.1460028]\n",
            "[ 0.96257055 -0.27103132 -1.146643  ]\n",
            "[ 0.9421696 -0.3351364 -1.3457143]\n",
            "[ 0.91626334 -0.4005764  -1.4079165 ]\n",
            "[ 0.8728569 -0.4879762 -1.9524759]\n",
            "[ 0.8180917  -0.57508785 -2.0588374 ]\n",
            "[ 0.7449174 -0.6671567 -2.3534753]\n",
            "[ 0.6462655  -0.76311266 -2.754612  ]\n",
            "[ 0.52270865 -0.85251135 -3.053106  ]\n",
            "[ 0.35711297 -0.9340612  -3.6969986 ]\n",
            "[ 0.13643225 -0.9906494  -4.566323  ]\n",
            "[-0.1266254  -0.99195063 -5.276507  ]\n",
            "[-0.4016096  -0.91581094 -5.72615   ]\n",
            "[-0.6793695  -0.73379636 -6.672587  ]\n",
            "[-0.90057844 -0.43469357 -7.483905  ]\n",
            "[-0.9987653  -0.04967754 -8.        ]\n",
            "[-0.9392691  0.3431815 -8.       ]\n",
            "[-0.7314834   0.68185925 -7.9999876 ]\n",
            "[-0.42624214  0.9046091  -7.6032076 ]\n",
            "[-0.10886588  0.99405646 -6.62505   ]\n",
            "[ 0.172415   0.9850244 -5.6472588]\n",
            "[ 0.40585703  0.91393656 -4.89271   ]\n",
            "[ 0.5857378   0.81050056 -4.157475  ]\n",
            "[ 0.7118588  0.7023226 -3.327025 ]\n",
            "[ 0.7996103  0.6005192 -2.6900938]\n",
            "[ 0.86197954  0.5069431  -2.2503111 ]\n",
            "[ 0.90273935  0.43018794 -1.7386751 ]\n",
            "[ 0.92996585  0.36764583 -1.364493  ]\n",
            "[ 0.9453242  0.3261321 -0.8853451]\n",
            "[ 0.9539307   0.30002704 -0.5497607 ]\n",
            "[ 0.9610048   0.2765317  -0.49075642]\n",
            "[ 0.9634828   0.26777032 -0.18210174]\n",
            "[ 0.96390843  0.26623392 -0.0318854 ]\n",
            "[0.96277076 0.27031922 0.08481516]\n",
            "In episode 18\n",
            "[0.95691156 0.2903795  0.4179758 ]\n",
            "[0.94867766 0.3162446  0.54289836]\n",
            "[0.93434584 0.35636753 0.85217947]\n",
            "[0.91896373 0.394342   0.81948906]\n",
            "[0.89752036 0.44097298 1.0266145 ]\n",
            "[0.8599436  0.51038903 1.5790929 ]\n",
            "[0.8103514  0.58594424 1.8081533 ]\n",
            "[0.7476752 0.6640646 2.0039456]\n",
            "[0.6577152 0.7532667 2.5354555]\n",
            "[0.5217227  0.85311514 3.3782508 ]\n",
            "[0.34055313 0.9402253  4.027277  ]\n",
            "[0.10784596 0.9941676  4.7889805 ]\n",
            "[-0.16191547  0.9868046   5.4137506 ]\n",
            "[-0.45192516  0.89205587  6.125817  ]\n",
            "[-0.7169014   0.69717455  6.6085067 ]\n",
            "[-0.9173479   0.39808646  7.2403755 ]\n",
            "[-0.99974585  0.02254444  7.737672  ]\n",
            "[-0.9319444  -0.36260128  7.8720794 ]\n",
            "[-0.73742855 -0.6754251   7.4096694 ]\n",
            "[-0.46820548 -0.8836196   6.8399286 ]\n",
            "[-0.18155323 -0.9833811   6.0938625 ]\n",
            "[ 0.08419171 -0.9964496   5.337144  ]\n",
            "[ 0.3211894 -0.947015   4.8538733]\n",
            "[ 0.5065079  -0.86223537  4.0828934 ]\n",
            "[ 0.636738   -0.77108026  3.1826115 ]\n",
            "[ 0.73695993 -0.67593646  2.766025  ]\n",
            "[ 0.8124991  -0.58296245  2.397293  ]\n",
            "[ 0.86366904 -0.5040593   1.8815519 ]\n",
            "[ 0.89673734 -0.4425632   1.3967481 ]\n",
            "[ 0.91310287 -0.40772927  0.7697833 ]\n",
            "[ 0.9198461  -0.39227936  0.33715162]\n",
            "[ 0.9188748  -0.39454928 -0.0493805 ]\n",
            "[ 0.91756946 -0.39757553 -0.06591488]\n",
            "[ 0.9150127  -0.40342498 -0.12767632]\n",
            "[ 0.9049658  -0.4254843  -0.48480216]\n",
            "[ 0.89233804 -0.45136768 -0.5760095 ]\n",
            "[ 0.87486935 -0.484359   -0.7466581 ]\n",
            "[ 0.8396662 -0.5431028 -1.3699528]\n",
            "[ 0.7867767  -0.61723775 -1.82198   ]\n",
            "[ 0.7064574 -0.7077556 -2.4217832]\n",
            "[ 0.59997994 -0.80001503 -2.8200831 ]\n",
            "[ 0.4510445 -0.8925015 -3.5108144]\n",
            "[ 0.24496692 -0.9695314  -4.408994  ]\n",
            "[ 5.4780371e-04 -9.9999982e-01 -4.9387555e+00]\n",
            "[-0.2869325  -0.95795083 -5.831419  ]\n",
            "[-0.5700436  -0.82161444 -6.3107157 ]\n",
            "[-0.8160702  -0.57795274 -6.960392  ]\n",
            "[-0.9684876  -0.24906164 -7.290131  ]\n",
            "[-0.9928885   0.11904789 -7.4208426 ]\n",
            "[-0.88469946  0.46616188 -7.312331  ]\n",
            "[-0.67033297  0.7420604  -7.023829  ]\n",
            "[-0.39715275  0.9177525  -6.5249014 ]\n",
            "[-0.11849213  0.99295497 -5.792823  ]\n",
            "[ 0.13868468  0.9903366  -5.1580863 ]\n",
            "[ 0.35159647  0.9361517  -4.4028554 ]\n",
            "[ 0.5301378   0.84791154 -3.9897423 ]\n",
            "[ 0.6533608   0.75704664 -3.0650463 ]\n",
            "[ 0.7333041  0.6799008 -2.223072 ]\n",
            "[ 0.7884886   0.61504936 -1.7035762 ]\n",
            "[ 0.8310584   0.55618525 -1.4532026 ]\n",
            "[ 0.866126    0.49982578 -1.3278171 ]\n",
            "[ 0.88951296  0.45690995 -0.9775875 ]\n",
            "[ 0.9056015   0.42412955 -0.7303549 ]\n",
            "[ 0.90920365  0.41635165 -0.17143127]\n",
            "[0.9081907  0.41855657 0.0485298 ]\n",
            "[0.9028234  0.43001154 0.25300285]\n",
            "[0.8890753  0.45776096 0.61939275]\n",
            "[0.87309825 0.48754427 0.67599374]\n",
            "[0.8429577 0.5379799 1.175279 ]\n",
            "[0.7898467 0.6133043 1.8439698]\n",
            "[0.7084651 0.7057458 2.4647603]\n",
            "[0.59919757 0.8006012  2.8964512 ]\n",
            "[0.45833737 0.8887783  3.327497  ]\n",
            "[0.27365327 0.9618284  3.978687  ]\n",
            "[0.03516428 0.99938154 4.840354  ]\n",
            "[-0.24260543  0.970125    5.604443  ]\n",
            "[-0.53709614  0.84352106  6.4388027 ]\n",
            "[-0.7985184  0.6019704  7.156784 ]\n",
            "[-0.9658614  0.2590595  7.6783614]\n",
            "[-0.9920773  -0.12562886  7.7602    ]\n",
            "[-0.86667544 -0.49887243  7.9267116 ]\n",
            "[-0.62174577 -0.7832191   7.5505867 ]\n",
            "[-0.3209706  -0.94708914  6.8843117 ]\n",
            "[-0.0068124 -0.9999768  6.3988338]\n",
            "[ 0.28613654 -0.95818883  5.9400964 ]\n",
            "[ 0.51818466 -0.8552688   5.090694  ]\n",
            "[ 0.69253963 -0.7213799   4.4055314 ]\n",
            "[ 0.8165823 -0.577229   3.8092296]\n",
            "[ 0.89646    -0.44312465  3.1249998 ]\n",
            "[ 0.94537896 -0.3259733   2.540803  ]\n",
            "[ 0.97615534 -0.21707311  2.2645202 ]\n",
            "[ 0.9942283  -0.10728481  2.2264678 ]\n",
            "[ 0.9999752  -0.00704557  2.0089211 ]\n",
            "[0.9955646  0.09408059 2.0253112 ]\n",
            "[0.9818769  0.18951985 1.9290636 ]\n",
            "[0.95439565 0.29854462 2.249885  ]\n",
            "[0.9040864 0.4273497 2.767838 ]\n",
            "[0.8287564 0.5596096 3.0471075]\n",
            "[0.72483504 0.6889225  3.3217363 ]\n",
            "[0.5866892 0.8098122 3.6766095]\n",
            "In episode 19\n",
            "[0.38995385 0.9208344  4.5276585 ]\n",
            "[0.14182907 0.9898912  5.165451  ]\n",
            "[-0.14580546  0.9893133   5.7727203 ]\n",
            "[-0.46242318  0.8866594   6.687982  ]\n",
            "[-0.74635357  0.66554964  7.236803  ]\n",
            "[-0.94661444  0.32236803  8.        ]\n",
            "[-0.9974256 -0.0717084  8.       ]\n",
            "[-0.8907653  -0.45446366  8.        ]\n",
            "[-0.6480727 -0.7615785  7.879506 ]\n",
            "[-0.327252  -0.9449371  7.4331408]\n",
            "[ 0.01021721 -0.9999478   6.8722277 ]\n",
            "[ 0.30005383 -0.9539223   5.8906336 ]\n",
            "[ 0.5307206 -0.8475469  5.094029 ]\n",
            "[ 0.713888   -0.70025986  4.7116866 ]\n",
            "[ 0.8424141  -0.53883064  4.134261  ]\n",
            "[ 0.9290724 -0.369898   3.8029842]\n",
            "[ 0.9823633  -0.18698236  3.8161955 ]\n",
            "[ 9.9999839e-01 -1.7835093e-03  3.7261186e+00]\n",
            "[0.9844223 0.17582   3.5704439]\n",
            "[0.9371961 0.348803  3.5910983]\n",
            "[0.8598691 0.5105145 3.5897884]\n",
            "[0.74155307 0.6708942  3.9926193 ]\n",
            "[0.5735818  0.81914824 4.49021   ]\n",
            "[0.3379651  0.94115865 5.322358  ]\n",
            "[0.04378602 0.99904096 6.0190783 ]\n",
            "[-0.2824565   0.95928013  6.6030784 ]\n",
            "[-0.6052945  0.7960016  7.2756386]\n",
            "[-0.85759443  0.5143265   7.608767  ]\n",
            "[-0.98885113  0.1489076   7.8151736 ]\n",
            "[-0.96877956 -0.24792378  8.        ]\n",
            "[-0.80990577 -0.58656     7.525367  ]\n",
            "[-0.5525321 -0.8334916  7.1718473]\n",
            "[-0.2410909  -0.97050256  6.8381877 ]\n",
            "[ 0.06658424 -0.9977808   6.2024655 ]\n",
            "[ 0.3402269 -0.9403434  5.6104927]\n",
            "[ 0.5572074  -0.83037335  4.877215  ]\n",
            "[ 0.71558136 -0.69852936  4.128742  ]\n",
            "[ 0.8331159  -0.55309844  3.7452307 ]\n",
            "[ 0.91140217 -0.41151688  3.2392204 ]\n",
            "[ 0.96331006 -0.268391    3.0479078 ]\n",
            "[ 0.98988724 -0.14185666  2.5877113 ]\n",
            "[ 0.9996126  -0.02783056  2.2900527 ]\n",
            "[0.99714833 0.07546687 2.067457  ]\n",
            "[0.9854857  0.16975869 1.9009224 ]\n",
            "[0.963325  0.2683373 2.0216365]\n",
            "[0.9242556 0.3817742 2.4009695]\n",
            "[0.8594731  0.51118094 2.8968632 ]\n",
            "[0.7702752 0.6377117 3.099311 ]\n",
            "[0.6412381 0.767342  3.6632373]\n",
            "[0.468973  0.8832125 4.1596603]\n",
            "[0.23660623 0.9716056  4.9851246 ]\n",
            "[-0.04312257  0.9990698   5.640147  ]\n",
            "[-0.34716675  0.93780345  6.2282457 ]\n",
            "[-0.6380838  0.7699669  6.749176 ]\n",
            "[-0.86815685  0.49628988  7.189386  ]\n",
            "[-0.99058115  0.1369268   7.639233  ]\n",
            "[-0.9717169  -0.23614897  7.5151825 ]\n",
            "[-0.8151517 -0.5792475  7.588089 ]\n",
            "[-0.5485414 -0.8361234  7.4474463]\n",
            "[-0.24511285 -0.9694946   6.659653  ]\n",
            "[ 0.06365592 -0.9979719   6.2267017 ]\n",
            "[ 0.32647055 -0.94520736  5.3773627 ]\n",
            "[ 0.5351663 -0.8447467  4.6427507]\n",
            "[ 0.6986988  -0.71541595  4.1774487 ]\n",
            "[ 0.81072235 -0.58543086  3.4361565 ]\n",
            "[ 0.8946759  -0.44671574  3.2464066 ]\n",
            "[ 0.95049405 -0.31074274  2.9423344 ]\n",
            "[ 0.9840086  -0.17812091  2.7379572 ]\n",
            "[ 0.9984468  -0.05571292  2.4666944 ]\n",
            "[0.9974889  0.07082239 2.5324702 ]\n",
            "[0.97705305 0.21299599 2.8751714 ]\n",
            "[0.9334654  0.35866743 3.043993  ]\n",
            "[0.8647461  0.50220937 3.1862369 ]\n",
            "[0.7683724  0.64000297 3.3670068 ]\n",
            "[0.6330366 0.7741218 3.8164914]\n",
            "[0.4523577 0.8918366 4.3212485]\n",
            "[0.22260389 0.97490895 4.898453  ]\n",
            "[-0.05092742  0.99870235  5.5086803 ]\n",
            "[-0.34409416  0.93893516  6.006488  ]\n",
            "[-0.6287221  0.7776301  6.572699 ]\n",
            "[-0.85839343  0.5129919   7.044418  ]\n",
            "[-0.986039    0.16651481  7.4274516 ]\n",
            "[-0.9749897  -0.22224988  7.8283105 ]\n",
            "[-0.8188432 -0.5740172  7.7456403]\n",
            "[-0.5469199 -0.8371849  7.6142435]\n",
            "[-0.22036582 -0.9754173   7.1298237 ]\n",
            "[ 0.10634086 -0.99432975  6.574636  ]\n",
            "[ 0.38447243 -0.9231365   5.7618794 ]\n",
            "[ 0.59688556 -0.8023264   4.8995485 ]\n",
            "[ 0.7487887 -0.6628087  4.1323805]\n",
            "[ 0.854945  -0.5187186  3.5842426]\n",
            "[ 0.92594725 -0.37765285  3.1618273 ]\n",
            "[ 0.9718239 -0.2357083  2.9862556]\n",
            "[ 0.9954045  -0.09575958  2.840816  ]\n",
            "[0.9986244  0.05243438 2.9672995 ]\n",
            "[0.98015445 0.1982353  2.9419744 ]\n",
            "[0.9429396  0.33296397 2.79776   ]\n",
            "[0.88317174 0.46904972 2.9753864 ]\n",
            "[0.7917415 0.6108563 3.3785439]\n",
            "[0.6665596  0.74545175 3.6814137 ]\n"
          ]
        }
      ],
      "source": [
        "# Create Inverted Pendulum environment\n",
        "#https://gymnasium.farama.org/environments/classic_control/cart_pole/\n",
        "\n",
        "env = gym.make('Pendulum-v1', render_mode=\"rgb_array\")\n",
        "s = env.reset(seed = 34)\n",
        "print(\"Observation Space = \")\n",
        "print(env.observation_space)\n",
        "print(\"Action Space = \")\n",
        "print(env.action_space)\n",
        "done = False\n",
        "for episode in range(20):\n",
        "    print(\"In episode {}\".format(episode))\n",
        "    for i in range(100):\n",
        "        env.render()\n",
        "        print(s)\n",
        "        a = env.action_space.sample()\n",
        "        s, r, done, truncated, _ = env.step(a)\n",
        "        if done:\n",
        "            print(\"Finished after {} timestep\".format(i+1))\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bycDV6__Tqk0",
        "outputId": "a2753323-47fb-4758-b01a-f850b985a1e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.2.1\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.2.1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2376134 sha256=cfdd8c8b712ed8d07d35472240104e37e81fa2c567d74180c9c015a5aa93056b\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n",
            "Requirement already satisfied: gymnasium[mujoco] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (0.0.4)\n",
            "Collecting mujoco>=2.3.3 (from gymnasium[mujoco])\n",
            "  Downloading mujoco-3.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (2.31.6)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.14.1->gymnasium[mujoco]) (9.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (1.7.0)\n",
            "Collecting glfw (from mujoco>=2.3.3->gymnasium[mujoco])\n",
            "  Downloading glfw-2.7.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (3.1.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (3.18.1)\n",
            "Installing collected packages: glfw, mujoco\n",
            "Successfully installed glfw-2.7.0 mujoco-3.1.4\n",
            "Observation Space = \n",
            "Box(-inf, inf, (11,), float64)\n",
            "Action Space = \n",
            "Box(-1.0, 1.0, (3,), float32)\n",
            "In episode 0\n",
            "(array([ 1.25372177e+00, -2.57257612e-03,  1.51061298e-03, -1.59076170e-04,\n",
            "        2.88533494e-03,  3.80722565e-03,  3.99721996e-03,  2.09928936e-04,\n",
            "        4.64165624e-03,  4.11351193e-03,  1.77765794e-03]), {})\n",
            "[ 1.25333756e+00 -3.85801155e-03 -6.34384473e-04  7.54290150e-04\n",
            "  7.61178398e-03  9.34251766e-03 -9.88767646e-02 -3.68046399e-01\n",
            " -5.29289070e-01  1.03170197e-01  1.18506775e+00]\n",
            "[ 1.25217013e+00 -7.16913194e-03 -3.97892438e-03 -1.11779900e-03\n",
            "  2.13318673e-02 -1.83043274e-02 -1.93055896e-01 -4.59791259e-01\n",
            " -3.07138050e-01 -5.70296955e-01  2.24356003e+00]\n",
            "[ 1.25035825 -0.01399856 -0.0109072  -0.00411278  0.03658695 -0.05722987\n",
            " -0.26032126 -1.24652169 -1.42357567 -0.17913315  1.57102038]\n",
            "[ 1.24802696 -0.02199334 -0.01953035 -0.00611092  0.04584947 -0.05029136\n",
            " -0.32218559 -0.75272647 -0.73311652 -0.32026413  0.74566281]\n",
            "[ 1.24516932 -0.03256894 -0.03107186 -0.00796872  0.04956394 -0.12261364\n",
            " -0.39322591 -1.8898637  -2.15053397 -0.14462678  0.18351857]\n",
            "[ 1.24178736 -0.04700391 -0.04883427 -0.00625118  0.04530121 -0.09419291\n",
            " -0.4521828  -1.71918923 -2.28985397  0.57314287 -1.24745384]\n",
            "[ 1.23776204e+00 -5.68203061e-02 -6.40512945e-02  9.21511935e-04\n",
            "  3.87472394e-02  1.95248841e-02 -5.53148474e-01 -7.61693479e-01\n",
            " -1.50928951e+00  1.15248669e+00 -3.88358953e-01]\n",
            "[ 1.23309762 -0.06456538 -0.07566632  0.00589817  0.03344676 -0.08338496\n",
            " -0.61287365 -1.17434439 -1.3947248   0.09291797 -0.93612214]\n",
            "[ 1.2279372  -0.07877323 -0.09204586  0.00614117  0.02123218 -0.18906217\n",
            " -0.67873458 -2.37129098 -2.69976902 -0.01822714 -2.11707576]\n",
            "[ 1.22209125 -0.09827273 -0.11352292  0.00437919  0.00826756 -0.20326896\n",
            " -0.78296876 -2.50320654 -2.66955504 -0.42183621 -1.12527901]\n",
            "[ 1.21531453e+00 -1.22537360e-01 -1.40570325e-01  1.98721912e-03\n",
            "  3.34039140e-03 -2.36100401e-01 -9.13243606e-01 -3.56979007e+00\n",
            " -4.08846386e+00 -1.97963348e-01 -1.06774072e-01]\n",
            "[ 1.20806893e+00 -1.54801259e-01 -1.77304019e-01  9.60974098e-04\n",
            "  2.61098748e-03 -3.95407845e-01 -8.51571396e-01 -4.52675365e+00\n",
            " -5.07460922e+00 -6.89259627e-02  9.80320730e-02]\n",
            "[ 1.20189782e+00 -1.96154300e-01 -2.22990546e-01  7.35605711e-04\n",
            "  2.98488755e-03 -6.13706960e-01 -6.80093565e-01 -5.80738163e+00\n",
            " -6.35496086e+00  3.93896581e-03 -5.45655784e-02]\n",
            "Finished after 14 timestep\n",
            "[ 1.19721083e+00 -2.42004225e-01 -2.70902645e-01 -2.19676186e-03\n",
            "  3.74724346e-03 -7.36861719e-01 -5.02029601e-01 -5.65447899e+00\n",
            " -5.62467388e+00 -7.39108590e-01  2.40065763e-01]\n",
            "Finished after 15 timestep\n",
            "[ 1.19369162 -0.28396366 -0.31091082 -0.01055083  0.00993044 -0.70856927\n",
            " -0.38446774 -4.84092437 -4.38106288 -1.36305855  1.26697326]\n",
            "Finished after 16 timestep\n",
            "[ 1.19111254 -0.32037038 -0.34491138 -0.01789226  0.01630466 -0.6929945\n",
            " -0.26459079 -4.25873787 -4.11857446 -0.46982422  0.33783879]\n",
            "Finished after 17 timestep\n",
            "[ 1.18915609 -0.35434765 -0.37773937 -0.02147463  0.01936434 -0.71998659\n",
            " -0.22968675 -4.2365016  -4.0882448  -0.42842918  0.41870143]\n",
            "Finished after 18 timestep\n",
            "[ 1.18729343 -0.39246376 -0.41580184 -0.02298681  0.01960418 -0.83931854\n",
            " -0.2373351  -5.29199521 -5.42591912  0.05038    -0.35369437]\n",
            "Finished after 19 timestep\n",
            "[ 1.18534685 -0.43647476 -0.45999794 -0.0238641   0.0165275  -0.94268951\n",
            " -0.25163068 -5.71172492 -5.62316659 -0.27102377 -0.41919733]\n",
            "Finished after 20 timestep\n",
            "[ 1.18291519 -0.4857028  -0.50658972 -0.02997265  0.01597759 -1.07464053\n",
            " -0.36277046 -6.59658484 -6.02369389 -1.25862953  0.26995216]\n",
            "Finished after 21 timestep\n",
            "[ 1.17977449e+00 -5.42169218e-01 -5.55834959e-01 -4.43654539e-02\n",
            "  1.70402019e-02 -1.26224464e+00 -4.25014203e-01 -7.52186806e+00\n",
            " -6.28722649e+00 -2.33715852e+00  1.27986189e-03]\n",
            "Finished after 22 timestep\n",
            "[ 1.17604596 -0.6008156  -0.60703116 -0.05854161  0.01804992 -1.15013717\n",
            " -0.50893861 -7.14031497 -6.51127306 -1.21294525  0.23614939]\n",
            "Finished after 23 timestep\n",
            "[ 1.17187408 -0.65316393 -0.65440064 -0.06719203  0.02287493 -1.04411669\n",
            " -0.53104234 -5.94992615 -5.33248281 -0.9484853   0.9677737 ]\n",
            "Finished after 24 timestep\n",
            "[ 1.16780649 -0.69512116 -0.69332215 -0.07009456  0.02952803 -0.89940411\n",
            " -0.48196811 -4.53984088 -4.39993133  0.22184509  0.69655147]\n",
            "Finished after 25 timestep\n",
            "[ 1.16360675 -0.73086949 -0.72532948 -0.0729736   0.03647094 -0.95134154\n",
            " -0.56865966 -4.39908875 -3.60249936 -0.93956026  1.0374987 ]\n",
            "Finished after 26 timestep\n",
            "[ 1.15902126 -0.76226785 -0.75216721 -0.0764224   0.04737741 -0.82963454\n",
            " -0.57608848 -3.45169054 -3.10759034  0.07686175  1.68820994]\n",
            "Finished after 27 timestep\n",
            "[ 1.15427862 -0.78834199 -0.77500901 -0.07606358  0.05848345 -0.82774989\n",
            " -0.61022031 -3.06931851 -2.60283176  0.01387437  1.08733113]\n",
            "Finished after 28 timestep\n",
            "[ 1.14834381 -0.81918213 -0.80080291 -0.08004358  0.06800966 -0.93050812\n",
            " -0.87609235 -4.64002715 -3.8433752  -1.00812099  1.29344877]\n",
            "Finished after 29 timestep\n",
            "[ 1.14093779 -0.8586907  -0.83689911 -0.08387318  0.07948303 -0.82374276\n",
            " -0.94527517 -5.25171766 -5.19791991  0.00776269  1.51112741]\n",
            "Finished after 30 timestep\n",
            "[ 1.13363832 -0.90098679 -0.88199952 -0.07939418  0.09379711 -0.65205106\n",
            " -0.87649764 -5.32593143 -6.07753462  1.10736904  2.05965785]\n",
            "Finished after 31 timestep\n",
            "[ 1.12665297 -0.94544209 -0.93567981 -0.06581051  0.10863879 -0.51846532\n",
            " -0.87288846 -5.78666905 -7.33911374  2.28931902  1.6533973 ]\n",
            "Finished after 32 timestep\n",
            "[ 1.12042865 -0.9881227  -0.99059952 -0.04805974  0.12499973 -0.40476704\n",
            " -0.6793063  -4.88639702 -6.39398452  2.14820699  2.43245676]\n",
            "Finished after 33 timestep\n",
            "[ 1.11515908 -1.02712253 -1.04348924 -0.02731473  0.13850949 -0.32911044\n",
            " -0.64483728 -4.85794166 -6.8236771   3.04476506  0.95889222]\n",
            "Finished after 34 timestep\n",
            "[ 1.10973171e+00 -1.06875884e+00 -1.10122623e+00 -3.48499765e-03\n",
            "  1.49628144e-01 -2.64812746e-01 -7.12789331e-01 -5.55108106e+00\n",
            " -7.60922713e+00  2.91264874e+00  1.81919980e+00]\n",
            "Finished after 35 timestep\n",
            "[ 1.1036429  -1.11585386 -1.16115826  0.01346397  0.16427872 -0.35344082\n",
            " -0.81674183 -6.23888191 -7.36742476  1.29736223  1.85878268]\n",
            "Finished after 36 timestep\n",
            "[ 1.09690775e+00 -1.16621945e+00 -1.21696660e+00  1.86111329e-02\n",
            "  1.74953181e-01 -4.51589630e-01 -8.68726870e-01 -6.34880800e+00\n",
            " -6.58558152e+00 -5.46008297e-03  8.15830078e-01]\n",
            "Finished after 37 timestep\n",
            "[ 1.08903572 -1.22167615 -1.27368653  0.01751012  0.17796094 -0.46284617\n",
            " -1.09965159 -7.49668249 -7.59538899 -0.23569308 -0.06430536]\n",
            "Finished after 38 timestep\n",
            "[ 1.0802577  -1.27973077 -1.33158051  0.01519593  0.17190968 -0.46857239\n",
            " -1.09292292 -7.00573323 -6.88154957 -0.32355228 -1.44720178]\n",
            "Finished after 39 timestep\n",
            "[ 1.07158719 -1.33374084 -1.38305999  0.01101703  0.15476482 -0.50199711\n",
            " -1.07404912 -6.49582304 -5.99023463 -0.72084584 -2.83711003]\n",
            "Finished after 40 timestep\n",
            "[ 1.06207633e+00 -1.38901122e+00 -1.43240810e+00  1.38521644e-03\n",
            "  1.37302285e-01 -4.95745691e-01 -1.30481602e+00 -7.31992336e+00\n",
            " -6.34575732e+00 -1.68728732e+00 -1.53013953e+00]\n",
            "Finished after 41 timestep\n",
            "[ 1.05173024 -1.4444217  -1.47987591 -0.01153898  0.12562842 -0.4653137\n",
            " -1.28043943 -6.53156474 -5.52297761 -1.54340982 -1.38812773]\n",
            "Finished after 42 timestep\n",
            "[ 1.04110645 -1.49679589 -1.52517631 -0.02178305  0.11422724 -0.39970247\n",
            " -1.37475618 -6.5622262  -5.80185822 -1.01830131 -1.46195727]\n",
            "Finished after 43 timestep\n",
            "[ 1.02932167 -1.55262147 -1.57278306 -0.03370495  0.10135518 -0.41456189\n",
            " -1.57216236 -7.39620524 -6.09889605 -1.96170376 -1.75617589]\n",
            "Finished after 44 timestep\n",
            "[ 1.01663841 -1.60991648 -1.61740131 -0.05312518  0.0910037  -0.43989477\n",
            " -1.59909123 -6.92586053 -5.05703125 -2.89170015 -0.8328434 ]\n",
            "Finished after 45 timestep\n",
            "[ 1.00382713 -1.66327671 -1.65735071 -0.0728944   0.08349288 -0.37479074\n",
            " -1.60229121 -6.41392289 -4.93116991 -2.05146031 -1.04415745]\n",
            "Finished after 46 timestep\n",
            "[ 0.99040043 -1.71665189 -1.69972013 -0.08758177  0.07416543 -0.29575291\n",
            " -1.75347585 -6.9313309  -5.66022276 -1.62141651 -1.28741828]\n",
            "Finished after 47 timestep\n",
            "[ 0.97695178 -1.76658478 -1.7400151  -0.09862863  0.06186066 -0.31728279\n",
            " -1.60855351 -5.54948676 -4.41572405 -1.13987156 -1.78776686]\n",
            "Finished after 48 timestep\n",
            "[ 0.96312618 -1.81528139 -1.77977725 -0.10786333  0.05297241 -0.23275844\n",
            " -1.82703113 -6.65271448 -5.53777388 -1.15150813 -0.35719146]\n",
            "Finished after 49 timestep\n",
            "[ 0.94803246 -1.87092668 -1.82835315 -0.11413602  0.05578692 -0.10257917\n",
            " -1.944194   -7.2553028  -6.60380875 -0.4390161   1.00433158]\n",
            "Finished after 50 timestep\n",
            "[ 0.93227924 -1.93491583 -1.8857126  -0.11953762  0.06293872 -0.02214404\n",
            " -1.99935524 -8.73775503 -7.72954103 -0.90880796  0.78419615]\n",
            "Finished after 51 timestep\n",
            "[ 0.91788837 -1.99871561 -1.94342462 -0.12429597  0.07213709  0.06871676\n",
            " -1.59438511 -7.21429847 -6.70121435 -0.28438776  1.50417776]\n",
            "Finished after 52 timestep\n",
            "[ 0.90615251 -2.05444171 -1.99598717 -0.12573677  0.08680452  0.17788741\n",
            " -1.33781376 -6.71717229 -6.43957186 -0.07668633  2.15839515]\n",
            "Finished after 53 timestep\n",
            "[ 0.89579255 -2.10965555 -2.04787502 -0.1279668   0.10192457  0.23773726\n",
            " -1.25638904 -7.08244758 -6.52925031 -0.47366995  1.63348031]\n",
            "Finished after 54 timestep\n",
            "[ 0.88691897 -2.16304471 -2.09918522 -0.12871472  0.11796679  0.35911871\n",
            " -0.95974959 -6.26228428 -6.29859836  0.28395734  2.37059254]\n",
            "Finished after 55 timestep\n",
            "[ 0.87896473 -2.2179969  -2.15194197 -0.12975062  0.13298493  0.42008179\n",
            " -1.03509609 -7.47150429 -6.88608947 -0.53222697  1.40400504]\n",
            "Finished after 56 timestep\n",
            "[ 0.87112017 -2.27648672 -2.20365979 -0.13721015  0.14336818  0.3780626\n",
            " -0.93048354 -7.14719047 -6.04248544 -1.32638837  1.1998659 ]\n",
            "Finished after 57 timestep\n",
            "[ 0.86432768 -2.33095736 -2.25018498 -0.1463501   0.15211748  0.3979318\n",
            " -0.76936044 -6.4662415  -5.58842038 -0.95723985  0.98982253]\n",
            "Finished after 58 timestep\n",
            "[ 0.85734965 -2.38986574 -2.29862053 -0.1584663   0.15674196  0.47954668\n",
            " -0.97539246 -8.25633084 -6.51845521 -2.06848488  0.17638988]\n",
            "Finished after 59 timestep\n",
            "[ 0.84899669 -2.46056599 -2.35224303 -0.17926585  0.15640406  0.52800047\n",
            " -1.11015075 -9.4171842  -6.88693958 -3.13191553 -0.25977957]\n",
            "Finished after 60 timestep\n",
            "[ 0.84018188 -2.53625596 -2.4070789  -0.20551171  0.15953033  0.60528517\n",
            " -1.08701445 -9.50411696 -6.82320041 -3.43640177  1.02881917]\n",
            "Finished after 61 timestep\n",
            "[  0.8311572   -2.6176357   -2.46658508  -0.23244195   0.1655952\n",
            "   0.77781462  -1.16350842 -10.          -8.05218648  -3.29713917\n",
            "   0.49154427]\n",
            "Finished after 62 timestep\n",
            "[  0.8224471   -2.70147061  -2.53045641  -0.25434971   0.16520514\n",
            "   0.79421823  -1.01414012 -10.          -7.91541679  -2.18118045\n",
            "  -0.58907232]\n",
            "Finished after 63 timestep\n",
            "[ 0.81486165 -2.78084675 -2.59323442 -0.27070493  0.16370946  0.85387033\n",
            " -0.87685413 -9.72881886 -7.77877725 -1.91387284  0.20299168]\n",
            "Finished after 64 timestep\n",
            "[ 0.80842963 -2.85479365 -2.65100624 -0.28778839  0.16827805  0.59546472\n",
            " -0.65613121 -7.16111753 -5.14050142 -2.43551609  0.94601291]\n",
            "Finished after 65 timestep\n",
            "[ 0.80437813 -2.89419232 -2.67662204 -0.30566171  0.17510391  0.204725\n",
            " -0.3829641  -3.07973047 -1.64163565 -2.01372607  0.7534507 ]\n",
            "Finished after 66 timestep\n",
            "[ 0.80161919 -2.91131267 -2.68162559 -0.32342174  0.17867772 -0.01179816\n",
            " -0.3225319  -1.42829881  0.17143046 -2.40994862  0.14601277]\n",
            "Finished after 67 timestep\n",
            "[ 0.79949038 -2.91648772 -2.67688326 -0.33828614  0.17492898 -0.10435254\n",
            " -0.21648563  0.01850673  0.90190944 -1.2998094  -1.07742628]\n",
            "Finished after 68 timestep\n",
            "[ 0.79812505 -2.91161608 -2.66779498 -0.34437128  0.16272587 -0.1585115\n",
            " -0.12544146  1.19903679  1.36890905 -0.22201867 -1.96968741]\n",
            "Finished after 69 timestep\n",
            "[ 0.79680486 -2.9043621  -2.6574668  -0.34890477  0.14818316 -0.11711149\n",
            " -0.20638355  0.60188201  1.2012657  -0.90861061 -1.6650613 ]\n",
            "Finished after 70 timestep\n",
            "[ 0.79467171 -2.9027165  -2.6487636  -0.35904772  0.13120554 -0.10761591\n",
            " -0.32791777 -0.18461669  0.97567996 -1.62621181 -2.57762849]\n",
            "Finished after 71 timestep\n",
            "[ 0.79188818 -2.90620838 -2.64176152 -0.37413916  0.11662205 -0.08375636\n",
            " -0.34938665 -0.69164338  0.77755301 -2.14290965 -1.0136263 ]\n",
            "Finished after 72 timestep\n",
            "[ 0.78973361 -2.90841247 -2.63414997 -0.38812068  0.11002179 -0.1885408\n",
            " -0.19152648  0.14688637  1.12669897 -1.35793239 -0.65306017]\n",
            "Finished after 73 timestep\n",
            "[ 0.78805123 -2.90713924 -2.62247533 -0.40332448  0.10909243 -0.28736915\n",
            " -0.23516286  0.17722331  1.79434029 -2.44391252  0.39799016]\n",
            "Finished after 74 timestep\n",
            "[ 0.78628383 -2.908163   -2.61261152 -0.42025003  0.11640169 -0.0877737\n",
            " -0.20068619 -0.43587945  0.67354129 -1.79701421  1.41308435]\n",
            "Finished after 75 timestep\n",
            "[ 0.78452738 -2.91142342 -2.60470731 -0.43775856  0.12601308 -0.21044641\n",
            " -0.24185918 -0.38013548  1.30039452 -2.5712166   1.01027645]\n",
            "Finished after 76 timestep\n",
            "[ 0.78314485 -2.90791928 -2.59075081 -0.45524875  0.1377922  -0.26257755\n",
            " -0.09673053  1.25127796  2.18765569 -1.81147942  1.92215874]\n",
            "Finished after 77 timestep\n",
            "[ 0.78303091 -2.89164695 -2.56943644 -0.46767471  0.15724908 -0.31062639\n",
            "  0.07499173  2.8108531   3.13958787 -1.30389224  2.931242  ]\n",
            "Finished after 78 timestep\n",
            "[ 0.78319029 -2.87031512 -2.54208712 -0.48290203  0.1763153  -0.39413112\n",
            " -0.04173891  2.52644123  3.69700398 -2.49258636  1.84946581]\n",
            "Finished after 79 timestep\n",
            "[ 0.78313093 -2.84673356 -2.51063839 -0.50049687  0.18803804 -0.45158312\n",
            "  0.02750487  3.36811874  4.16407027 -1.90686853  1.0847424 ]\n",
            "Finished after 80 timestep\n",
            "[ 0.78314242 -2.82257552 -2.47941429 -0.51732958  0.20089022 -0.33193189\n",
            " -0.02312053  2.67097574  3.64264909 -2.30475219  2.12091635]\n",
            "Finished after 81 timestep\n",
            "[ 0.78291008 -2.7976863  -2.44583654 -0.53694378  0.21279343 -0.48906048\n",
            " -0.03650459  3.55489267  4.75030693 -2.59566078  0.86200132]\n",
            "Finished after 82 timestep\n",
            "[ 0.78252225 -2.77255721 -2.4124091  -0.55507522  0.217894   -0.3424304\n",
            " -0.06024879  2.7289039   3.60749079 -1.93990899  0.41190564]\n",
            "Finished after 83 timestep\n",
            "[ 0.78172818 -2.75542088 -2.3887863  -0.56876555  0.21797486 -0.19071067\n",
            " -0.14013335  1.55777292  2.29965709 -1.48154541 -0.38877036]\n",
            "Finished after 84 timestep\n",
            "[ 0.7800223  -2.74565328 -2.37011008 -0.58498397  0.2174657  -0.21514239\n",
            " -0.28894539  0.88794191  2.36967952 -2.56857517  0.26365117]\n",
            "Finished after 85 timestep\n",
            "[ 0.77699412 -2.74457157 -2.35365142 -0.60980542  0.2190496  -0.1912443\n",
            " -0.46959318 -0.61468392  1.74630367 -3.63442874  0.13280567]\n",
            "Finished after 86 timestep\n",
            "[ 0.77336372 -2.75420674 -2.34561622 -0.63514627  0.21693748 -0.10262319\n",
            " -0.43419724 -1.79443575  0.26283738 -2.70510973 -0.65383549]\n",
            "Finished after 87 timestep\n",
            "[ 0.76990929 -2.76801255 -2.34145981 -0.65841859  0.21091617 -0.23751516\n",
            " -0.42979581 -1.65764106  0.7757406  -3.11274614 -0.84958995]\n",
            "Finished after 88 timestep\n",
            "[ 0.76710281 -2.77630264 -2.33166352 -0.68087683  0.20364043 -0.42884339\n",
            " -0.27123196 -0.41543202  1.67183437 -2.50470566 -0.96855044]\n",
            "Finished after 89 timestep\n",
            "[ 0.76488208 -2.78581933 -2.32382244 -0.7000174   0.19253121 -0.36212105\n",
            " -0.28229349 -1.9660912   0.28965342 -2.28162858 -1.80344619]\n",
            "Finished after 90 timestep\n",
            "[ 0.76237465 -2.80360154 -2.32025553 -0.72214944  0.17622464 -0.48527904\n",
            " -0.3459902  -2.48166595  0.60249305 -3.24915417 -2.27166916]\n",
            "Finished after 91 timestep\n",
            "[ 0.75966056 -2.82320164 -2.31504952 -0.74789676  0.15902014 -0.54786201\n",
            " -0.33509988 -2.41401184  0.70042267 -3.18801748 -2.03976319]\n",
            "Finished after 92 timestep\n",
            "[ 0.75705087 -2.84342493 -2.30882998 -0.77424335  0.13951341 -0.66354627\n",
            " -0.31718163 -2.64559974  0.85433017 -3.39885402 -2.83174656]\n",
            "Finished after 93 timestep\n",
            "[ 0.75462852 -2.8694237  -2.3062334  -0.80015421  0.11305375 -0.63813237\n",
            " -0.28648925 -3.85690425 -0.20377279 -3.08112176 -3.78030659]\n",
            "Finished after 94 timestep\n",
            "[ 0.75170761 -2.90667601 -2.31022977 -0.8290275   0.08064259 -0.61241514\n",
            " -0.44539629 -5.45731571 -0.79236979 -4.13401365 -4.32778869]\n",
            "Finished after 95 timestep\n",
            "[ 0.74828852 -2.94859    -2.31437916 -0.86190022  0.0455211  -0.73567807\n",
            " -0.41251701 -5.01880658 -0.24428493 -4.08374163 -4.45898218]\n",
            "Finished after 96 timestep\n",
            "[ 0.74486558 -2.9847085  -2.31315563 -0.89430157  0.01491625 -0.80832322\n",
            " -0.44915452 -4.00579415  0.55117354 -4.01272334 -3.20804609]\n",
            "Finished after 97 timestep\n",
            "[ 0.74145802 -3.01350211 -2.30674812 -0.92427416 -0.0113293  -0.9112474\n",
            " -0.40349701 -3.19388507  1.05006613 -3.48170565 -3.35378381]\n",
            "Finished after 98 timestep\n",
            "[ 0.73853102 -3.03437315 -2.29701614 -0.94808942 -0.03259309 -0.96375207\n",
            " -0.32788672 -2.02583449  1.38180452 -2.47434998 -1.96399434]\n",
            "Finished after 99 timestep\n",
            "[ 0.73582323 -3.05035889 -2.2871807  -0.96601114 -0.04614946 -0.92521667\n",
            " -0.34908768 -1.97250714  1.0773638  -2.00606276 -1.42611742]\n",
            "Finished after 100 timestep\n"
          ]
        }
      ],
      "source": [
        "!pip install swig\n",
        "!pip install gymnasium[box2d]\n",
        "!pip install gymnasium[mujoco]\n",
        "\n",
        "# Create Hopper environment\n",
        "# https://gymnasium.farama.org/environments/mujoco/hopper/\n",
        "\n",
        "\n",
        "import gymnasium as gym\n",
        "env = gym.make(\"Hopper-v4\", render_mode = \"rgb_array\")\n",
        "s = env.reset(seed = 34)\n",
        "print(\"Observation Space = \")\n",
        "print(env.observation_space)\n",
        "print(\"Action Space = \")\n",
        "print(env.action_space)\n",
        "done = False\n",
        "for episode in range(1):\n",
        "    print(\"In episode {}\".format(episode))\n",
        "    for i in range(100):\n",
        "        # env.render()\n",
        "        print(s)\n",
        "        a = env.action_space.sample()\n",
        "        s, r, done, truncated, _ = env.step(a)\n",
        "        if done:\n",
        "            print(\"Finished after {} timestep\".format(i+1))\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwR9tHKFTqk0",
        "outputId": "e6da7dba-a505-4f00-b291-87a0a0763891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (4.2.1)\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.2.1)\n",
            "Requirement already satisfied: gymnasium[mujoco] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (0.0.4)\n",
            "Requirement already satisfied: mujoco>=2.3.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (3.1.4)\n",
            "Requirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[mujoco]) (2.31.6)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.14.1->gymnasium[mujoco]) (9.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (1.7.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (2.7.0)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium[mujoco]) (3.1.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium[mujoco]) (3.18.1)\n",
            "Observation Space = \n",
            "Box(-inf, inf, (17,), float64)\n",
            "Action Space = \n",
            "Box(-1.0, 1.0, (6,), float32)\n",
            "In episode 0\n",
            "(array([ 0.07443538, -0.05145152,  0.03021226, -0.00318152,  0.0577067 ,\n",
            "        0.07614451,  0.0799444 ,  0.00419858, -0.06093145,  0.06146804,\n",
            "        0.04904031, -0.01182644, -0.07192433, -0.08793664, -0.10080283,\n",
            "        0.02766291, -0.03509065]), {})\n",
            "[ 0.06679258 -0.0362546   0.01943762 -0.19368414 -0.22705751  0.21034121\n",
            "  0.19555646  0.1499971   0.12118955 -0.39164957  0.37853089 -1.02171845\n",
            " -4.84149079 -6.79503003  4.07386906  3.55689926  4.26483499]\n",
            "[ 2.35972850e-02  5.56441208e-03 -2.68574705e-01 -4.21710169e-01\n",
            " -7.30680366e-02  3.76007537e-01  2.78877554e-01  3.56175524e-01\n",
            " -5.25750209e-01 -1.21001049e+00  8.33084458e-01 -7.30228618e+00\n",
            " -3.96110631e+00  6.57902235e+00  2.83477138e+00  8.37299957e-01\n",
            "  3.44815986e+00]\n",
            "[-0.02790122  0.01865662 -0.3633514  -0.46965193  0.4189703   0.13300614\n",
            "  0.36039291  0.54423257 -0.34363297 -0.9642831   0.1299182   1.43954192\n",
            "  0.99692147  8.31275868 -8.09383836  0.7505241  -0.61854627]\n",
            "[-5.61912704e-02  7.65346198e-03 -2.09056635e-01 -2.92354128e-01\n",
            " -1.51286457e-01  3.83396978e-02  7.33873320e-02  4.59384481e-01\n",
            " -2.16544953e-02 -3.50513761e-01 -7.23304376e-01  4.74574196e+00\n",
            "  4.51815755e+00 -1.42128485e+01  1.00881419e+00 -7.40826981e+00\n",
            " -2.48821119e+00]\n",
            "[-0.07848935 -0.01428059  0.16838211 -0.33986004 -0.49145145  0.17677214\n",
            " -0.26503137  0.38392476  0.35512785 -0.2332843   0.25956075  5.21400785\n",
            " -2.84972825 -8.52900504  2.45431605 -4.81980656 -0.76863202]\n",
            "[-0.1007906  -0.01660912  0.14985798  0.0234075  -0.41990884  0.12555926\n",
            " -0.28757782  0.09805121 -0.067817   -0.68979927 -0.33372077 -0.80768157\n",
            "  9.62559379  1.85692952 -2.55466006  1.52416656 -7.51940994]\n",
            "[-0.14827927 -0.03645278  0.18577882  0.44176115 -0.06985424 -0.13085448\n",
            " -0.16626985  0.09812514 -0.12840344 -1.10841425 -0.18108262  2.10255157\n",
            "  5.62410314  7.56602264 -5.59712472  1.83529252  4.06161789]\n",
            "[-2.09882270e-01  2.33597335e-03 -1.23858297e-01  5.49127341e-01\n",
            "  2.39136361e-01 -1.47604411e-01 -2.11335433e-01 -1.88375563e-01\n",
            " -3.96528207e-01 -1.24678778e+00  9.08904324e-01 -9.17110005e+00\n",
            " -3.67659555e-01  3.23164107e+00  2.86065659e+00 -3.97998510e+00\n",
            " -1.15671452e+01]\n",
            "[-0.25248715  0.10566735 -0.33831072  0.53524711 -0.01588644  0.08655621\n",
            " -0.61107626 -0.36003968  0.02877637 -0.46960699  2.76082824 -1.43805059\n",
            " -0.5616382  -8.23719462  4.21185172 -8.99551385  0.50326544]\n",
            "[-2.13600633e-01  2.65993574e-01  8.36262449e-03 -2.09166083e-01\n",
            " -4.66499940e-01 -7.58301085e-02 -7.34451336e-01 -3.29005704e-01\n",
            " -1.05483140e-01  1.12237635e+00  2.43980695e+00  8.19581840e+00\n",
            " -1.75469906e+01 -6.53785770e+00 -5.71031305e+00  1.10426062e+00\n",
            "  7.37067998e-01]\n",
            "[-0.18191049  0.29347945 -0.06363428 -0.40364884 -0.19753592  0.05887368\n",
            " -0.77864753 -0.26995669 -0.48195195  0.62987946  0.10356082 -5.43465137\n",
            "  4.82682171  5.84725169  6.57854314 -1.09892188  1.46305525]\n",
            "[-0.13330519  0.2406035  -0.07000348 -0.35128904  0.06435249  0.22766358\n",
            " -0.51784888 -0.35841359  0.12640123  1.11519972 -1.5490001   2.74837463\n",
            " -0.58630707  3.38908053  1.74132735  9.65219031 -1.214425  ]\n",
            "[ -0.05711961   0.11940251  -0.11547446  -0.29127621   0.09763461\n",
            "  -0.24648734   0.20193576  -0.41285934  -1.33698947   1.43536953\n",
            "  -2.2893406   -2.58497697   1.12205734  -0.90201399 -12.53561709\n",
            "  16.15153598   1.97374342]\n",
            "[ -0.03111652   0.03231094  -0.21996096  -0.06955282   0.05353058\n",
            "  -0.46742258   0.07376621  -0.31630094  -0.57661704   0.13116756\n",
            "  -1.4991522   -0.70096315   4.72886515  -0.58887098  -0.44034903\n",
            " -11.53289076   1.16604551]\n",
            "[-0.0331213  -0.08117253 -0.30334468  0.13803954  0.31977704 -0.40184366\n",
            " -0.15287311 -0.01049261 -0.36614912 -0.07927781 -2.6770853  -1.50978013\n",
            "  2.51592716  6.58352503  2.48853867  0.21023188  7.76491152]\n",
            "[ 1.89863588e-02 -9.43246514e-02 -2.36039488e-02 -1.83943404e-01\n",
            "  2.14700721e-01 -3.48625626e-01  3.76957516e-03  2.15713107e-01\n",
            "  2.62398132e-01  1.34429340e+00  6.38063393e-01  7.75011193e+00\n",
            " -9.82830317e+00 -4.35556664e+00  5.86219671e-01  4.18791780e+00\n",
            "  2.16643227e+00]\n",
            "[ 0.04156653 -0.1571871   0.20555443  0.04151951  0.29444913 -0.35759014\n",
            "  0.45898761  0.31802014  0.33285025 -0.06460304 -1.93014113  3.81758926\n",
            " 10.03350917  4.61093912 -0.2729194   9.25642371  1.86208569]\n",
            "[ 1.03521854e-02 -1.94040040e-01  1.68632190e-01  5.32382894e-01\n",
            "  1.19715568e-01  1.43682496e-01 -8.05593508e-02 -1.08160718e-02\n",
            "  7.81573018e-02 -8.33813225e-01  4.68741949e-01 -3.86138667e+00\n",
            "  6.81056994e+00 -6.35214217e+00  1.26199757e+01 -1.63169226e+01\n",
            " -1.02123075e+01]\n",
            "[ -0.01051062  -0.11410458   0.16666091   0.24493108   0.21899902\n",
            "   0.23582112  -0.44948389  -0.26851264  -0.31372009  -0.2424543\n",
            "   1.79657287   1.89957937 -10.35005035   5.24006675  -4.80514553\n",
            "  -2.21540404  -1.74152602]\n",
            "[-1.49096423e-02  4.98613685e-03  8.09705978e-02 -2.68055300e-01\n",
            "  2.19951127e-01  3.74779675e-02 -6.50110926e-03 -4.84028432e-01\n",
            " -3.49750299e-01  4.22211998e-02  3.18393471e+00 -3.05004079e+00\n",
            " -3.28325105e+00 -2.21722427e+00 -2.34534923e+00  1.24379049e+01\n",
            " -4.51508979e+00]\n",
            "[-0.04736037  0.16029683  0.18091003 -0.442994   -0.25212161  0.23607598\n",
            "  0.08409476 -0.463829    0.56391314 -1.13944736  2.97823687  3.59562887\n",
            " -2.29447811 -9.85297971  6.70068721 -3.25471736  2.86290258]\n",
            "[-0.0614246   0.18142781  0.2427569  -0.11829313 -0.40935464  0.27269499\n",
            " -0.13038639 -0.15039442 -0.68919828  0.36612771 -0.82975827  0.83311958\n",
            "  8.50477097  1.35714846 -2.97541055 -2.21283062  9.32676057]\n",
            "[-0.04096126  0.116312    0.11806317  0.45846183 -0.38320132  0.01216633\n",
            " -0.04367203  0.21117172 -1.41548714  0.41327516 -1.09866037 -3.22919607\n",
            "  9.30450172 -0.18504899 -6.06367991  3.3740627   5.12557556]\n",
            "[-1.08096733e-02  1.37959989e-01 -5.69338176e-02  2.41733609e-01\n",
            "  1.00569095e-01 -1.74242697e-01  5.73569592e-02  3.15657503e-01\n",
            " -9.00020293e-01  5.91988171e-01  9.53167461e-01 -2.60486108e+00\n",
            " -9.80870719e+00  1.15013980e+01 -1.71458862e+00  5.78277069e-01\n",
            " -8.45589196e-02]\n",
            "[ 0.00673469  0.15630601 -0.0421229  -0.15044016  0.46910504 -0.37953961\n",
            "  0.17057038  0.35731225 -1.07145259  0.07864741 -0.19910873  1.11445192\n",
            " -4.44319912  3.16111538 -4.33990042  2.41466958  1.39849402]\n",
            "[-0.03391537  0.05055256  0.20267144  0.14144697  0.09725698 -0.18361791\n",
            "  0.06565303  0.38338979 -0.08299222 -1.26274428 -2.95197801  7.18150099\n",
            "  9.39968094 -9.41758181  7.0338923  -3.20728408  0.06833436]\n",
            "[-6.54616378e-02 -8.19232633e-04  3.65670288e-01 -5.96599290e-02\n",
            "  2.53362686e-01 -2.34468392e-01  2.03990154e-01  4.66835706e-01\n",
            " -1.21549835e+00  4.37623378e-03 -8.77494159e-01  1.99602502e-01\n",
            " -8.79880833e+00  7.80331774e+00 -3.07846534e+00  1.43925835e+00\n",
            "  2.84847998e+00]\n",
            "[-9.09051862e-02 -4.47879500e-04  3.18965605e-02  4.94082835e-02\n",
            "  3.85817034e-01 -7.86273305e-02 -2.90731868e-01  2.93687276e-01\n",
            " -1.41401321e+00 -7.06692607e-01  5.69699344e-01 -8.57783912e+00\n",
            "  6.06738759e+00 -6.02777936e-01  5.28322674e+00 -1.23790405e+01\n",
            " -6.55364924e+00]\n",
            "[-1.34046859e-01 -1.92036138e-02 -2.53311605e-03  2.80155334e-01\n",
            "  1.49225617e-01  7.91337067e-02 -4.33799476e-01 -3.42069865e-01\n",
            " -6.67513111e-01 -8.93504916e-01 -7.84114507e-01  3.91885386e+00\n",
            "  3.08487397e+00 -5.04096394e+00  1.24130883e+00  2.25105689e+00\n",
            " -1.39179249e+01]\n",
            "[-1.48028400e-01  3.91098930e-02  5.29988226e-02  1.38354054e-01\n",
            " -1.25014810e-01 -2.12859848e-02 -9.64277175e-02 -5.06924956e-01\n",
            " -9.20325086e-01 -9.37328458e-04  2.40508909e+00 -7.48765412e-01\n",
            " -5.34649439e+00 -3.94304692e+00 -3.00508785e+00  7.59246333e+00\n",
            "  3.01406284e+00]\n",
            "[-0.11349311  0.17881195  0.01592016 -0.31365571  0.06525539 -0.19557112\n",
            " -0.21424504 -0.29996878 -1.17959737  0.83571455  2.65976256 -0.95223778\n",
            " -9.21895756  6.44893799 -3.90962428 -3.94296202  6.36107549]\n",
            "[-0.12778303  0.20127508 -0.15085453  0.07536738  0.37262659  0.10056097\n",
            " -0.56610956 -0.12271932 -0.43216561 -0.80030953 -0.46847984 -2.50663209\n",
            " 12.56088198  4.4919876   9.98518315 -6.03537087  1.37808717]\n",
            "[-0.12947216  0.14004272  0.12356063  0.42798526  0.02227692 -0.03677992\n",
            " -0.45612422  0.12163275 -1.32456276  0.43542522 -1.68961823  8.79863079\n",
            "  3.69025405 -9.80796411 -8.93536439  5.08862651  5.90613298]\n",
            "[-0.11301922  0.15102702  0.06366277  0.38890799 -0.23072754 -0.56164956\n",
            " -0.26481748  0.28194324 -2.10469     0.17801437  1.14313639 -6.07354353\n",
            " -3.21812141 -1.89963581 -9.1379117   1.75409159  0.99605757]\n",
            "[-0.11391736  0.1535519  -0.15341315  0.17369142  0.17663722 -0.65086827\n",
            "  0.02737136 -0.05233209 -1.29854636 -0.21455839 -0.76213199 -2.6386305\n",
            " -3.7596371  10.30491363  2.90355637  6.60805216 -9.46461523]\n",
            "[-0.14209337  0.02110238  0.04168964  0.15457091  0.16034502 -0.18990054\n",
            "  0.13832875 -0.46675049 -0.23491641 -0.84398265 -3.39029962  6.33791003\n",
            "  1.61396709 -4.82977823 11.27564872  2.4804672  -4.28631226]\n",
            "[-0.14317217 -0.08022578  0.37198007  0.19931156 -0.09724741  0.05508334\n",
            "  0.2765896  -0.48495854 -0.0539111   0.19442397 -1.42498446  6.08375263\n",
            " -0.41560146 -2.08945419  1.66697629  4.53843444  1.70330911]\n",
            "[ -0.12742736  -0.0577471    0.08784852   0.26619753  -0.23328282\n",
            "  -0.23794496   0.3042557   -0.30090044  -1.95175942   0.24324733\n",
            "   1.48660814 -10.37252942   0.50350786  -2.8758761   -8.81306989\n",
            "  -1.41127888   4.78027703]\n",
            "[-1.36291619e-01  1.45183172e-02  5.67536342e-02  8.50143700e-02\n",
            " -4.38579645e-01 -5.36248138e-01 -1.02655153e-01 -3.21410395e-03\n",
            " -6.24703281e-01 -4.39729452e-01  1.20914784e+00  3.95621731e+00\n",
            " -3.90019555e+00 -1.42258672e-01 -4.48760819e+00 -9.89479296e+00\n",
            "  5.19578486e+00]\n",
            "[-0.1248792   0.05367216  0.2219864  -0.15086142 -0.34087882 -0.35972571\n",
            " -0.1565489   0.22298598  0.52177292  0.53255032  0.6031975   2.25048416\n",
            " -3.86101351  3.80365603  7.68862527  4.51239746  3.67904176]\n",
            "[-1.18143738e-01 -9.01403015e-03  3.09490291e-01  5.92901206e-02\n",
            " -1.86211624e-01  1.75260640e-01 -9.61972492e-02 -2.69319311e-01\n",
            "  7.81360620e-01 -1.33216484e-01 -1.85548075e+00  1.76625946e+00\n",
            "  6.34783712e+00  2.58107302e+00  1.14311616e+01  3.68395334e+00\n",
            " -1.24895440e+01]\n",
            "[-0.12222502  0.03792724  0.20439984 -0.02736521  0.1403443   0.71697593\n",
            " -0.27880997 -0.48664104  0.21321813  0.09596192  2.65506483 -3.70470729\n",
            " -3.64993201  6.15812195  8.76052927 -5.55190967  0.76527091]\n",
            "[-0.11453568  0.15995084 -0.16269941 -0.03412508 -0.02346873  0.68316923\n",
            " -0.38235704  0.05792568 -0.60622255 -0.04974599  2.25340548 -7.83445752\n",
            "  0.50008066 -7.2129104  -2.18270668 -1.57964445 14.35007861]\n",
            "[-0.13328344  0.19462431 -0.49202503  0.23048852 -0.44042004  0.61251307\n",
            " -0.26410419  0.48974429  0.05129708 -0.24986053 -0.25220619 -4.44059263\n",
            "  5.51536774 -1.26777972  0.55183272  1.86488782  3.67078414]\n",
            "[-0.08801103  0.20372068 -0.51850211  0.06990099  0.08144563  0.42616291\n",
            " -0.10678052  0.52610921 -0.06925663  1.4092653   0.32754164  1.22793905\n",
            " -6.16734804 13.02714154 -4.8995974   3.91747078 -0.26467326]\n",
            "[ -0.04305014   0.20605733  -0.29363768  -0.13319531  -0.09423009\n",
            "   0.39146675   0.11893606  -0.03867138   0.3942592    0.46287828\n",
            "  -0.25743825   4.75780427  -1.43656222  -9.97855442   1.51576669\n",
            "   3.56615448 -15.62076358]\n",
            "[ -0.02019198   0.1860886   -0.04506451  -0.05708367   0.1004156\n",
            "   0.02132403   0.1520824   -0.54930325  -0.27678477   0.23591525\n",
            "  -0.32698485   4.7158968    3.2179156    9.49813667 -11.63937559\n",
            "  -2.27460581  -5.84049319]\n",
            "[-0.05031194  0.15982233  0.16414406  0.13631443  0.25162614 -0.12431309\n",
            " -0.21052529 -0.266296    0.26174243 -0.93122712 -0.71572685  3.59057004\n",
            "  3.53135924 -0.60753336  2.10696863 -7.80938014  8.77742759]\n",
            "[-1.04881827e-01  1.39902784e-01  5.06235824e-02  4.75320378e-01\n",
            "  2.66911754e-01 -4.37596790e-01 -2.48603317e-01  1.09323367e-01\n",
            " -8.38184396e-01 -1.22045865e+00  3.95710190e-03 -4.31865102e+00\n",
            "  6.17826097e+00  5.28451202e-01 -9.37001353e+00  2.41882105e+00\n",
            "  5.48768672e+00]\n",
            "[-1.40476230e-01  1.19893216e-01  4.20170372e-01 -1.14182106e-02\n",
            " -2.07284583e-01 -3.82143931e-01 -2.05717332e-01  1.41593957e-01\n",
            "  6.91824952e-01 -4.71166598e-01 -1.48877484e+00  1.01698782e+01\n",
            " -1.46795620e+01 -1.11967906e+01  6.14081823e+00 -2.79015673e+00\n",
            " -3.66742621e+00]\n",
            "[-1.54532297e-01  1.63428748e-01  2.03497434e-01 -2.64206290e-01\n",
            " -2.89396583e-01 -4.84407584e-01 -2.83609233e-01  1.34566720e-01\n",
            " -1.33564094e+00  9.35396285e-04  2.54532747e+00 -8.84179632e+00\n",
            "  3.44027259e+00  2.04509806e+00 -5.71034979e+00 -1.76424963e+00\n",
            "  1.32292774e+00]\n",
            "[-0.16841516  0.13813083 -0.0413262   0.18566162  0.01770188 -0.38374914\n",
            " -0.27833242 -0.04612248 -0.2006752  -0.33444956 -2.07317969 -0.991955\n",
            "  8.72833945  6.39701037  5.69674959  1.3520594  -5.58666146]\n",
            "[-0.17901911  0.08939737  0.11268905  0.12376131  0.03255858 -0.26320181\n",
            " -0.21977547 -0.21704364 -0.17489293 -0.22882118 -0.44250187  3.91468842\n",
            " -5.13608682 -2.55303504  0.32310366  0.85839549 -1.56215852]\n",
            "[-1.88491301e-01  3.84342112e-03  1.70554877e-01  2.83871674e-01\n",
            " -9.37835173e-02 -2.24237717e-01  2.83365407e-02 -4.59566120e-01\n",
            " -2.32292482e-01 -1.69641759e-01 -2.28451763e+00  1.42159207e-01\n",
            "  5.23294147e+00 -8.91640626e-01  1.03475324e+00  6.41805617e+00\n",
            " -5.29678314e+00]\n",
            "[-0.16340867 -0.04437012  0.01832168  0.35146994  0.31559602  0.04326976\n",
            "  0.01125257 -0.31750327  0.35255793  0.84523365 -0.1924916  -3.79084398\n",
            " -1.56887959 11.20959806  7.21270758 -1.80569685  7.66010535]\n",
            "[ -0.08605772   0.03748005   0.33129046  -0.21133977  -0.03556059\n",
            "  -0.07665129  -0.04701357  -0.0455739    0.25665058   1.52515463\n",
            "   2.09136316   8.353141   -14.89722612 -14.21628622  -7.09410881\n",
            "   0.33144908   4.67429121]\n",
            "[-0.05539113  0.12363543  0.2124254  -0.23226941  0.12985707 -0.24778493\n",
            " -0.3815783   0.03179115 -0.34171111  0.18672191  1.49116155 -6.58962633\n",
            "  6.04943368 10.2161644  -1.32680661 -8.69017744 -0.76513451]\n",
            "[-5.09316254e-02  1.47584020e-01 -7.77294505e-02 -2.27585005e-03\n",
            " -9.29181182e-03 -7.00996851e-02 -2.51093080e-01 -2.07890670e-01\n",
            "  1.46184498e-01  3.02182413e-02  1.39632434e-01 -4.66532961e+00\n",
            "  1.86801995e+00 -8.20866718e+00  5.94913612e+00  8.34201194e+00\n",
            " -5.74413823e+00]\n",
            "[-0.08946235  0.13932265 -0.10313159  0.19102207 -0.44734073  0.50492355\n",
            " -0.05800043 -0.22433788  0.9881961  -1.17676081  0.14057875  1.28580125\n",
            "  3.73105949 -0.94021354 12.43225011  2.07722078  3.02709094]\n",
            "[-0.13850072  0.1833769   0.2552778  -0.12381182 -0.38973089  0.7300754\n",
            "  0.32278942 -0.02190342  0.89612733 -0.95609334  0.77733797  8.13354275\n",
            " -8.51181387  1.39478134 -1.13521685  9.17429756  4.36438147]\n",
            "[-0.1676381   0.23062586  0.27061923 -0.35493117  0.24114311  0.37892114\n",
            "  0.58321391  0.51734972  0.27053288 -0.14349954  0.23539951 -2.04651181\n",
            " -1.742687   14.13217133 -3.75169188  3.04418004 17.09974956]\n",
            "[ -0.194778     0.25900766   0.32118872  -0.41149535   0.08497736\n",
            "   0.51726784   0.39875191   0.48642459   0.57261555  -0.71555566\n",
            "   0.79730245   2.12913258  -0.5474959  -10.22763236   5.12178245\n",
            "  -5.60362023  -3.3723946 ]\n",
            "[-0.23589376  0.27529754 -0.03739432  0.13869757 -0.45696202  0.66496014\n",
            "  0.34188573  0.31304154 -0.2466939  -0.78251602  0.19812606 -9.82701358\n",
            " 11.41977727 -8.24350516  1.50986951  1.39236847 -3.04874304]\n",
            "[-0.24098363  0.34620808 -0.30524204  0.03795519  0.02846695  0.72825355\n",
            "  0.3015825   0.1109361   0.4777288   0.40778398  1.940419   -1.73707886\n",
            " -8.04880347 14.7146645  -0.40065114  0.13859989 -3.04956256]\n",
            "[-0.21285697  0.41345334 -0.18141061 -0.26819112  0.26993659  0.57554766\n",
            "  0.34325293  0.41275872  0.81493845  0.52255528  0.87874085  3.44217837\n",
            " -2.88272072 -1.13487136 -3.97890621  0.84086313 10.13235296]\n",
            "[ -0.19762427   0.41470041  -0.0492988   -0.03578104  -0.29102955\n",
            "   0.32823256   0.70206109   0.54200263   0.63948815   0.19401373\n",
            "  -0.07171505   2.30536921   6.80744572 -12.31389408  -4.23636556\n",
            "   7.88501262  -1.12462644]\n",
            "[ -0.1896131    0.51632188  -0.04039001  -0.2309487   -0.11368603\n",
            "   0.51595355   0.29816396   0.50878425   0.43325262   0.10252758\n",
            "   2.95493848  -1.60223542  -7.78741498   9.82531035   6.1170232\n",
            " -13.22386403  -0.53186609]\n",
            "[-0.21130523  0.58283906 -0.29291599  0.1143236   0.33251322  0.75410202\n",
            " -0.07040755  0.37075558  0.18788623 -0.32204077  0.44285196 -4.20117234\n",
            " 10.28291233  5.89128883 -0.0699085   1.17588334 -1.34711394]\n",
            "[ -0.20160728   0.6789958    0.07322222  -0.21435186   0.05761663\n",
            "   0.65607832   0.0431062    0.36691574   1.30331355   0.18861737\n",
            "   2.15786228  10.14037475 -11.69508924  -8.94639513  -2.1625771\n",
            "   2.05228519   0.49656166]\n",
            "[-0.18379351  0.7504153   0.13715291 -0.3568636  -0.10093249  0.42323033\n",
            "  0.39276917  0.33707878  0.50867206  0.4779411   1.39475964 -3.59651607\n",
            "  1.90841413  0.18631772 -5.04996464  7.38402693 -1.16523759]\n",
            "[-0.16537746  0.8239012  -0.13050709 -0.18037851 -0.03113293  0.2420748\n",
            "  0.62987103  0.29267291  0.4762677   0.24218714  1.62270824 -4.97159851\n",
            "  2.54739133  1.37899993 -2.13177271  2.06445126 -0.63156741]\n",
            "[-0.16076014  0.93130441 -0.36600141 -0.11504465 -0.21145899  0.30559741\n",
            "  0.38291552  0.34523679  0.53163626  0.01779541  2.53918537 -3.83875561\n",
            " -0.23793972 -5.06638573  2.09360809 -6.8556629   1.54434663]\n",
            "[-1.33748297e-01  1.04322050e+00 -8.30870316e-02 -5.08788256e-01\n",
            " -1.41216411e-03  2.71770366e-01  2.96159050e-01  2.51140461e-01\n",
            "  9.80108648e-01  1.07236638e+00  8.34543899e-01  8.12377878e+00\n",
            " -7.59202604e+00  7.71394293e+00 -2.16822538e+00  1.32046826e+00\n",
            " -3.22065733e+00]\n",
            "[-1.00608939e-01  1.03041462e+00  5.70444484e-02 -1.83811291e-01\n",
            " -1.15424230e-01  2.55496862e-01  2.70888429e-01  1.81291881e-01\n",
            "  9.44599369e-03  5.21216667e-01 -4.82027352e-01  1.11422458e+00\n",
            "  1.07827921e+01 -5.98750899e+00  2.73000004e-01 -1.52698379e+00\n",
            " -2.94282859e-01]\n",
            "[-0.07352213  1.02758373  0.22341387  0.02830821 -0.3653462   0.07917226\n",
            "  0.46655691  0.29324181  0.33106643  0.54289283  0.36181617  3.46817096\n",
            "  0.45935725 -3.07881369 -4.60238199  5.06368288  3.25500678]\n",
            "[-0.03415944  1.12698998  0.25685198 -0.31081087 -0.34489975 -0.03106381\n",
            "  0.3129016   0.55005622  0.43097957  0.89942801  2.64353866 -1.32928422\n",
            " -8.23866161  1.85188691 -0.90206983 -6.09783013  3.60738286]\n",
            "[-8.51600369e-03  1.25753381e+00 -3.89017559e-02 -5.02882541e-01\n",
            "  2.96840609e-01  1.79240330e-01  7.70807651e-03  6.04657872e-02\n",
            "  3.61711386e-02  2.01575576e-01  2.37207537e+00 -7.33054969e+00\n",
            " -1.50942339e+00  1.40581772e+01  6.25588610e+00 -3.78406638e+00\n",
            " -1.54944668e+01]\n",
            "[-4.59464273e-03  1.33992890e+00 -4.77075518e-01 -3.37769925e-01\n",
            " -6.10179647e-02  4.90306271e-01 -2.83537197e-01 -2.68450934e-01\n",
            " -4.81575722e-01  5.25978701e-01 -2.44846516e-01 -8.45112251e+00\n",
            "  3.75045616e+00 -1.51147740e+01  3.86321212e+00 -3.77052152e+00\n",
            " -2.94806699e-01]\n",
            "[-0.01701712  1.31265901 -0.4805851  -0.28941252 -0.10628499  0.55792847\n",
            " -0.11542061 -0.31792271  0.79459735 -0.66879725 -0.66498224  3.77191698\n",
            "  1.26708053  6.29847365  0.04588896  6.04927275 -0.99936146]\n",
            "[ -0.03789698   1.18952032  -0.07378737   0.13425781  -0.2935049\n",
            "   0.13626627   0.38933617  -0.32254884   0.58146107  -0.62773402\n",
            "  -2.7602837   11.40528025  10.64170418  -6.61916178 -10.39324479\n",
            "   8.72217872   0.50078317]\n",
            "[-5.97097084e-02  1.14035910e+00  4.13556704e-01  1.99691604e-03\n",
            "  3.46540840e-02  6.15254057e-02  4.74737635e-01 -2.43332906e-02\n",
            "  7.52762145e-01 -1.96626939e-01  1.24671546e-02  5.34038875e+00\n",
            " -7.10171163e+00  1.07561332e+01  4.05183547e-01 -3.92400049e+00\n",
            "  6.57916179e+00]\n",
            "[-6.44898367e-02  1.16713181e+00  1.72543987e-01  1.05588202e-03\n",
            "  3.98203377e-01  2.69590857e-01  1.81358025e-01  3.30579820e-01\n",
            "  1.70152092e-01 -1.56337858e-01  7.13281694e-01 -8.90347241e+00\n",
            "  2.60484128e+00  3.12425862e+00  5.68324890e+00 -4.41670674e+00\n",
            "  6.18267317e+00]\n",
            "[-8.17058987e-02  1.15603021e+00 -2.69552591e-01  3.08682453e-01\n",
            "  8.62907036e-03  6.77404219e-01 -2.02596253e-01  2.25629644e-01\n",
            " -3.48737129e-01 -3.95535020e-01 -8.86837786e-01 -7.09525977e+00\n",
            "  5.09743854e+00 -1.07941922e+01  7.51806175e+00 -6.54198050e+00\n",
            " -6.25096481e+00]\n",
            "[ -0.08088628   1.13928762  -0.41246453  -0.08869115   0.12326158\n",
            "   0.42490113  -0.05358877   0.16066917   0.78043486   0.11331737\n",
            "  -0.21589847  -0.45728746 -11.85218199   7.64424121 -10.30667084\n",
            "   6.31240978   1.56810022]\n",
            "[ -0.08616706   1.08197917  -0.24693594  -0.37698787  -0.17168222\n",
            "  -0.06679679   0.63068539   0.55059089   0.96895838  -0.3158007\n",
            "  -1.4956767    3.67995179  -0.65925694 -10.35087855  -7.06838009\n",
            "  13.23448451   9.7706416 ]\n",
            "[-0.14383634  0.97932499 -0.30348336  0.21320956 -0.41733462  0.21067452\n",
            "  0.46843855  0.36291381  0.28936903 -1.49182751 -1.91008548 -1.59673326\n",
            " 13.32662617 -0.59918922 10.08490641 -9.33588805 -5.54954594]\n",
            "[-0.21427711  0.89778979 -0.16053724  0.52530874 -0.33639448  0.55696997\n",
            "  0.28911925 -0.04134032  0.23869143 -0.50848926 -3.07703261  3.2746613\n",
            "  3.43503592  2.28750187  2.87084001  1.08310644 -7.58599778]\n",
            "[ -0.21852755   0.85679242   0.09510281  -0.18739231   0.09677871\n",
            "   0.44161581   0.55758855  -0.0868219    0.92340405   0.05564962\n",
            "  -0.16283909   4.57084105 -18.3794302    9.47887937  -3.94199905\n",
            "   5.70363054   2.84703009]\n",
            "[-2.03615149e-01  7.67834986e-01 -2.35148348e-01  8.17441718e-03\n",
            " -8.32400225e-04  1.35409884e-01  9.33466165e-01  3.78389450e-01\n",
            " -6.67418824e-01  2.45349970e-01 -2.07739904e+00 -1.08836444e+01\n",
            "  1.11538107e+01 -7.08288910e+00 -3.07344103e+00  8.29611310e-01\n",
            "  1.31399994e+01]\n",
            "[-0.18671253  0.73379966 -0.44079208 -0.02092551  0.22447371  0.18303399\n",
            "  0.81590305  0.39712897  0.2055717   0.42352729  0.01988358  0.43722019\n",
            " -5.44381817  8.49406603  0.99669642 -2.06340765 -4.13265328]\n",
            "[-2.03088151e-01  7.43757770e-01 -3.43608061e-01 -4.90342192e-02\n",
            "  2.77082011e-01  7.16508427e-01  1.04050592e-02  1.43113338e-01\n",
            "  1.04338855e-02 -6.13370738e-01  2.53548085e-01  2.37509072e+00\n",
            "  2.04404645e+00 -2.52860251e+00  1.18756732e+01 -1.76115199e+01\n",
            " -5.52320533e+00]\n",
            "[-0.20537447  0.75705452  0.10148812 -0.27473005  0.13218099  0.72710591\n",
            " -0.0249009   0.15053495  0.63523435 -0.18945864 -0.1230847   9.84417494\n",
            " -4.36091219 -1.87120736 -1.0447656   2.29657582  1.02435416]\n",
            "[-0.21071217  0.74877883  0.33819241 -0.24844233 -0.2477549   0.69126291\n",
            " -0.10085637  0.50462792 -0.15531188  0.05208217  0.09168551  1.17001842\n",
            "  2.71712107 -8.03094403 -0.75146404 -3.31386065  9.13355133]\n",
            "[-0.18228221  0.72562156  0.23696698  0.17410831 -0.42666047  0.54257706\n",
            "  0.07550937  0.54905949 -0.06360717  0.88854568 -0.4650519  -2.72556969\n",
            "  8.25671061  0.74309003 -3.88240556  5.29654232 -1.13891562]\n",
            "[ -0.12467909   0.73570346  -0.06661976   0.39096062  -0.41164972\n",
            "   0.32461458   0.4853074    0.14851081   0.04278385   1.1717374\n",
            "   0.67862403  -6.69501744   0.72890987  -0.3154129   -3.65093058\n",
            "   7.3756488  -10.71655221]\n",
            "[-0.0686787   0.77411837 -0.38832621  0.42497663 -0.42053199  0.16787411\n",
            "  0.54269347  0.21567193  0.07930046  1.03114717  0.88626925 -4.85245545\n",
            "  0.0357619   0.03446493 -2.57711031 -2.43007635  7.57919293]\n",
            "[-0.06634064  0.82099965 -0.09164     0.28993785  0.10219549  0.38336495\n",
            "  0.25144385  0.10709228  1.15328772 -0.58914621  0.46754751 10.2000875\n",
            " -2.71698449 12.98290029  7.03875242 -5.09351577 -7.09333573]\n",
            "[ -0.11276397   0.82465774   0.43973382   0.21748014  -0.10965636\n",
            "   0.74591549  -0.22678997  -0.2754264    0.39130188  -0.56702589\n",
            "  -0.31073      8.17805152   0.16252662 -10.54801255  -0.07050581\n",
            "  -6.41458241  -6.26295371]\n",
            "[-0.09480565  0.8880841   0.27053952  0.12488982  0.09789984  0.70615377\n",
            " -0.3583043  -0.15061449  0.27739196  0.63268695  1.96788111 -8.04533208\n",
            " -2.70811964  9.31378767 -1.48188268 -2.42886345  5.7645146 ]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install swig\n",
        "!pip install gymnasium[box2d]\n",
        "\n",
        "# Create Half-Cheetah environment\n",
        "# https://gymnasium.farama.org/environments/mujoco/hopper/\n",
        "\n",
        "\n",
        "import gymnasium as gym\n",
        "env = gym.make(\"HalfCheetah-v4\", render_mode = \"rgb_array\")\n",
        "s = env.reset(seed = 34)\n",
        "print(\"Observation Space = \")\n",
        "print(env.observation_space)\n",
        "print(\"Action Space = \")\n",
        "print(env.action_space)\n",
        "done = False\n",
        "for episode in range(1):\n",
        "    print(\"In episode {}\".format(episode))\n",
        "    for i in range(100):\n",
        "        # env.render()\n",
        "        print(s)\n",
        "        a = env.action_space.sample()\n",
        "        s, r, done, truncated, _ = env.step(a)\n",
        "        if done:\n",
        "            print(\"Finished after {} timestep\".format(i+1))\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZl7gdilTqk0"
      },
      "source": [
        "# Hyperparameters\n",
        "<a id=\"Hyperparameters\"></a>\n",
        "\n",
        "All your hyperparameters should be stated here. We will change their value here and your code should work  accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "xy2JuTNSTqk0"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQdO8L3wTqk0"
      },
      "source": [
        "# Helper Functions\n",
        "<a id=\"helper\"></a>\n",
        "\n",
        "Write all the helper functions that will be used for value-based and policy based algorithms below. In case you want to add more helper functions, please feel free to add."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "cvfPRYTyTqk1"
      },
      "outputs": [],
      "source": [
        "#Value Network\n",
        "def createValueNetwork(inDim, outDim, action_size, hDim = [32,32], activation = F.relu):\n",
        "    #this creates a Feed Forward Neural Network class and instantiates it and returns the class\n",
        "    #the class should be derived from torch nn.Module and it should have init and forward method at the very least\n",
        "    #the forward function should return q-value for each possible action\n",
        "\n",
        "    #Your code goes in here\n",
        "    class criticNetwork(nn.Module):\n",
        "      def __init__(self,input_dim,output_dim,n_action,hidden_dim,activation_fn):\n",
        "        super(criticNetwork,self).__init__()\n",
        "        self.activation_fn=activation_fn\n",
        "        self.hidden_dim=hidden_dim\n",
        "        self.hidden_dim[0]=self.hidden_dim[0]+n_action\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim,hidden_dim[0])\n",
        "        self.fc2 = nn.Linear(hidden_dim[0]+n_action, hidden_dim[1])\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(self.device)\n",
        "\n",
        "      def forward(self,state,action):\n",
        "        x=state\n",
        "        a=action\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.fc2(torch.cat([out,a],1))\n",
        "        out = self.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "    return criticNetwork(inDim, outDim, action_size, hDim, activation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "pzIvt4LpTqk1"
      },
      "outputs": [],
      "source": [
        "#Policy Network\n",
        "def createPolicyNetwork(inDim, outDim, hDim = [32,32], activation = F.relu, output_activation_fn=torch.tanh):\n",
        "    #this creates a Feed Forward Neural Network class and instantiates it and returns the class\n",
        "    #the class should be derived from torch nn.Module and it should have init and forward method at the very least\n",
        "    #the forward function should return action logit vector\n",
        "    #Your code goes in here\n",
        "    class actorNetwork(nn.Module):\n",
        "      def __init__(self,input_dim,output_dim,hidden_dim,activation_fn,output_activation_fn):\n",
        "        super(actorNetwork,self).__init__()\n",
        "        self.activation_fn=activation_fn\n",
        "        self.output_activation_fn=output_activation_fn\n",
        "\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.fc2 = nn.Linear( hidden_dim[0],  hidden_dim[1])\n",
        "        self.fc3 = nn.Linear( hidden_dim[1], output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(self.device)\n",
        "\n",
        "      def forward(self,state):\n",
        "        out = self.fc1(state)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.tanh(out)\n",
        "        return out\n",
        "\n",
        "    return actorNetwork(inDim, outDim, hDim, activation, output_activation_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxc90XWyTqk1"
      },
      "source": [
        "## ReplayBuffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlL3jPvtTqk1"
      },
      "source": [
        "In next few cells, you will implement replaybuffer class.\n",
        "\n",
        "This class creates a buffer for storing and retrieving experiences. This is a generic class and can be used\n",
        "for different agents like NFQ, DQN, DDQN, PER_DDQN, etc.\n",
        "Following are the methods for this class which are implemented in subsequent cells\n",
        "\n",
        "```\n",
        "class ReplayBuffer():\n",
        "    def __init__(self, bufferSize, batch_size, seed)\n",
        "    def store(self, state, action, reward, next_state, done)\n",
        "    def sample(self, batchSize)\n",
        "    def length(self)\n",
        "```   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "kRdUi6ciTqk1"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer():\n",
        "    def __init__(self, buffer_size):\n",
        "        # this function creates the relevant data-structures, and intializes all relevant variables\n",
        "        #Your code goes in here\n",
        "\n",
        "        self.ss_mem = np.empty(shape=(buffer_size), dtype=np.ndarray)\n",
        "        self.as_mem = np.empty(shape=(buffer_size), dtype=np.ndarray)\n",
        "        self.rs_mem = np.empty(shape=(buffer_size), dtype=float)\n",
        "        self.ps_mem = np.empty(shape=(buffer_size), dtype=np.ndarray)\n",
        "        self.ds_mem = np.empty(shape=(buffer_size), dtype=bool)\n",
        "\n",
        "        self.buffer_size = buffer_size\n",
        "        self._idx = 0\n",
        "        self.size = 0\n",
        "        # Assume default batch size for sampling if not provided\n",
        "        self.default_batch_size = 64\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "8cCo3q9uTqk1"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(ReplayBuffer):\n",
        "    def store(self, experience):\n",
        "        #stores the experiences, based on parameters in init\n",
        "        #\n",
        "        #this function does not return anything\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        s, a, r, p, d = experience\n",
        "        self.ss_mem[self._idx] = s\n",
        "        self.as_mem[self._idx] = a\n",
        "        self.rs_mem[self._idx] = r\n",
        "        self.ps_mem[self._idx] = p\n",
        "        self.ds_mem[self._idx] = d\n",
        "\n",
        "        self._idx = (self._idx + 1) % self.buffer_size\n",
        "        self.size = min(self.size + 1, self.buffer_size)\n",
        "\n",
        "        return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "E4Klx1yzTqk1"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(ReplayBuffer):\n",
        "    def sample(self, batch_size):\n",
        "        # this method returns batchSize number of experiences\n",
        "        # this function returns experiences samples\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        idxs = np.random.choice(self.size, batch_size, replace=False)\n",
        "        experiences = (np.vstack(self.ss_mem[idxs]), \\\n",
        "                        np.vstack(self.as_mem[idxs]), \\\n",
        "                        np.vstack(self.rs_mem[idxs]), \\\n",
        "                        np.vstack(self.ps_mem[idxs]), \\\n",
        "                        np.vstack(self.ds_mem[idxs]))\n",
        "\n",
        "        return experiences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer(ReplayBuffer):\n",
        "  def splitExperiences(self, experiences):\n",
        "        states, actions, rewards, nextStates, dones = experiences\n",
        "\n",
        "        return states, actions, rewards, nextStates, dones"
      ],
      "metadata": {
        "id": "lo_paZ3_eBQs"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "SZAUpbqGTqk1"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer(ReplayBuffer):\n",
        "    def length(self):\n",
        "        #tells the number of experiences stored in the internal buffer\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        return self.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEgPzo31Tqk1"
      },
      "source": [
        "## Deep Deterministic Policy Gradient (DDPG) ##\n",
        "<a id=\"ddpg\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iA58AIxdTqk1"
      },
      "source": [
        "Implement the Deep Deterministic Policy Gradient (DDPG) agent. We have studied about DDPG agent in the Lecture. Use the function definitions (given below).\n",
        "\n",
        "This class implements the DDPG agent, you are required to implement the various methods of this class\n",
        "as outlined below. Note this class is generic and should work with any permissible Gym environment\n",
        "\n",
        "```\n",
        "class DDPG():\n",
        "    def init(self, env, seed, gamma, tau, bufferSize, batch_size, updateFrequency,\n",
        "             policyOptimizerFn, valueOptimizerFn,\n",
        "             policyOptimizerLR,valueOptimizerLR,\n",
        "             MAX_TRAIN_EPISODES,MAX_EVAL_EPISODE,\n",
        "             optimizerFn)\n",
        "    \n",
        "    def runDDPG(self)\n",
        "    def trainAgent(self)\n",
        "    def gaussianStrategy(self, net , s , envActionRange , noiseScaleRatio,\n",
        "        explorationMax = True)\n",
        "    def greedyStrategy(self, net , s , envActionRange)\n",
        "    def trainNetworks(self, experiences)\n",
        "    def updateNetworks(self, onlineNet, targetNet, tau)\n",
        "    def evaluateAgent(self)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "6xbsv1bzTqk1"
      },
      "outputs": [],
      "source": [
        "class DDPG():\n",
        "    def __init__(self,env_id,seed,gamma,tau,buffer_size,batch_size,update_freq,policyOptimizer,valueOptimizer,policyOptimizerLr,valueOptimizerLr,max_train_eps,max_eval_eps):\n",
        "      self.env = gym.make(env_id)\n",
        "      self.seed = seed\n",
        "      self.env.reset(seed=self.seed)\n",
        "\n",
        "      torch.manual_seed(seed)\n",
        "      np.random.seed(seed)\n",
        "      random.seed(seed)\n",
        "\n",
        "      self.gamma=gamma\n",
        "      self.tau=tau\n",
        "      self.update_freq=update_freq\n",
        "      self.max_train_eps=max_train_eps\n",
        "      self.max_eval_eps=max_eval_eps\n",
        "      self.batch_size=batch_size\n",
        "\n",
        "      self.n_action=self.env.action_space.shape[0]\n",
        "      self.n_state=self.env.observation_space.shape[0]\n",
        "      self.actionLowValue=self.env.action_space.low\n",
        "      self.actionHighValue=self.env.action_space.high\n",
        "      self.actionRange=(self.actionLowValue,self.actionHighValue)\n",
        "\n",
        "      self.rBuffer=ReplayBuffer(buffer_size)\n",
        "\n",
        "      self.target_value_net=createValueNetwork(self.n_state,1,self.n_action,[32,32],F.relu)\n",
        "      self.online_value_net=createValueNetwork(self.n_state,1,self.n_action,[32,32],F.relu)\n",
        "      self.target_policy_net=createPolicyNetwork(self.n_state,self.n_action,[32,32],F.relu,torch.tanh)\n",
        "      self.online_policy_net=createPolicyNetwork(self.n_state,self.n_action,[32,32],F.relu,torch.tanh)\n",
        "\n",
        "      self.optimizerP = policyOptimizer(self.online_policy_net.parameters(), policyOptimizerLr)\n",
        "      self.optimizerV = valueOptimizer(self.online_value_net.parameters(), valueOptimizerLr)\n",
        "\n",
        "\n",
        "      self.updateNetworks(self.online_value_net,self.target_value_net, self.tau)\n",
        "      self.updateNetworks(self.online_policy_net,self.target_policy_net, self.tau)\n",
        "\n",
        "    def initBookeeping(self):\n",
        "      self.episode_step = []\n",
        "      self.episode_reward = []\n",
        "      self.training_time = []\n",
        "      self.evaluation_scores = []\n",
        "      # self.wallClock_time=[]\n",
        "\n",
        "    def performBookeeping(self,train=True):\n",
        "      if train:\n",
        "        self.episode_step.append(self.step)\n",
        "        self.episode_reward.append(self.Tr/1000)\n",
        "        self.training_time.append(self.episode_elapsed)\n",
        "        self.evaluation_scores.append(self.evalscore)\n",
        "\n",
        "\n",
        "\n",
        "        #Your code goes in here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Fw4gyGlGTqk2"
      },
      "outputs": [],
      "source": [
        "class DDPG(DDPG):\n",
        "    def updateNetworks(self, onlineNet, targetNet, tau):\n",
        "        #this function updates the onlineNetwork with the target network\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        for target, online in zip(targetNet.parameters(),\n",
        "                                  onlineNet.parameters()):\n",
        "            target.data.copy_(tau*online.data+(1-tau)*target.data)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "5fdTYL9kTqk2"
      },
      "outputs": [],
      "source": [
        "class DDPG(DDPG):\n",
        "    def gaussianStrategy (self, net , s , envActionRange , noiseScaleRatio ,\n",
        "        explorationMax = True ):\n",
        "        #this function sets the scale of exploration then add the noise of this scale to the greedy action\n",
        "        #and clips it within the range\n",
        "\n",
        "        #Your code here\n",
        "        actionLowValue, actionHighValue=envActionRange\n",
        "        if explorationMax:\n",
        "          scale=actionHighValue\n",
        "        else:\n",
        "          scale=noiseScaleRatio*actionHighValue\n",
        "\n",
        "        greedyAction=net(torch.from_numpy(s)).detach()\n",
        "        noise=np.random.normal(0, scale, len(actionHighValue))\n",
        "        action=greedyAction+noise\n",
        "        action=np.clip(action,actionLowValue,actionHighValue)\n",
        "\n",
        "        return action\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "ThKXSsbUTqk2"
      },
      "outputs": [],
      "source": [
        "class DDPG(DDPG):\n",
        "    def greedyStrategy(self,net,s,actionRange):\n",
        "      actionLowValue,actionHighValue=actionRange\n",
        "      action=net(torch.from_numpy(s)).detach()\n",
        "      action=np.clip(action,actionLowValue,actionHighValue)\n",
        "      return action\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "KuQJ5e8ATqk2"
      },
      "outputs": [],
      "source": [
        "class DDPG(DDPG):\n",
        "    def runDDPG (self):\n",
        "        #this is the main method, it trains the agent, performs bookkeeping while training and finally evaluates\n",
        "        #the agent and returns the following quantities:\n",
        "        #1. episode wise mean train rewards\n",
        "        #2. epsiode wise mean eval rewards\n",
        "        #2. episode wise trainTime (in seconds): time elapsed during training since the start of the first episode\n",
        "        #3. episode wise wallClockTime (in seconds): actual time elapsed since the start of training,\n",
        "        #                               note this will include time for BookKeeping and evaluation\n",
        "        # Note both trainTime and wallClockTime get accumulated as episodes proceed.\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        resultTrain=self.trainAgent()\n",
        "        steps,rewards,evalScore,trainingTime=resultTrain\n",
        "        resultEval=self.evaluateAgent()\n",
        "\n",
        "\n",
        "        return rewards, trainingTime, evalScore, resultEval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "3ikRkQkTTqk2"
      },
      "outputs": [],
      "source": [
        "class DDPG(DDPG):\n",
        "    def trainAgent(self):\n",
        "        #this method collects experiences and trains the agent and does BookKeeping while training.\n",
        "        #this calls the trainNetwork() method internally, it also evaluates the agent per episode\n",
        "        #it trains the agent for MAX_TRAIN_EPISODES\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        self.updateNetworks(self.online_value_net,self.target_value_net, self.tau)\n",
        "        self.updateNetworks(self.online_policy_net,self.target_policy_net, self.tau)\n",
        "        self.initBookeeping()\n",
        "        episode_start=time.time()\n",
        "        for e in range(self.max_train_eps):\n",
        "          s,done=self.env.reset(seed=self.seed)\n",
        "          print(e)\n",
        "          self.step=0\n",
        "          self.Tr=0\n",
        "          self.evalscore=0\n",
        "\n",
        "          for i in range(1000):\n",
        "            explorationMax=self.rBuffer.length()<400\n",
        "            a=self.gaussianStrategy(self.online_policy_net, s, self.actionRange, 0.5, explorationMax)\n",
        "            s_n, r, done, _, _ =self.env.step(a)\n",
        "            experience=(s,a,r,s_n,done)\n",
        "            self.rBuffer.store(experience)\n",
        "\n",
        "\n",
        "            if self.rBuffer.length()>300:\n",
        "              experiences=self.rBuffer.sample(self.batch_size)\n",
        "              self.trainNetwork(experiences)\n",
        "\n",
        "            if e%self.update_freq==0:\n",
        "              self.updateNetworks(self.online_value_net,self.target_value_net, self.tau)\n",
        "              self.updateNetworks(self.online_policy_net,self.target_policy_net, self.tau)\n",
        "\n",
        "            s=s_n\n",
        "\n",
        "            self.step+=1\n",
        "            self.Tr+=r\n",
        "\n",
        "            if done:\n",
        "              break\n",
        "\n",
        "          self.evalscore,_=self.evaluateAgent()\n",
        "          self.episode_elapsed = time.time() - episode_start\n",
        "          self.performBookeeping(train=True)\n",
        "\n",
        "        return self.episode_step, self.episode_reward, self.evaluation_scores, self.training_time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "fgVVkDOdTqk2"
      },
      "outputs": [],
      "source": [
        "class DDPG(DDPG):\n",
        "    def trainNetwork(self, experiences):\n",
        "        # this method trains the value network epoch number of times and is called by the trainAgent function\n",
        "        # it essentially uses the experiences to calculate target, using the targets it calculates the error, which\n",
        "        # is further used for calulating the loss. It then uses the optimizer over the loss\n",
        "        # to update the params of the network by backpropagating through the network\n",
        "        # this function does not return anything\n",
        "        # you can try out other loss functions other than MSE like Huber loss, MAE, etc.\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        s, a, r, s_n, done=self.rBuffer.splitExperiences(experiences)\n",
        "        argmax_a_qs_v=self.target_policy_net(torch.from_numpy(s_n)).detach()\n",
        "        max_a_qs_v=self.target_value_net(torch.from_numpy(s_n), argmax_a_qs_v).detach()\n",
        "\n",
        "        max_a_qs_v=max_a_qs_v.numpy()\n",
        "        target_qs=r+self.gamma*max_a_qs_v*((1-done).T)\n",
        "        a=a.astype(np.float32)\n",
        "        qs=self.online_value_net(torch.from_numpy(s),torch.from_numpy(a))\n",
        "        tdError=torch.from_numpy(target_qs)-qs\n",
        "        valueLoss=tdError.pow(2).mul(0.5).mean()\n",
        "        self.optimizerV.zero_grad()\n",
        "        valueLoss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.online_value_net.parameters(), max_norm=15)\n",
        "        self.optimizerV.step()\n",
        "        argmax_a_qs_p=self.online_policy_net(torch.from_numpy(s_n)).detach()\n",
        "        max_a_qs_p=self.online_value_net(torch.from_numpy(s_n),argmax_a_qs_p)\n",
        "        policyLoss=-1.0*torch.mean(max_a_qs_p)\n",
        "        self.optimizerP.zero_grad()\n",
        "        policyLoss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.online_value_net.parameters(), max_norm=15)\n",
        "        self.optimizerP.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "5-3JWsBmTqk2"
      },
      "outputs": [],
      "source": [
        "class DDPG(DDPG):\n",
        "    def evaluateAgent(self):\n",
        "        #this function evaluates the agent using the value network, it evaluates agent for MAX_EVAL_EPISODES\n",
        "        #typcially MAX_EVAL_EPISODES = 1\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        rewards=[]\n",
        "        for ep in range(self.max_eval_eps):\n",
        "          rs=0\n",
        "          s,done=self.env.reset(seed=self.seed)\n",
        "          for c in range(500):\n",
        "            a=self.greedyStrategy(self.online_policy_net,s,self.actionRange)\n",
        "\n",
        "            s,r,done, _, _=self.env.step(a)\n",
        "            rs+=r\n",
        "            if done:\n",
        "              break\n",
        "          rewards.append(rs)\n",
        "\n",
        "        return np.mean(rewards), np.std(rewards)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# seed_list = [420,133,74,317,233]\n",
        "# for seed in seed_list:\n",
        "gamma=0.99\n",
        "tau=0.1\n",
        "buffer_size=5000\n",
        "update_freq=10\n",
        "policyOptimizer=torch.optim.Adam\n",
        "valueOptimizer=torch.optim.Adam\n",
        "policyOptimizerLr=3*1e-3\n",
        "valueOptimizerLr=3*1e-3\n",
        "max_train_eps=120\n",
        "max_eval_eps=1\n",
        "batch_size=224\n"
      ],
      "metadata": {
        "id": "NcPp5ekElrtD"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotQuantity(eps,env_id):\n",
        "  seeds=[55,45]\n",
        "  # Steps=[]\n",
        "  Rewards=[]\n",
        "  EvalScore=[]\n",
        "  TrainingTime=[]\n",
        "  ResultEval=[]\n",
        "\n",
        "  for s in seeds:\n",
        "\n",
        "    agent=DDPG(env_id,s,gamma,tau,buffer_size,batch_size, update_freq,policyOptimizer,valueOptimizer,policyOptimizerLr,valueOptimizerLr,max_train_eps,max_eval_eps)\n",
        "    rewards,evalScore,trainingTime,resultEval=agent.runDDPG()\n",
        "    # Steps.append(steps)\n",
        "    Rewards.append(rewards)\n",
        "    EvalScore.append(evalScore)\n",
        "    TrainingTime.append(trainingTime)\n",
        "    ResultEval.append(resultEval)\n",
        "    print(ResultEval)\n",
        "  quantities = [Rewards, EvalScore, TrainingTime]\n",
        "  quantity_names = [\"Rewards\", \"EvalScore\", \"TrainingTime\"]\n",
        "\n",
        "  for quantity, quantity_name in zip(quantities, quantity_names):\n",
        "      mean_values = np.mean(quantity, axis=0)\n",
        "      min_values = np.min(quantity, axis=0)\n",
        "      max_values = np.max(quantity, axis=0)\n",
        "\n",
        "    # Calculate mean, min, and max values across environment instances for each episode\n",
        "\n",
        "    # for episode in range(eps):\n",
        "    #     quantity_values = quantityList[episode]\n",
        "\n",
        "    #     mean_values.append(np.mean(quantity_values))\n",
        "    #     min_values.append(np.min(quantity_values))\n",
        "    #     max_values.append(np.max(quantity_values))\n",
        "\n",
        "    # Create the plot\n",
        "      plt.figure(figsize=(10, 6))\n",
        "\n",
        "      # Plot mean values\n",
        "      plt.plot(range(1, eps + 1), mean_values, label='Mean', color='blue')\n",
        "\n",
        "      # Fill between min and max values\n",
        "      plt.fill_between(range(1, eps + 1), min_values, max_values, color='lightblue', alpha=0.3)\n",
        "\n",
        "      # Add legend\n",
        "      plt.legend(loc='upper left')\n",
        "\n",
        "      # Add labels and title\n",
        "      plt.xlabel('Episode')\n",
        "      plt.ylabel(quantity_name)\n",
        "      plt.title(env_id)\n",
        "\n",
        "      # Show plot\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "7YRtuicqkDrU"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "envs=[\"Pendulum-v1\",\"Hopper-v4\",\"HalfCheetah-v4\"]\n",
        "for env in envs:\n",
        "  plotQuantity(120,env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "ZEToKXYrbyL7",
        "outputId": "501ab2c3-2916-4e8f-ed46-a1a05311fbe2"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:246: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'torch.Tensor'>\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-a47e5e275df6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pendulum-v1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Hopper-v4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"HalfCheetah-v4\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mplotQuantity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-133-7a77208da870>\u001b[0m in \u001b[0;36mplotQuantity\u001b[0;34m(eps, env_id)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDDPG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolicyOptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalueOptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolicyOptimizerLr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalueOptimizerLr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_train_eps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_eval_eps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevalScore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainingTime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresultEval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunDDPG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Steps.append(steps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mRewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-85258f79fd39>\u001b[0m in \u001b[0;36mrunDDPG\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#Your code goes in here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mresultTrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevalScore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainingTime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresultTrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mresultEval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluateAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-129-4db9a328cfff>\u001b[0m in \u001b[0;36mtrainAgent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrBuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m               \u001b[0mexperiences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrBuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_freq\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-130-d384ad4b021a>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[0;34m(self, experiences)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mpolicyLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monline_value_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizerP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Optimizer.step#{self.__class__.__name__}.step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0;31m# call optimizer step pre hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mpre_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_global_optimizer_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RecordFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m         )\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG5psRuFTqk2"
      },
      "source": [
        "# Twin-Delayed Deep Deterministic Policy Gradient (TD3)\n",
        "<a id=\"td3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_4oHd5uTqk2"
      },
      "source": [
        "Implement the Twin-delayed deep deterministic policy gradient (TD3) agent. We have studied about TD3 agent in the Lecture. Use the function definitions (given below).\n",
        "\n",
        "This class implements the TD3 agent, you are required to implement the various methods of this class\n",
        "as outlined below. Note this class is generic and should work with any permissible Gym environment\n",
        "\n",
        "```\n",
        "class DDPG():\n",
        "    def init(env, gamma, tau,\n",
        "    bufferSize ,\n",
        "    updateFrequencyPolicy ,\n",
        "    updateFrequencyValue ,\n",
        "    trainPolicyFrequency ,\n",
        "    policyOptimizerFn ,\n",
        "    valueOptimizerFn ,\n",
        "    policyOptimizerLR ,\n",
        "    valueOptimizerLR ,\n",
        "    MAX TRAIN EPISODES,\n",
        "    MAX EVAL EPISODE,\n",
        "    optimizerFn )\n",
        "    \n",
        "    def runTD3 (self)\n",
        "    def trainAgent (self)\n",
        "    def gaussianStrategy (self, net , s , envActionRange , noiseScaleRatio ,\n",
        "        explorationMax = True)\n",
        "    def greedyStrategy (self, net , s , envActionRange)\n",
        "    def trainNetworks (self,experiences , envActionRange)\n",
        "    def updateValueNetwork(self, onlineNet, targetNet, tau)\n",
        "    def updatePolicyNetwork(self, onlineNet, targetNet, tau)\n",
        "    def evaluateAgent (self)\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "KEJ5UkcdTqk2"
      },
      "outputs": [],
      "source": [
        "class TD3():\n",
        "    # def __init__(self,env, gamma, tau,\n",
        "    # bufferSize ,\n",
        "    # update_freq_policy ,\n",
        "    # update_freq_value ,\n",
        "    # trainPolicyFrequency ,\n",
        "    # policyOptimizerFn ,\n",
        "    # valueOptimizerFn ,\n",
        "    # policyOptimizerLR ,\n",
        "    # valueOptimizerLR ,\n",
        "    # MAX_TRAIN_EPISODES,\n",
        "    # MAX_EVAL_EPISODE,\n",
        "    # optimizerFn):\n",
        "        #this TD3 method\n",
        "        # 1. creates and initializes (with seed) the environment, train/eval episodes, gamma, etc.\n",
        "        # 2. creates and intializes all the variables required for book-keeping values via the initBookKeeping method\n",
        "        # 3. creates targetValueNetwork , targetPolicyNetwork\n",
        "        # 4. creates and initializes (with network params) the optimizer function\n",
        "        # 5. creates onlineValueNetwork, onlinePolicyNetwork\n",
        "        # 6. Creates the replayBuffer\n",
        "\n",
        "        #Your code goes in here\n",
        "    def __init__(self,env_id,seed,gamma,tau,buffer_size,batch_size,update_freq_policy, update_freq_value, trainPolicyFrequency, policyOptimizer,valueOptimizer,policyOptimizerLr,valueOptimizerLr,max_train_eps,max_eval_eps):\n",
        "      self.env = gym.make(env_id)\n",
        "      self.seed = seed\n",
        "      self.env.reset(seed=self.seed)\n",
        "\n",
        "      torch.manual_seed(seed)\n",
        "      np.random.seed(seed)\n",
        "      random.seed(seed)\n",
        "\n",
        "      self.gamma=gamma\n",
        "      self.tau=tau\n",
        "      self.update_freq_policy=update_freq_policy\n",
        "      self.update_freq_value=update_freq_value\n",
        "      self.max_train_eps=max_train_eps\n",
        "      self.max_eval_eps=max_eval_eps\n",
        "      self.batch_size=batch_size\n",
        "      self.trainPolicyFrequency=trainPolicyFrequency\n",
        "\n",
        "      self.n_action=self.env.action_space.shape[0]\n",
        "      self.n_state=self.env.observation_space.shape[0]\n",
        "      self.actionLowValue=self.env.action_space.low\n",
        "      self.actionHighValue=self.env.action_space.high\n",
        "      self.actionRange=(self.actionLowValue,self.actionHighValue)\n",
        "\n",
        "      self.rBuffer=ReplayBuffer(buffer_size)\n",
        "\n",
        "      self.target_value_net=createValueNetwork(self.n_state,1,self.n_action,[32,32],F.relu)\n",
        "      self.online_value_net=createValueNetwork(self.n_state,1,self.n_action,[32,32],F.relu)\n",
        "      self.target_policy_net=createPolicyNetwork(self.n_state,self.n_action,[32,32],F.relu,torch.tanh)\n",
        "      self.online_policy_net=createPolicyNetwork(self.n_state,self.n_action,[32,32],F.relu,torch.tanh)\n",
        "\n",
        "      self.optimizerP = policyOptimizer(self.online_policy_net.parameters(), policyOptimizerLr)\n",
        "      self.optimizerV = valueOptimizer(self.online_value_net.parameters(), valueOptimizerLr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def initBookeeping(self):\n",
        "      self.episode_step = []\n",
        "      self.episode_reward = []\n",
        "      self.training_time = []\n",
        "      self.evaluation_scores = []\n",
        "      # self.wallClock_time=[]\n",
        "\n",
        "    def performBookeeping(self,train=True):\n",
        "      if train:\n",
        "        self.episode_step.append(self.step)\n",
        "        self.episode_reward.append(self.Tr/1000)\n",
        "        self.training_time.append(self.episode_elapsed)\n",
        "        self.evaluation_scores.append(self.evalscore)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "nTiqVgpNTqk2"
      },
      "outputs": [],
      "source": [
        "class TD3(TD3):\n",
        "    def updateValueNetwork(self, tau):\n",
        "        #this function updates the onlineValueNetwork with the targetValuenetwork\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        for target, online in zip(self.target_value_net.parameters(),\n",
        "                                  self.online_value_net.parameters()):\n",
        "            target.data.copy_(tau*online.data+(1-tau)*target.data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "HDRO2ZJVTqk3"
      },
      "outputs": [],
      "source": [
        "class TD3(TD3):\n",
        "    def updatePolicyNetwork(self, tau):\n",
        "        #this function updates the onlinePolicuNetwork with the targetPolicynetwork\n",
        "        #\n",
        "        # Your code goes in here\n",
        "        for target, online in zip(self.target_policy_net.parameters(),\n",
        "                                  self.target_policy_net.parameters()):\n",
        "            target.data.copy_(tau*online.data+(1-tau)*target.data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "q7Hj4cxbTqk3"
      },
      "outputs": [],
      "source": [
        "class TD3(TD3):\n",
        "    def gaussianStrategy (self, net , s , envActionRange , noiseScaleRatio ,\n",
        "        explorationMax = True ):\n",
        "        #this function sets the scale of exploration then add the noise of this scale to the greedy action\n",
        "        #and clips it within the range\n",
        "\n",
        "        #Your code here\n",
        "        actionLowValue, actionHighValue=envActionRange\n",
        "        if explorationMax:\n",
        "          scale=actionHighValue\n",
        "        else:\n",
        "          scale=noiseScaleRatio*actionHighValue\n",
        "\n",
        "        greedyAction=net(torch.from_numpy(s)).detach()\n",
        "        noise=np.random.normal(0, scale, len(actionHighValue))\n",
        "        action=greedyAction+noise\n",
        "        action=np.clip(action,actionLowValue,actionHighValue)\n",
        "\n",
        "        return action\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "otNLK41eTqk9"
      },
      "outputs": [],
      "source": [
        "class TD3(TD3):\n",
        "    def greedyStrategy (self, net , s , actionRange ):\n",
        "        #this function selects the greedy action\n",
        "        #and clips it within the range\n",
        "\n",
        "        #Your code here\n",
        "        actionLowValue,actionHighValue=actionRange\n",
        "        action=net(torch.from_numpy(s)).detach()\n",
        "        action=np.clip(action,actionLowValue,actionHighValue)\n",
        "        return action\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "g7MxyTcaTqk9"
      },
      "outputs": [],
      "source": [
        "class TD3(TD3):\n",
        "    def runTD3 (self):\n",
        "        #this is the main method, it trains the agent, performs bookkeeping while training and finally evaluates\n",
        "        #the agent and returns the following quantities:\n",
        "        #1. episode wise mean train rewards\n",
        "        #2. epsiode wise mean eval rewards\n",
        "        #2. episode wise trainTime (in seconds): time elapsed during training since the start of the first episode\n",
        "        #3. episode wise wallClockTime (in seconds): actual time elapsed since the start of training,\n",
        "        #                               note this will include time for BookKeeping and evaluation\n",
        "        # Note both trainTime and wallClockTime get accumulated as episodes proceed.\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        #\n",
        "        resultTrain=self.trainAgent()\n",
        "        steps,rewards,evalScore,trainingTime=resultTrain\n",
        "        resultEval=self.evaluateAgent()\n",
        "\n",
        "\n",
        "        return rewards, trainingTime, evalScore, resultEval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "UaGVsltUTqk-"
      },
      "outputs": [],
      "source": [
        "class TD3(TD3):\n",
        "    def trainAgent(self):\n",
        "        #this method collects experiences and trains the agent and does BookKeeping while training.\n",
        "        #this calls the trainNetwork() method internally, it also evaluates the agent per episode\n",
        "        #it trains the agent for MAX_TRAIN_EPISODES\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        self.updateValueNetwork(self.tau)\n",
        "        self.updatePolicyNetwork(self.tau)\n",
        "        self.initBookeeping()\n",
        "        for e in range(self.max_train_eps):\n",
        "          s,done=self.env.reset(seed=self.seed)\n",
        "          self.step=0\n",
        "          self.Tr=0\n",
        "          self.evalscore=0\n",
        "          episode_start=time.time()\n",
        "          for i in range(1000):\n",
        "            explorationMax=self.rBuffer.length()<400\n",
        "            a=self.gaussianStrategy(self.online_policy_net, s, self.actionRange, 0.5, explorationMax)\n",
        "            s_n, r, done, _, _ =self.env.step(a)\n",
        "            experience=(s,a,r,s_n,done)\n",
        "            self.rBuffer.store(experience)\n",
        "\n",
        "\n",
        "            if self.rBuffer.length()>300:\n",
        "              experiences=self.rBuffer.sample(self.batch_size)\n",
        "              self.trainNetwork(experiences, e)\n",
        "\n",
        "            if e%self.update_freq_policy==0:\n",
        "              self.updatePolicyNetwork(self.tau)\n",
        "\n",
        "            if e%self.update_freq_value==0:\n",
        "              self.updateValueNetwork(self.tau)\n",
        "\n",
        "            s=s_n\n",
        "\n",
        "            self.step+=1\n",
        "            self.Tr+=r\n",
        "\n",
        "            if done:\n",
        "              break\n",
        "\n",
        "          self.evalscore,_=self.evaluateAgent()\n",
        "          self.episode_elapsed = time.time() - episode_start\n",
        "          self.performBookeeping(train=True)\n",
        "\n",
        "        return self.episode_step, self.episode_reward, self.evaluation_scores, self.training_time\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "NwJR0S5XTqk-"
      },
      "outputs": [],
      "source": [
        "class TD3(TD3):\n",
        "    def trainNetwork(self,experiences , episode):\n",
        "        # this method trains the value network epoch number of times and is called by the trainAgent function\n",
        "        # it essentially uses the experiences to calculate target, using the targets it calculates the error, which\n",
        "        # is further used for calulating the loss. It then uses the optimizer over the loss\n",
        "        # to update the params of the network by backpropagating through the network\n",
        "        # this function does not return anything\n",
        "        # you can try out other loss functions other than MSE like Huber loss, MAE, etc.\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        #self.actionRange=(self.actionLowValue,self.actionHighValue)\n",
        "        s, a, r, s_n, done=self.rBuffer.splitExperiences(experiences)\n",
        "        a_noise=(self.actionHighValue-self.actionLowValue)*(torch.randn_like(a))\n",
        "        a_noise=torch.max(torch.min(a_noise,self.actionHighValue),self.actionLowValue)\n",
        "\n",
        "        argmax_a_qs_v=self.target_policy_net(torch.from_numpy(s_n))\n",
        "        noisy_argmax_a_qs_v=argmax_a_qs_v+a_noise\n",
        "        noisy_argmax_a_qs_v=torch.max(torch.min(noisy_argmax_a_qs_v,self.actionHighValue),self.actionLowValue)\n",
        "        max_1_a_qs_v, max_2_a_qs_v=self.target_value_net(torch.from_numpy(s_n), noisy_argmax_a_qs_v)\n",
        "\n",
        "        max_a_qs_v=min(max_1_a_qs_v,max_2_a_qs_v)\n",
        "        max_a_qs_v=max_a_qs_v.numpy()\n",
        "        target_qs=r+self.gamma*max_a_qs_v*((1-done).T)\n",
        "        a=a.astype(np.float32)\n",
        "        qs_1, qs_2=self.online_value_net(torch.from_numpy(s),torch.from_numpy(a))\n",
        "        tdError_1=torch.from_numpy(target_qs).detach()-qs_1\n",
        "        tdError_2=torch.from_numpy(target_qs).detach()-qs_2\n",
        "\n",
        "        valueLoss=torch.mean(0.5*(tdError_1)**2)+torch.mean(0.5*(tdError_2)**2)\n",
        "        self.optimizerV.zero_grad()\n",
        "        valueLoss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(self.online_value_net.parameters(), max_norm=15)\n",
        "        self.optimizerV.step()\n",
        "\n",
        "        if episode%self.trainPolicyFrequency==0:\n",
        "          argmax_a_qs_p=self.online_policy_net(torch.from_numpy(s_n))\n",
        "          max_a_qs_p=self.online_value_net(torch.from_numpy(s_n),argmax_a_qs_p)\n",
        "          policyLoss=-1.0*torch.mean(max_a_qs_p)\n",
        "          self.optimizerP.zero_grad()\n",
        "          policyLoss.backward()\n",
        "          torch.nn.utils.clip_grad_norm_(self.online_value_net.parameters(), max_norm=15)\n",
        "          self.optimizerP.step()\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "DH1hT_5DTqk-"
      },
      "outputs": [],
      "source": [
        "class TD3(TD3):\n",
        "    def evaluateAgent(self):\n",
        "        #this function evaluates the agent using the value network, it evaluates agent for MAX_EVAL_EPISODES\n",
        "        #typcially MAX_EVAL_EPISODES = 1\n",
        "        #\n",
        "        #Your code goes in here\n",
        "        rewards=[]\n",
        "        for ep in range(self.max_eval_eps):\n",
        "          s,done=self.env.reset(seed=self.seed)\n",
        "          for c in range(500):\n",
        "            a=self.greedyStrategy(self.online_policy_net,s,self.actionRange)\n",
        "            s,r,done, _, _=self.env.step(a)\n",
        "            if done:\n",
        "              break\n",
        "          rewards.append(r)\n",
        "\n",
        "        return np.mean(rewards), np.std(rewards)\n",
        "\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotQuantity(eps,env_id):\n",
        "  seeds=[55,45]\n",
        "  # Steps=[]\n",
        "  Rewards=[]\n",
        "  EvalScore=[]\n",
        "  TrainingTime=[]\n",
        "  ResultEval=[]\n",
        "\n",
        "  for s in seeds:\n",
        "\n",
        "    agent=TD3(env_id,seed,gamma,tau,buffer_size,batch_size,ufp, ufv , tpf, policyOptimizer,valueOptimizer,policyOptimizerLr,valueOptimizerLr,max_train_eps,max_eval_eps)\n",
        "    rewards,evalScore,trainingTime,resultEval=agent.runTD3()\n",
        "    # Steps.append(steps)\n",
        "    Rewards.append(rewards)\n",
        "    EvalScore.append(evalScore)\n",
        "    TrainingTime.append(trainingTime)\n",
        "    ResultEval.append(resultEval)\n",
        "    print(ResultEval)\n",
        "  quantities = [Rewards, EvalScore, TrainingTime]\n",
        "  quantity_names = [\"Rewards\", \"EvalScore\", \"TrainingTime\"]\n",
        "\n",
        "  for quantity, quantity_name in zip(quantities, quantity_names):\n",
        "      mean_values = np.mean(quantity, axis=0)\n",
        "      min_values = np.min(quantity, axis=0)\n",
        "      max_values = np.max(quantity, axis=0)\n",
        "\n",
        "    # Calculate mean, min, and max values across environment instances for each episode\n",
        "\n",
        "    # for episode in range(eps):\n",
        "    #     quantity_values = quantityList[episode]\n",
        "\n",
        "    #     mean_values.append(np.mean(quantity_values))\n",
        "    #     min_values.append(np.min(quantity_values))\n",
        "    #     max_values.append(np.max(quantity_values))\n",
        "\n",
        "    # Create the plot\n",
        "      plt.figure(figsize=(10, 6))\n",
        "\n",
        "      # Plot mean values\n",
        "      plt.plot(range(1, eps + 1), mean_values, label='Mean', color='blue')\n",
        "\n",
        "      # Fill between min and max values\n",
        "      plt.fill_between(range(1, eps + 1), min_values, max_values, color='lightblue', alpha=0.3)\n",
        "\n",
        "      # Add legend\n",
        "      plt.legend(loc='upper left')\n",
        "\n",
        "      # Add labels and title\n",
        "      plt.xlabel('Episode')\n",
        "      plt.ylabel(quantity_name)\n",
        "      plt.title(env_id)\n",
        "\n",
        "      # Show plot\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "h8kjhbjM2AVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ufp=10\n",
        "ufv=9\n",
        "tpf=2\n",
        "envs=[\"Pendulum-v1\",\"Hopper-v4\",\"HalfCheetah-v4\"]\n",
        "for env in envs:\n",
        "  plotQuantity(120,env)"
      ],
      "metadata": {
        "id": "9aV0Dzd32WKB"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpcL3G20Tqk-"
      },
      "source": [
        "# PPO\n",
        "<a id=\"PPO\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7U96CLNTqk-"
      },
      "source": [
        "PPO have quite a few key implementation details.\n",
        "Please Refer:\n",
        "\"Proximal Policy Optimization Algorithms\" [PPO](https://arxiv.org/abs/1707.06347) and\n",
        "\"Implementation Matters in Deep RL: A Case Study on PPO and TRPO\" [Implementation Matters](https://openreview.net/forum?id=r1etN1rtPB)\n",
        "\n",
        "Lets finish things off with an easy implementation of PPO!\n",
        "A easy way to check you implementation details is running your implementation on some easier environment first and make sure it converges. Like \"CartPole-v1\" should converge to episodic return of 500 in around 300k steps."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "id": "lHZj3dIgs_lM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "RP6epYOhTqk-"
      },
      "outputs": [],
      "source": [
        "#All imports here\n",
        "## Feel free to add or remove\n",
        "\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions.categorical import Categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "8zVGECC9Tqk-"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "gym_id = \"CartPole-v1\"  #The id of the gym environment\n",
        "learning_rate = 2.5e-4\n",
        "seed = 1\n",
        "total_timesteps = 2000 #The total timesteps of the experiments\n",
        "torch_deterministic = True   #If toggled, `torch.backends.cudnn.deterministic=False\n",
        "cuda = True\n",
        "\n",
        "num_envs = 4  #The number of parallel game environments (Yes PPO works with vectorized environments)\n",
        "num_steps = 128 #The number of steps to run in each environment per policy rollout\n",
        "anneal_lr = True #Toggle learning rate annealing for policy and value networks\n",
        "gae = True #Use GAE for advantage computation\n",
        "gamma =0.99\n",
        "gae_lambda = 0.95 #The lambda for the general advantage estimation\n",
        "num_minibatches = 4\n",
        "update_epochs =4  #The K epochs to update the policy\n",
        "norm_adv = True  #Toggles advantages normalization\n",
        "clip_coef = 0.2 #The surrogate clipping coefficient (See what is recommended in the paper!)\n",
        "clip_vloss = True #Toggles whether or not to use a clipped loss for the value function, as per the paper\n",
        "ent_coef =0.01  #Coefficient of the entropy\n",
        "vf_coef = 0.5 #Coefficient of the value function\n",
        "max_grad_norm = 0.5\n",
        "target_kl = None #The target KL divergence threshold\n",
        "\n",
        "\n",
        "batch_size = int(num_envs * num_steps)\n",
        "minibatch_size = int(batch_size // num_minibatches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "GDmIerizTqk-"
      },
      "outputs": [],
      "source": [
        "#PPO works with vectorized enviromnets lets make a function that returns a function that returns an environment.\n",
        "#Refer how to make vectorized environments in gymnasium\n",
        "def make_env(gym_id, seed, idx):\n",
        "    def thunk():\n",
        "        env = gym.make(gym_id)\n",
        "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
        "        env.reset(seed=seed)\n",
        "        return env\n",
        "\n",
        "    return thunk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "5NMj8yVHTqk_"
      },
      "outputs": [],
      "source": [
        "#We initialize the layers in PPO , refer paper.\n",
        "#Lets initialize the layers with this function\n",
        "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
        "    #Initializes the weights and bias of the layers\n",
        "    #Your code here\n",
        "    torch.nn.init.orthogonal_(layer.weight, std)\n",
        "    torch.nn.init.constant_(layer.bias, bias_const)\n",
        "\n",
        "    return layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "LU-WEr_iTqk_"
      },
      "outputs": [],
      "source": [
        "#Lets make the Main agent class\n",
        "class Agent(nn.Module):\n",
        "    def __init__(self, envs):\n",
        "        super(Agent, self).__init__()\n",
        "\n",
        "        state_dim=envs.single_observation_space.shape[0]\n",
        "        action_dim=envs.single_action_space.n\n",
        "        h_layers=[64,64]\n",
        "\n",
        "        self.critic = nn.Sequential(\n",
        "            layer_init(nn.Linear(state_dim,h_layers[0])),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(h_layers[0],h_layers[1])),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(h_layers[1],1), std=0.01),\n",
        "        )\n",
        "\n",
        "        self.actor = nn.Sequential(\n",
        "            layer_init(nn.Linear(state_dim,h_layers[0])),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(h_layers[0],h_layers[1])),\n",
        "            nn.Tanh(),\n",
        "            layer_init(nn.Linear(h_layers[1],action_dim), std=0.01),\n",
        "\n",
        "\n",
        "        )\n",
        "\n",
        "    def get_value(self, x):\n",
        "            # Returns the value from the critic on the observation x\n",
        "            value=self.critic(x)\n",
        "            return value\n",
        "\n",
        "    def get_action_and_value(self, x, action=None):\n",
        "        #Returns 1.the action (sampled according to the logits),\n",
        "        #2.log_prob of the action,\n",
        "        #3.Entropy,\n",
        "        #4.Value from the critic\n",
        "        logits= self.actor(x)\n",
        "        dist=Categorical(logits=logits)\n",
        "        actions=dist.sample()\n",
        "        logPs=dist.log_prob(actions)\n",
        "        entropies=dist.entropy()\n",
        "        value=self.get_value(x)\n",
        "\n",
        "        return actions, logPs, entropies, value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "DCO2HOQlTqk_"
      },
      "outputs": [],
      "source": [
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = torch_deterministic\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() and cuda else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "1bMQTt7CTqk_"
      },
      "outputs": [],
      "source": [
        "#Make the vectorized environments, use the helper function that we have declared above\n",
        "envs=gym.vector.SyncVectorEnv([make_env(gym_id, seed+i, i) for i in range(num_envs)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "s9YGWWO6Tqk_"
      },
      "outputs": [],
      "source": [
        "agent = Agent(envs).to(device)\n",
        "optimizer = optim.Adam(agent.parameters(), lr=learning_rate, eps=1e-5)\n",
        "\n",
        "# ALGO Logic: Storage setup\n",
        "obs = torch.zeros((num_steps, num_envs) + envs.single_observation_space.shape).to(device)\n",
        "actions = torch.zeros((num_steps, num_envs) + envs.single_action_space.shape).to(device)\n",
        "logprobs = torch.zeros((num_steps, num_envs)).to(device)\n",
        "rewards = torch.zeros((num_steps, num_envs)).to(device)\n",
        "dones = torch.zeros((num_steps, num_envs)).to(device)\n",
        "values = torch.zeros((num_steps, num_envs)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "hTUQMuUBTqk_"
      },
      "outputs": [],
      "source": [
        "# Start the game\n",
        "global_step = 0\n",
        "start_time = time.time()\n",
        "next_obs, info = envs.reset()\n",
        "next_obs = torch.Tensor(next_obs).to(device)\n",
        "next_done = torch.zeros(num_envs).to(device)\n",
        "num_updates = total_timesteps // batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "DbnD-K7jTqk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "628b2c3f-9127-4385-ff8e-d20674bc5360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "global_step=1584, episodic_return=[17.]\n",
            "global_step=1636, episodic_return=[13.]\n",
            "global_step=1748, episodic_return=[28.]\n",
            "global_step=1832, episodic_return=[21.]\n",
            "global_step=1896, episodic_return=[16.]\n",
            "global_step=2012, episodic_return=[29.]\n",
            "global_step=2160, episodic_return=[37.]\n",
            "global_step=2208, episodic_return=[12.]\n",
            "global_step=2312, episodic_return=[26.]\n",
            "global_step=2396, episodic_return=[21.]\n",
            "global_step=2464, episodic_return=[17.]\n",
            "global_step=2532, episodic_return=[17.]\n",
            "global_step=2636, episodic_return=[26.]\n",
            "global_step=2696, episodic_return=[15.]\n",
            "global_step=2824, episodic_return=[32.]\n",
            "global_step=2888, episodic_return=[16.]\n",
            "global_step=2968, episodic_return=[20.]\n",
            "global_step=3020, episodic_return=[13.]\n"
          ]
        }
      ],
      "source": [
        "#This is the main training loop where we collect the experience ,\n",
        "#calculate the advantages, ratio , the total loss and learn the policy\n",
        "\n",
        "for update in range(1, num_updates + 1):\n",
        "\n",
        "    # Annealing the rate if instructed to do so.\n",
        "    if anneal_lr:\n",
        "        # Your code here\n",
        "        f=1.0-(update-1.0)/num_updates\n",
        "        lrnow=f*learning_rate\n",
        "        optimizer.param_groups[0][\"lr\"]=lrnow\n",
        "\n",
        "        pass\n",
        "\n",
        "    for step in range(0, num_steps):\n",
        "        global_step += 1 * num_envs  # We are taking a step in each environment\n",
        "        obs[step] = next_obs\n",
        "        dones[step] = next_done\n",
        "\n",
        "        # ALGO LOGIC: action logic\n",
        "        with torch.no_grad():\n",
        "            #Get the action , logprob , _ , value from the agent.\n",
        "            action, logprob, _, value = agent.get_action_and_value(next_obs)\n",
        "\n",
        "            values[step] = value.flatten()\n",
        "        actions[step] = action\n",
        "        logprobs[step] = logprob\n",
        "\n",
        "        # TRY NOT TO MODIFY: execute the game and log data.\n",
        "        next_obs, reward, done,truncated, info = envs.step(action.cpu().numpy())\n",
        "        rewards[step] = torch.tensor(reward).to(device).view(-1)\n",
        "        next_obs, next_done = torch.Tensor(next_obs).to(device), torch.Tensor(done).to(device)\n",
        "\n",
        "        for item in info:\n",
        "            if item == \"final_info\" and info[item][0] is not None:\n",
        "                print(f\"global_step={global_step}, episodic_return={info[item][0]['episode']['r']}\")\n",
        "                break\n",
        "\n",
        "    # bootstrap value if not done\n",
        "    with torch.no_grad():\n",
        "        next_value = agent.get_value(next_obs).reshape(1, -1)\n",
        "        if gae:\n",
        "          advantages=torch.zeros_like(rewards).to(device)\n",
        "          lastgaelam=0\n",
        "          for t in reversed(range(num_steps)):\n",
        "            if t== num_steps-1:\n",
        "              nextnonterminal=1-next_done\n",
        "              nextvalues=next_value\n",
        "            else:\n",
        "              nextnonterminal=1-dones[t+1]\n",
        "              nextvalues=values[t+1]\n",
        "            delta=rewards[t]*gamma*nextvalues*nextnonterminal-values[t]\n",
        "            advantages[t]=lastgaelam=delta+gamma*gae_lambda*nextnonterminal*lastgaelam\n",
        "\n",
        "          returns = advantages + values  #(yes official implementation of ppo calculates it this way)\n",
        "        else:\n",
        "          returns=torch.zero_like(rewards).to(device)\n",
        "          for t in  reversed(range(num_steps)):\n",
        "            if t== num_steps-1:\n",
        "              nextnonterminal=1-next_done\n",
        "              next_return=next_value\n",
        "            else:\n",
        "              nextnonterminal=1-dones[t+1]\n",
        "              next_return=returns[t+1]\n",
        "            returns[t]=rewards[t]+gamma*nextnonterminal*next_return\n",
        "\n",
        "            advantages = returns - values\n",
        "\n",
        "    # flatten the batch\n",
        "    b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
        "    b_logprobs = logprobs.reshape(-1)\n",
        "    b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n",
        "    b_advantages = advantages.reshape(-1)\n",
        "    b_returns = returns.reshape(-1)\n",
        "    b_values = values.reshape(-1)\n",
        "\n",
        "    # Optimizing the policy and value network\n",
        "    b_inds = np.arange(batch_size)\n",
        "    clipfracs = []\n",
        "    for epoch in range(update_epochs):\n",
        "        #Get a random sample of batch_size\n",
        "        np.random.shuffle(b_inds)\n",
        "        for start in range(0, batch_size, minibatch_size):\n",
        "            end = start + minibatch_size\n",
        "            mb_inds = b_inds[start:end]\n",
        "\n",
        "            #Your code here\n",
        "            #Calculate the ratio\n",
        "            _, newlogprob, entropy, newvalue = agent.get_action_and_value(b_obs[mb_inds], b_actions.long()[mb_inds])\n",
        "            logratio = newlogprob-b_logprobs[mb_inds]\n",
        "            ratio = logratio.exp()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # calculate approx_kl http://joschu.net/blog/kl-approx.html\n",
        "                # Refer the blog for calculating kl in a simpler way\n",
        "                old_approx_kl = (-logratio).mean()\n",
        "                approx_kl =((ratio-1)-logratio).mean()\n",
        "                clipfracs += [((ratio - 1.0).abs() > clip_coef).float().mean().item()]\n",
        "\n",
        "            mb_advantages = b_advantages[mb_inds]\n",
        "            if norm_adv:\n",
        "                mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
        "\n",
        "            # Policy loss (Calculate the policy loss pg_loss)\n",
        "            # Your code here\n",
        "            pg_loss1=-mb_advantages*ratio\n",
        "            pg_loss2=-mb_advantages*torch.clamp(ratio, 1-clip_coef, 1+clip_coef)\n",
        "            pg_loss=torch.max(pg_loss1, pg_loss2).mean()\n",
        "\n",
        "\n",
        "            # Value loss v_loss\n",
        "            newvalue = newvalue.view(-1)\n",
        "            if clip_vloss:\n",
        "                v_loss_unclipped=(newvalue-b_returns[mb_inds])**2\n",
        "                v_clipped=b_values[mb_inds]+torch.clamp(\n",
        "                    newvalue - b_values[mb_inds],\n",
        "                    clip_coef,\n",
        "                    clip_coef,\n",
        "                )\n",
        "                v_loss_clipped=(v_clipped-b_returns[mb_inds])**2\n",
        "                v_loss_max=torch.max(v_loss_unclipped, v_loss_clipped)\n",
        "                v_loss=0.5*v_loss_max.mean()\n",
        "            else:\n",
        "                v_loss= 0.5*((newvalue - b_returns[mb_inds])**2).mean()\n",
        "            # Entropy loss\n",
        "            entropy_loss = entropy.mean()\n",
        "            # Total loss\n",
        "            loss = pg_loss - ent_coef * entropy_loss + v_loss * vf_coef\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "\n",
        "        if target_kl is not None:\n",
        "            if approx_kl > target_kl:\n",
        "                break\n",
        "\n",
        "    y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n",
        "    var_y = np.var(y_true)\n",
        "    explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
        "\n",
        "\n",
        "envs.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTCAziiVTqlA"
      },
      "source": [
        "# Experiments and Plots\n",
        "<a id=\"experiments\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0fs53psTqlA"
      },
      "source": [
        "Run the DDPG, TD3, PPO on Pendulum, Hopper and Half Cheetah environment respectively.\n",
        "\n",
        "Plot the following for each of the environment separately. Note based on different hyper-parameters and strategies you use, you can have multiple plots for each of the below.\n",
        "\n",
        "As you are aware from your past experience, single run of the agent over the environment results in plots that have lot of variance and look very noisy. One way to overcome this is to create several different instances of the environment using different seeds and then average out the results across these and plot these. For all the plots below, you this strategy. You need to run 5 different instances of the environment for each agent. As you have seen in the lecture slides, we plot the maximum and minimum values around the mean in the plots, so this gives us the shaded plot with the mean curve in the between. In this assignment, you are required to do the same. Generate plots with envelop between maximum and minimum value\n",
        "For each of the quantity of interest, plot each of the agent within the same plot using different colors for the envelop. Choose colors such that that there is clear contrast between the plots corresponding to different agents.\n",
        "\n",
        "1. Plot mean train rewards vs episodes\n",
        "2. Plot mean evaluation rewards vs episodes\n",
        "3. Plot total steps vs episode\n",
        "4. Plot train time vs episode\n",
        "5. Plot wall clock time vs episode\n",
        "6. Based on plots what are your observations about DDPG and TD3, compare the two algorithms.\n",
        "7. What is the advatage of PPO over DDPG or TD3?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}